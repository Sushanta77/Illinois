{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath='data/',print_ind=False):\n",
    "    columns = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','target']\n",
    "    train = pd.read_csv(\"data/train.txt\",names=columns)\n",
    "    test = pd.read_csv(\"data/test.txt\",names=columns[:-1])\n",
    "    \n",
    "    train['target'].replace(' <=50K',-1,inplace=True)\n",
    "    train['target'].replace(' >50K',1,inplace=True)  \n",
    "    label=np.array(train['target']).reshape(len(train['target']),1)\n",
    "    train.drop('target',axis=1,inplace=True)\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    label = label.astype(int)\n",
    "    if (print_ind):\n",
    "        print (\"Train Shape: {} Test Shape{}\".format(train.shape,test.shape))\n",
    "    return train,test,label\n",
    "\n",
    "def preprocessing(data):\n",
    "    #train,test,label=load_dataset()\n",
    "    train=extract_contineous(data)\n",
    "    #test=extract_contineous(test)\n",
    "    train_scale=feature_scaling(train)\n",
    "    test_scale=feature_scaling(test)\n",
    "    train_with_label = np.append(train_scale,label,axis=1)\n",
    "    return train_with_label,test_scale\n",
    "\n",
    "def extract_contineous(data):\n",
    "    cont_columns = [0,2,4,10,11,12]\n",
    "    return (data[:,cont_columns]).astype(float)\n",
    "\n",
    "\n",
    "def feature_scaling(data,print_ind=False):\n",
    "    feature_mean=data.mean(axis=0).astype(float)\n",
    "    feature_var =data.var(axis=0).astype(float)\n",
    "    data = (data - feature_mean) / np.sqrt(feature_var)\n",
    "    if (print_ind):\n",
    "        print (\"Scale Shape:{}\".format(input_df_scale.shape))\n",
    "    return data\n",
    "\n",
    "def penalty_term(a):\n",
    "    return 1/2 * np.asscalar(np.transpose(a).dot(a))\n",
    "\n",
    "def obj_func(a,b,data):\n",
    "    obj = np.dot(a.T,data)+b\n",
    "    return obj\n",
    "\n",
    "\n",
    "def gradient_calc(w,lam,data):\n",
    "    X = data[:-1]\n",
    "    y = data[-1]\n",
    "    a = w[:-1]\n",
    "    b = w[-1]\n",
    "    diff = y * obj_func(a,b,X)\n",
    "    a_delta = np.array([])\n",
    "    b_delta = 0\n",
    "    if (diff >= 1):\n",
    "        a_delta = lam*a\n",
    "        b_delta = 0\n",
    "    else:\n",
    "        a_delta = np.subtract(lam * a, (y * X).reshape(6, 1))\n",
    "        b_delta = -y\n",
    "    gradient = (np.append(np.array(a_delta), np.array([b_delta]))).reshape(7, 1)\n",
    "    return gradient\n",
    "    \n",
    "    \n",
    "def cost_function(w,lam,data):\n",
    "    a = w[:-1]\n",
    "    b = w[-1:]\n",
    "    m=len(data)  \n",
    "    temp_max_val=0\n",
    "    \n",
    "    for e in data:\n",
    "        X = e[:-1]\n",
    "        y = e[-1:]\n",
    "        obj = obj_func(a,b,X)\n",
    "        error = 1 - y * obj\n",
    "        temp_max_val+=max(0, np.asscalar(error))\n",
    "        \n",
    "    max_val = ((1/m)*temp_max_val) + lam * penalty_term(a)\n",
    "    return max_val\n",
    "\n",
    "\n",
    "def pred_calc(w,X):\n",
    "    a = w[:-1]\n",
    "    b = w[-1][0]\n",
    "    obj = obj_func(a,b,X)\n",
    "    pred = np.sign(obj)[0]\n",
    "    return pred\n",
    "\n",
    "\n",
    "def evaluate_model(w,lam,data):\n",
    "    num_correct = 0\n",
    "    for d in data:\n",
    "        X = d[:-1]\n",
    "        y = d[-1]\n",
    "        pred = pred_calc(w,X)\n",
    "        if (pred == y):\n",
    "            num_correct += 1\n",
    "    return (num_correct/len(data))\n",
    "\n",
    "\n",
    "def train_test_split(data,eval_percent):\n",
    "    np.random.shuffle(data)\n",
    "    end_loc = len(data)//eval_percent\n",
    "    eval_data=data[:end_loc]\n",
    "    train_data=data[end_loc:]\n",
    "    return train_data,eval_data\n",
    "\n",
    "\n",
    "def train_model(train):\n",
    "    w = np.random.rand(7,1) #initialize weight\n",
    "    weight_cost = {}\n",
    "    step_count=0\n",
    "    num_epochs = 50 #initialize number of epochs\n",
    "    num_steps = 300 #initialize number of steps\n",
    "    #l_rate = 0.001 #initialize learning rate\n",
    "    #l_rate = (1/(0.01*i+50))\n",
    "    costs = []\n",
    "    accuracy_step_wise = []\n",
    "    accuracy_lam_wise = []\n",
    "    #train,test=preprocessing()\n",
    "    np.random.shuffle(train) # Shuffle train Dataset\n",
    "    train_set,eval_set=train_test_split(train,10) #|--10%(valid_set)---|-----------------90%(train_set)-----------------|\n",
    "    epoch_data = train_set[:50]  #|-(50 epoch_data)--|--------------90%-50 Example(train_data)-----------------|\n",
    "    train_data = train_set[50:]  #|-(50 epoch_data)--|--------------90%-50 Example(train_data)-----------------|\n",
    "    for l in [1e-5,1e-4,1e-3,1e-2,1e-1,1]:\n",
    "        for i in range(num_epochs):\n",
    "            for j in range(num_steps):\n",
    "                step_count += 1\n",
    "                gradient = gradient_calc(w,l,train_data[j])\n",
    "                l_rate = (1/(0.01*i+100))\n",
    "                step = l_rate * gradient\n",
    "                w = np.subtract(w, step)\n",
    "                if (step_count % 30 == 0): #Each Step = 30\n",
    "                    acuuracy_step=evaluate_model(w,l,epoch_data) #Each Step Level (epoch_data)\n",
    "                    cost_step = cost_function(w, l, epoch_data) #Each Step Level (epoch_data)\n",
    "                    accuracy_step_wise.append([l,step_count,acuuracy_step,np.sqrt(np.sum(w[:-1]**2)),cost_step]) #Each Step Level\n",
    "            np.random.shuffle(train_set) #|-----------------90%(train_set)(Shuffle)-----------------|\n",
    "            epoch_data = train_set[:50]  #|-(50 epoch_data)--|--------------90%-50 Example(train_data)-----------------|\n",
    "            train_data = train_set[50:]  #|-(50 epoch_data)--|--------------90%-50 Example(train_data)-----------------|\n",
    "        acuuracy_lam=evaluate_model(w,l,eval_set) #Each lamda level (epoch_data)\n",
    "        cost_lam = cost_function(w, l, eval_set) #Each lambda level (epoch_data)\n",
    "        weight_cost[l] = {'W':w,'Accuracy':acuuracy_lam, 'Cost':cost_lam}        \n",
    "        accuracy_lam_wise.append([l,step_count,acuuracy_lam,np.sqrt(np.sum(w[:-1]**2)),cost_lam]) #Each Step Level\n",
    "        step_count=0\n",
    "        np.random.shuffle(train) # Shuffle train Dataset\n",
    "        train_set,eval_set=train_test_split(train,10) #|--10%(valid_set)---|-----------------90%(train_set)-----------------|\n",
    "        epoch_data = train_set[:50]  #|-(50 epoch_data)--|--------------90%-50 Example(train_data)-----------------|\n",
    "        train_data = train_set[50:]  #|-(50 epoch_data)--|--------------90%-50 Example(train_data)-----------------|\n",
    "        w = np.random.rand(7,1) #initialize weight\n",
    "    #step_accuracy=np.array(accuracy_step_wise)\n",
    "    #lam_accuracy=np.array(accuracy_lam_wise)\n",
    "    #return step_accuracy,lam_accuracy\n",
    "    return accuracy_step_wise,accuracy_lam_wise,weight_cost\n",
    "\n",
    "\n",
    "\n",
    "def plot_val_accuracy(step_accuracy):\n",
    "    plt.subplots(figsize=(20,8))\n",
    "    plt.plot(step_accuracy[step_accuracy[:,0] == 0.00001][:,1],step_accuracy[step_accuracy[:,0] == 0.0001][:,2],color='black')\n",
    "    plt.plot(step_accuracy[step_accuracy[:,0] == 0.0001][:,1],step_accuracy[step_accuracy[:,0] == 0.0001][:,2],color='purple')\n",
    "    plt.plot(step_accuracy[step_accuracy[:,0] == 0.001][:,1],step_accuracy[step_accuracy[:,0] == 0.001][:,2],color='red')\n",
    "    plt.plot(step_accuracy[step_accuracy[:,0] == 0.01][:,1],step_accuracy[step_accuracy[:,0] == 0.01][:,2],color='green')\n",
    "    plt.plot(step_accuracy[step_accuracy[:,0] == 0.1][:,1],step_accuracy[step_accuracy[:,0] == 0.1][:,2],color='blue')\n",
    "    plt.plot(step_accuracy[step_accuracy[:,0] == 1][:,1],step_accuracy[step_accuracy[:,0] == 1][:,2],color='orange')\n",
    "    plt.legend(['1e-5','1e-4','1e-3','1e-2','1e-1','1'])\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "\n",
    "    \n",
    "def plot_magnitude_w(step_accuracy):\n",
    "    plt.subplots(figsize=(20,8))\n",
    "    plt.plot(step_accuracy[step_accuracy[:,0] == 0.00001][:,1],step_accuracy[step_accuracy[:,0] == 0.00001][:,3],color='black')\n",
    "    plt.plot(step_accuracy[step_accuracy[:,0] == 0.0001][:,1],step_accuracy[step_accuracy[:,0] == 0.0001][:,3],color='purple')\n",
    "    plt.plot(step_accuracy[step_accuracy[:,0] == 0.001][:,1],step_accuracy[step_accuracy[:,0] == 0.001][:,3],color='red')\n",
    "    plt.plot(step_accuracy[step_accuracy[:,0] == 0.01][:,1],step_accuracy[step_accuracy[:,0] == 0.01][:,3],color='green')\n",
    "    plt.plot(step_accuracy[step_accuracy[:,0] == 0.1][:,1],step_accuracy[step_accuracy[:,0] == 0.1][:,3],color='blue')\n",
    "    plt.plot(step_accuracy[step_accuracy[:,0] == 1][:,1],step_accuracy[step_accuracy[:,0] == 1][:,3],color='orange')\n",
    "    plt.legend(['1e-5','1e-4','1e-3','1e-2','1e-1','1'])\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Size of w')\n",
    "\n",
    "def pred_test(w,test):\n",
    "    sr_pred_test=[]\n",
    "    for data in test:\n",
    "        pred_test_val=pred_calc(w,data)\n",
    "        if (pred_test_val == -1):\n",
    "            pred = '<=50K'\n",
    "        elif(pred_test_val == 1):\n",
    "            pred = '>50K'\n",
    "        sr_pred_test.append(pred)\n",
    "        #sr_pred_test.append(pred_test_val)\n",
    "    pd.DataFrame(sr_pred_test).to_csv(\"submission.txt\",index=False,header=False)\n",
    "        \n",
    "\n",
    "def main(show):\n",
    "    train,test,label=load_dataset()\n",
    "    train_contineous=extract_contineous(train)\n",
    "    train_scale=feature_scaling(train_contineous)\n",
    "    train_with_label = np.append(train_scale,label,axis=1)\n",
    "\n",
    "    test_contineous=extract_contineous(test)\n",
    "    test_scale=feature_scaling(test_contineous)\n",
    "    #train_with_label = np.append(train_scale,label,axis=1)\n",
    "\n",
    "    #train,test=preprocessing()\n",
    "    step_accuracy,lam_accuracy,weight_cost=train_model(train_with_label)\n",
    "    if (show):\n",
    "        plot_val_accuracy(np.array(step_accuracy))\n",
    "        plot_magnitude_w(np.array(step_accuracy))\n",
    "    pred_test(pd.DataFrame(weight_cost).T.loc[0.0001].loc['W'],test_scale)\n",
    "    return step_accuracy,pd.DataFrame(lam_accuracy,columns=['lam','step_count','accuracy','weight','cost']).sort_values(by='cost'),pd.DataFrame(weight_cost).T,pd.DataFrame(step_accuracy,columns=['lam','step_count','accuracy','weight','cost']).groupby('lam').mean().sort_values(by='cost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_accuracy,lam_accuracy,weight_cost,mean_step_accuracy=main(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_count</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>weight</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lam</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01000</th>\n",
       "      <td>7515</td>\n",
       "      <td>0.82356</td>\n",
       "      <td>1.199258</td>\n",
       "      <td>0.400728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00100</th>\n",
       "      <td>7515</td>\n",
       "      <td>0.80800</td>\n",
       "      <td>1.547060</td>\n",
       "      <td>0.428858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00001</th>\n",
       "      <td>7515</td>\n",
       "      <td>0.79892</td>\n",
       "      <td>1.563474</td>\n",
       "      <td>0.436106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00010</th>\n",
       "      <td>7515</td>\n",
       "      <td>0.78696</td>\n",
       "      <td>1.671798</td>\n",
       "      <td>0.463658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10000</th>\n",
       "      <td>7515</td>\n",
       "      <td>0.77580</td>\n",
       "      <td>0.566264</td>\n",
       "      <td>0.479415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00000</th>\n",
       "      <td>7515</td>\n",
       "      <td>0.75776</td>\n",
       "      <td>0.158920</td>\n",
       "      <td>0.500918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         step_count  accuracy    weight      cost\n",
       "lam                                              \n",
       "0.01000        7515   0.82356  1.199258  0.400728\n",
       "0.00100        7515   0.80800  1.547060  0.428858\n",
       "0.00001        7515   0.79892  1.563474  0.436106\n",
       "0.00010        7515   0.78696  1.671798  0.463658\n",
       "0.10000        7515   0.77580  0.566264  0.479415\n",
       "1.00000        7515   0.75776  0.158920  0.500918"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_step_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
