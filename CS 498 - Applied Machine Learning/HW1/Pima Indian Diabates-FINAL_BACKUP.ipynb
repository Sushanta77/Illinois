{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath=\"data/pima-indians-diabetes.csv\"):\n",
    "    df_pima = pd.read_csv(filepath)\n",
    "    df_pima.columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Class']\n",
    "    distinct_class=df_pima['Class'].unique()\n",
    "    return df_pima,distinct_class\n",
    "\n",
    "def train_test_split(input_df=None,fold=10,print_ind=False,train_split=80):\n",
    "    train_splitloc = []\n",
    "    test_splitloc  = []\n",
    "    train_end_loc = np.round(input_df.shape[0]*(train_split/100)).astype(int)\n",
    "    for f in range(fold):\n",
    "        loc_arr = np.arange(input_df.shape[0])\n",
    "        np.random.shuffle(loc_arr)\n",
    "        train_splitloc.append(loc_arr[:train_end_loc])\n",
    "        test_splitloc.append(loc_arr[train_end_loc:])\n",
    "    return train_splitloc,test_splitloc\n",
    "\n",
    "\n",
    "def train_class_mean_std(input_df,input_train_splitloc,impute_ind=False):\n",
    "    dict_train_mean_stdev_calc = {}\n",
    "    dict_train_mean_stdev_impute_calc = {}\n",
    "    for c in distinct_class:\n",
    "        #print (\"Running for the Class: {}\".format(c))\n",
    "        df_pima_train_set = input_df.iloc[input_train_splitloc][input_df.iloc[input_train_splitloc]['Class'] == c]\n",
    "        #mean=input_df.iloc[input_train_splitloc][input_df.iloc[input_train_splitloc]['Class'] == c].describe().loc['mean'][:-1]\n",
    "        #stdev=input_df.iloc[input_train_splitloc][input_df.iloc[input_train_splitloc]['Class'] == c].describe().loc['std'][:-1]\n",
    "        if (impute_ind):\n",
    "            #print (\"Coming\")\n",
    "            df_pima_train_set['BloodPressure']=df_pima_train_set['BloodPressure'].replace(0,np.NAN) #impute to NAN, so it won't used in mean/std\n",
    "            df_pima_train_set['SkinThickness']=df_pima_train_set['SkinThickness'].replace(0,np.NAN) #impute to NAN, so it won't used in mean/std\n",
    "            df_pima_train_set['BMI']=df_pima_train_set['BMI'].replace(0,np.NAN) #impute to NAN, so it won't used in mean/std\n",
    "            df_pima_train_set['Age']=df_pima_train_set['Age'].replace(0,np.NAN) #impute to NAN, so it won't used in mean/std\n",
    "        #print (np.sum(df_pima_train_set.isna()),0)\n",
    "\n",
    "        mean=df_pima_train_set.describe().loc['mean'][:-1]\n",
    "        stdev=df_pima_train_set.describe().loc['std'][:-1]\n",
    "        dict_train_mean_stdev_calc[c] = mean,stdev\n",
    "        \n",
    "#         input_df['BloodPressure']=input_df['BloodPressure'].replace(0,np.NAN) #impute to NAN, so it won't used in mean/std\n",
    "#         input_df['SkinThickness']=input_df['SkinThickness'].replace(0,np.NAN) #impute to NAN, so it won't used in mean/std\n",
    "#         input_df['BMI']=input_df['BMI'].replace(0,np.NAN) #impute to NAN, so it won't used in mean/std\n",
    "#         input_df['Age']=input_df['Age'].replace(0,np.NAN) #impute to NAN, so it won't used in mean/std\n",
    "#         mean_impute=input_df.iloc[input_train_splitloc][input_df.iloc[input_train_splitloc]['Class'] == c].describe().loc['mean'][:-1]\n",
    "#         stdev_impute=input_df.iloc[input_train_splitloc][input_df.iloc[input_train_splitloc]['Class'] == c].describe().loc['std'][:-1]\n",
    "#         dict_train_mean_stdev_impute_calc[c] = mean_impute,stdev_impute\n",
    "\n",
    "    #print (\"Len Train:{}. Number of 0:{} 1:{}\".format(len(input_train_splitloc),df_pima.iloc[input_train_splitloc][df_pima.iloc[input_train_splitloc]['Class'] == 0].shape,df_pima.iloc[input_train_splitloc][df_pima.iloc[input_train_splitloc]['Class'] == 1].shape))\n",
    "    return dict_train_mean_stdev_calc\n",
    "\n",
    "\n",
    "def gaussian_naive_bayes_pred(input_test_splitloc,input_dict_train_mean_stdev,input_distinct_class):\n",
    "    fold_predict_class = np.zeros((len(input_test_splitloc),len(input_distinct_class)))\n",
    "    for c in input_distinct_class:\n",
    "        exp_nr = -((df_pima.iloc[input_test_splitloc].drop('Class',axis=1)-np.array(input_dict_train_mean_stdev[c][0]))**2)\n",
    "        exp_dn = (2*((dict_train_mean_stdev[c][1]) ** 2 ))\n",
    "        exp = exp_nr / exp_dn\n",
    "        exp = np.exp(exp)\n",
    "        coef = (1/((np.sqrt(2*np.pi))*input_dict_train_mean_stdev[c][1]))\n",
    "        ndf = np.sum(np.log(coef * exp),axis=1)\n",
    "        fold_predict_class[:,c] = ndf\n",
    "    pred_test = pd.Series(pd.DataFrame(fold_predict_class).idxmax(axis=1).values,index=input_test_splitloc)\n",
    "    return pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold = 10\n",
    "# overall_match_class = 0\n",
    "# overall_match_class_scikit=0\n",
    "# df_pima,distinct_class=load_dataset(imputer_missing_ind=False) #Load the Dataset\n",
    "# train_splitloc,test_splitloc=train_test_split(df_pima) #Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder: 0 GaussianNaive Bayes Accuracy: 81.04575163398692  Ignore Missing Accuracy:81.04575163398692\n",
      "folder: 1 GaussianNaive Bayes Accuracy: 77.12418300653596  Ignore Missing Accuracy:77.77777777777779\n",
      "folder: 2 GaussianNaive Bayes Accuracy: 69.93464052287581  Ignore Missing Accuracy:69.93464052287581\n",
      "folder: 3 GaussianNaive Bayes Accuracy: 73.8562091503268  Ignore Missing Accuracy:73.8562091503268\n",
      "folder: 4 GaussianNaive Bayes Accuracy: 74.50980392156863  Ignore Missing Accuracy:74.50980392156863\n",
      "folder: 5 GaussianNaive Bayes Accuracy: 73.8562091503268  Ignore Missing Accuracy:73.8562091503268\n",
      "folder: 6 GaussianNaive Bayes Accuracy: 73.8562091503268  Ignore Missing Accuracy:73.8562091503268\n",
      "folder: 7 GaussianNaive Bayes Accuracy: 76.47058823529412  Ignore Missing Accuracy:77.12418300653596\n",
      "folder: 8 GaussianNaive Bayes Accuracy: 76.47058823529412  Ignore Missing Accuracy:76.47058823529412\n",
      "folder: 9 GaussianNaive Bayes Accuracy: 76.47058823529412  Ignore Missing Accuracy:76.47058823529412\n",
      "Gaussian Naive Bayes Average Accuracy: 75.35947712418302  Ignore Missing Accuracy:75.49019607843138\n"
     ]
    }
   ],
   "source": [
    "fold = 10\n",
    "overall_match_class = 0\n",
    "#overall_match_class_scikit=0\n",
    "overall_match_class_ignore_missing=0\n",
    "\n",
    "df_pima,distinct_class=load_dataset() #Load the Dataset\n",
    "train_splitloc,test_splitloc=train_test_split(df_pima) #Split the Dataset\n",
    "\n",
    "for f in range(fold): #For each Fold\n",
    "    match_class = 0\n",
    "    #match_scikit_class = 0\n",
    "    dict_train_mean_stdev=train_class_mean_std(df_pima,train_splitloc[f],impute_ind=False)\n",
    "    dict_train_mean_stdev_ignore_missing=train_class_mean_std(df_pima,train_splitloc[f],impute_ind=True)\n",
    "    #print (\"dict_train_mean_stdev:{}  dict_train_mean_stdev_ignore_missing:{}\".format(dict_train_mean_stdev,dict_train_mean_stdev_ignore_missing))\n",
    "    pred_test_val=gaussian_naive_bayes_pred(test_splitloc[f],dict_train_mean_stdev,distinct_class)\n",
    "    pred_test_val_ignore_missing=gaussian_naive_bayes_pred(test_splitloc[f],dict_train_mean_stdev_ignore_missing,distinct_class)\n",
    "    match_class = (np.sum(np.array(pred_test_val) == df_pima.iloc[test_splitloc[f]]['Class'].values)/len(test_splitloc[f]))*100\n",
    "    match_class_ignore_missing=(np.sum(np.array(pred_test_val_ignore_missing) == df_pima.iloc[test_splitloc[f]]['Class'].values)/len(test_splitloc[f]))*100\n",
    "    overall_match_class += match_class\n",
    "    overall_match_class_ignore_missing += match_class_ignore_missing\n",
    "\n",
    "#         clf = GaussianNB()\n",
    "#         clf.fit(df_pima.iloc[train_splitloc[f]].drop('Class',axis=1),df_pima.iloc[train_splitloc[f]]['Class'])\n",
    "#         pred_test_val_scikit=clf.predict(df_pima.iloc[test_splitloc[f]].drop('Class',axis=1))\n",
    "#         match_class_scikit=(np.sum(pred_test_val_scikit == df_pima.iloc[test_splitloc[f]]['Class'].values)/len(test_splitloc[f]))*100\n",
    "#         overall_match_class_scikit +=match_class_scikit\n",
    "    #print (\"folder: {} GaussianNaive Bayes Accuracy: {}  Scikit Accuracy:{}\".format(f,match_class,match_class_scikit))\n",
    "    print (\"folder: {} GaussianNaive Bayes Accuracy: {}  Ignore Missing Accuracy:{}\".format(f,match_class,match_class_ignore_missing))\n",
    "#print (\"Gaussian Naive Bayes Average Accuracy: {}  Scikit Accuracy:{}\".format(overall_match_class/fold,overall_match_class_scikit/fold))\n",
    "print (\"Gaussian Naive Bayes Average Accuracy: {}  Ignore Missing Accuracy:{}\".format(overall_match_class/fold,overall_match_class_ignore_missing/fold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
