{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    X,Y = mnist[\"data\"],mnist[\"target\"].astype(int)\n",
    "    df_mnist=pd.DataFrame(X)\n",
    "    df_mnist['target'] = Y\n",
    "    distinct_class=pd.Series(Y).unique().astype(int)\n",
    "    return df_mnist,distinct_class\n",
    "\n",
    "def train_test_split(df_input,train_set=60000,print_ind=False):\n",
    "    data_loc=np.arange(df_input.shape[0])\n",
    "    train_splitloc=[data_loc[:60000]]\n",
    "    test_splitloc=[data_loc[60000:]]\n",
    "    return train_splitloc,test_splitloc\n",
    "\n",
    "def priors_calc(df_input):\n",
    "    priors=df_input.iloc[train_splitloc[0]].groupby('target').count()[0]\n",
    "    return priors\n",
    "\n",
    "def mnist_transformed(df_input):\n",
    "    df_mnist_train = (df_input.iloc[train_splitloc[0]].drop('target',axis=1) >= 128).astype(int)\n",
    "    df_mnist_test = (df_input.iloc[test_splitloc[0]].drop('target',axis=1) >= 128).astype(int)\n",
    "    return df_mnist_train,df_mnist_test\n",
    "\n",
    "\n",
    "def mnist_train_summary(df_input_train,df_train_target):\n",
    "    df_input_train['target'] = df_train_target\n",
    "    df_train_summary=df_input_train.groupby('target').sum()\n",
    "    for p in range(len(priors)):\n",
    "        df_train_summary.iloc[p] = (df_train_summary.iloc[p]+0.01)/(priors[p]+0.02)\n",
    "    df_input_train.drop('target',axis=1,inplace=True)\n",
    "    return df_train_summary\n",
    "\n",
    "\n",
    "def train_class_mean_std(input_df,input_train_splitloc,print_ind=False):\n",
    "    dict_train_mean_stdev = {}\n",
    "    eps = 1e-4 #Added a small value in order to avoid the variance to 0 (divisible by zero)\n",
    "    for c in distinct_class:\n",
    "        mean=input_df.iloc[input_train_splitloc][df_mnist.iloc[input_train_splitloc]['target'] == c].describe().loc['mean'][:-1]\n",
    "        stdev=input_df.iloc[input_train_splitloc][df_mnist.iloc[input_train_splitloc]['target'] == c].describe().loc['std'][:-1]+eps\n",
    "        dict_train_mean_stdev[c] = mean,stdev\n",
    "    if (print_ind):\n",
    "        print (\"Len Train:{}. Number of 0:{} 1:{}\".format(len(input_train_splitloc),df_pima.iloc[input_train_splitloc][df_pima.iloc[input_train_splitloc]['Class'] == 0].shape,df_pima.iloc[input_train_splitloc][df_pima.iloc[input_train_splitloc]['Class'] == 1].shape))\n",
    "    return dict_train_mean_stdev\n",
    "\n",
    "def mnist_cropped_func(input_df,width=20,height=20):\n",
    "    i=0\n",
    "    sr_mnist_cropped = []\n",
    "    df_mnist_cropped = pd.DataFrame()\n",
    "    for k in np.array(input_df.drop('target',axis=1)):\n",
    "        x=k.reshape(28,28)\n",
    "        coord=np.argwhere(x)\n",
    "        x0,y0=np.min(coord,axis=0)\n",
    "        x1,y1=np.max(coord,axis=0)\n",
    "        X_cropped=x[x0:x1,y0:y1]\n",
    "        \n",
    "        dim = (width, height)\n",
    "        \n",
    "        X_stretched=cv2.resize(X_cropped, dim, interpolation = cv2.INTER_NEAREST)\n",
    "        X_stretched=X_stretched.reshape(width*height,)\n",
    "        sr_mnist_cropped.append(X_stretched)\n",
    "    #df_sr_mnist_train_cropped=sr_mnist_train_cropped\n",
    "    df_output_mnist_cropped=pd.DataFrame(sr_mnist_cropped)\n",
    "    df_output_mnist_cropped['target'] = df_mnist['target']\n",
    "    return df_output_mnist_cropped\n",
    "\n",
    "\n",
    "def naive_bayes_pred(input_df,input_test_splitloc,input_dict_train_mean_stdev,input_distinct_class):\n",
    "    fold_predict_class = np.zeros((len(input_test_splitloc),len(input_distinct_class)))\n",
    "    for c in input_distinct_class:\n",
    "        exp_nr = -((input_df.iloc[input_test_splitloc].drop('target',axis=1)-np.array(input_dict_train_mean_stdev[c][0]))**2)\n",
    "        exp_dn = (2*((dict_train_mean_stdev[c][1]) ** 2 ))\n",
    "        exp = exp_nr / exp_dn\n",
    "        exp = np.exp(exp)\n",
    "        coef = (1/((np.sqrt(2*np.pi))*input_dict_train_mean_stdev[c][1]))\n",
    "        ndf = np.sum(np.log(coef * exp),axis=1)\n",
    "        fold_predict_class[:,c] = ndf\n",
    "    pred_test = pd.Series(pd.DataFrame(fold_predict_class).idxmax(axis=1).values,index=input_test_splitloc)\n",
    "    return pred_test\n",
    "\n",
    "def naive_bayes_bernoulli(df_input,input_test_splitloc,df_input_mnist_test,df_train_summary):\n",
    "    pred_test_val=np.argmax(np.dot((np.log(1-df_train_summary)),(1-df_input_mnist_test).T)+np.dot((np.log(df_train_summary)),(df_input_mnist_test).T),axis=0)\n",
    "    #np.array(df_input.iloc[test_splitloc[0]]['target'])\n",
    "    return ((np.sum((np.array(df_input.iloc[input_test_splitloc[0]]['target'])) == pred_test_val))/len(input_test_splitloc[0]))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnist,distinct_class=load_mnist_data() #Load the Dataset\n",
    "train_splitloc,test_splitloc=train_test_split(df_mnist)\n",
    "df_mnist_cropped=mnist_cropped_func(df_mnist,20,20)\n",
    "fold=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Untouched Train Accuracy: 53.098333333333336  Test Accuracy:51.89\n"
     ]
    }
   ],
   "source": [
    "for f in range(fold): #For each Fold\n",
    "    match_train_class = 0\n",
    "    match_test_class = 0\n",
    "    dict_train_mean_stdev=train_class_mean_std(df_mnist,train_splitloc[f])\n",
    "    pred_train_val=naive_bayes_pred(df_mnist,train_splitloc[f],dict_train_mean_stdev,distinct_class) # Train Accuracy\n",
    "    pred_test_val=naive_bayes_pred(df_mnist,test_splitloc[f],dict_train_mean_stdev,distinct_class) # Test Accuracy\n",
    "    \n",
    "    match_class_train = np.sum(pred_train_val == df_mnist.iloc[train_splitloc[f]]['target'].values) / len(train_splitloc[0])\n",
    "    match_class_test = np.sum(pred_test_val == df_mnist.iloc[test_splitloc[f]]['target'].values) / len(test_splitloc[0])\n",
    "    print (\"Gaussian Untouched Train Accuracy: {}  Test Accuracy:{}\".format(match_class_train*100,match_class_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Untouched Train Accuracy: 81.11666666666667  Test Accuracy:82.38\n"
     ]
    }
   ],
   "source": [
    "for f in range(fold): #For each Fold\n",
    "    match_train_class = 0\n",
    "    match_test_class = 0\n",
    "    dict_train_mean_stdev=train_class_mean_std(df_mnist_cropped,train_splitloc[f])\n",
    "    pred_train_val=naive_bayes_pred(df_mnist_cropped,train_splitloc[f],dict_train_mean_stdev,distinct_class) # Train Accuracy\n",
    "    pred_test_val=naive_bayes_pred(df_mnist_cropped,test_splitloc[f],dict_train_mean_stdev,distinct_class) # Test Accuracy\n",
    "    match_class_train = np.sum(pred_train_val == df_mnist_cropped.iloc[train_splitloc[f]]['target'].values) / len(train_splitloc[0])\n",
    "    match_class_test = np.sum(pred_test_val == df_mnist_cropped.iloc[test_splitloc[f]]['target'].values) / len(test_splitloc[0])\n",
    "    print (\"Gaussian Stretched Train Accuracy: {}  Test Accuracy:{}\".format(match_class_train*100,match_class_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Bernouilli - Untouched Train Accuracy:83.71\n",
      "NB Bernouilli - Untouched Test Accuracy:84.38\n"
     ]
    }
   ],
   "source": [
    "priors = priors_calc(df_mnist)\n",
    "df_mnist_train,df_mnist_test=mnist_transformed(df_mnist)\n",
    "df_mnist_train_summary=mnist_train_summary(df_mnist_train,df_mnist['target'])\n",
    "print (\"NB Bernouilli - Untouched Train Accuracy:{}\".format(naive_bayes_bernoulli(df_mnist,train_splitloc,df_mnist_train,df_mnist_train_summary)))\n",
    "print (\"NB Bernouilli - Untouched Test Accuracy:{}\".format(naive_bayes_bernoulli(df_mnist,test_splitloc,df_mnist_test,df_mnist_train_summary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Bernouilli - Stretched Train Accuracy:81.81\n",
      "NB Bernouilli - Stretched Test Accuracy:83.15\n"
     ]
    }
   ],
   "source": [
    "priors = priors_calc(df_mnist)\n",
    "df_mnist_train,df_mnist_test=mnist_transformed(df_mnist_cropped)\n",
    "df_mnist_train_summary=mnist_train_summary(df_mnist_train,df_mnist_cropped['target'])\n",
    "print (\"NB Bernouilli - Stretched Train Accuracy:{}\".format(naive_bayes_bernoulli(df_mnist_cropped,train_splitloc,df_mnist_train,df_mnist_train_summary)))\n",
    "print (\"NB Bernouilli - Stretched Test Accuracy:{}\".format(naive_bayes_bernoulli(df_mnist_cropped,test_splitloc,df_mnist_test,df_mnist_train_summary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forrest - Untouched Tree:10 Depth:4  Train Accuracy:75.50666666666666 Test Accuracy:75.46000000000001\n",
      "Random Forrest - Stretched Tree:10 Depth:4  Train Accuracy:74.815 Test Accuracy:75.99000000000001\n",
      "Random Forrest - Untouched Tree:10 Depth:16  Train Accuracy:99.57833333333333 Test Accuracy:94.71000000000001\n",
      "Random Forrest - Stretched Tree:10 Depth:16  Train Accuracy:99.75333333333334 Test Accuracy:95.49\n",
      "Random Forrest - Untouched Tree:30 Depth:4  Train Accuracy:80.93166666666667 Test Accuracy:81.22\n",
      "Random Forrest - Stretched Tree:30 Depth:4  Train Accuracy:79.10666666666667 Test Accuracy:80.23\n",
      "Random Forrest - Untouched Tree:30 Depth:16  Train Accuracy:99.74833333333333 Test Accuracy:96.39\n",
      "Random Forrest - Stretched Tree:30 Depth:16  Train Accuracy:99.86333333333334 Test Accuracy:96.67999999999999\n"
     ]
    }
   ],
   "source": [
    "#Predict for Random Forrest\n",
    "for t in [10,30]: #Tree Iteration\n",
    "    for d in [4,16]: #Depth Iteration\n",
    "        #print (\"Processing for Tree:{} Depth:{}\".format(t,d))\n",
    "        clf=RandomForestClassifier(n_estimators=t,max_depth=d)\n",
    "        clf.fit(X=df_mnist.drop('target',axis=1).iloc[train_splitloc[0]],y=df_mnist['target'].iloc[train_splitloc[0]])\n",
    "        rand_forrest_train_pred=clf.predict(df_mnist.drop('target',axis=1).iloc[train_splitloc[0]])\n",
    "        rand_forrest_test_pred=clf.predict(df_mnist.drop('target',axis=1).iloc[test_splitloc[0]])\n",
    "        rand_forrest_train_percent=(np.sum(np.array(df_mnist.iloc[train_splitloc[0]]['target']) == rand_forrest_train_pred).astype(int)/df_mnist.iloc[train_splitloc[0]].shape[0])*100\n",
    "        rand_forrest_test_percent=(np.sum(np.array(df_mnist.iloc[test_splitloc[0]]['target']) == rand_forrest_test_pred).astype(int)/df_mnist.iloc[test_splitloc[0]].shape[0])*100\n",
    "        print (\"Random Forrest - Untouched Tree:{} Depth:{}  Train Accuracy:{} Test Accuracy:{}\".format(t,d,rand_forrest_train_percent,rand_forrest_test_percent))\n",
    "        \n",
    "        clf_cropped=RandomForestClassifier(n_estimators=t,max_depth=d)\n",
    "        clf_cropped.fit(X=df_mnist_cropped.drop('target',axis=1).iloc[train_splitloc[0]],y=df_mnist_cropped['target'].iloc[train_splitloc[0]])\n",
    "        cropped_rand_forrest_train_pred=clf_cropped.predict(df_mnist_cropped.drop('target',axis=1).iloc[train_splitloc[0]])\n",
    "        cropped_rand_forrest_test_pred=clf_cropped.predict(df_mnist_cropped.drop('target',axis=1).iloc[test_splitloc[0]])\n",
    "        cropped_rand_forrest_train_percent=(np.sum(np.array(df_mnist_cropped.iloc[train_splitloc[0]]['target']) == cropped_rand_forrest_train_pred).astype(int)/df_mnist.iloc[train_splitloc[0]].shape[0])*100\n",
    "        cropped_rand_forrest_test_percent=(np.sum(np.array(df_mnist_cropped.iloc[test_splitloc[0]]['target']) == cropped_rand_forrest_test_pred).astype(int)/df_mnist.iloc[test_splitloc[0]].shape[0])*100\n",
    "        print (\"Random Forrest - Stretched Tree:{} Depth:{}  Train Accuracy:{} Test Accuracy:{}\".format(t,d,cropped_rand_forrest_train_percent,cropped_rand_forrest_test_percent))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
