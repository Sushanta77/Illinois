{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    X,Y = mnist[\"data\"],mnist[\"target\"].astype(int)\n",
    "    df_mnist=pd.DataFrame(X)\n",
    "    df_mnist['target'] = Y\n",
    "    distinct_class=pd.Series(Y).unique().astype(int)\n",
    "    return df_mnist,distinct_class\n",
    "\n",
    "def train_test_split(df_input,train_set=60000,print_ind=False):\n",
    "    data_loc=np.arange(df_input.shape[0])\n",
    "    train_splitloc=[data_loc[:60000]]\n",
    "    test_splitloc=[data_loc[60000:]]\n",
    "    return train_splitloc,test_splitloc\n",
    "\n",
    "def priors_calc(df_input):\n",
    "    priors=df_input.iloc[train_splitloc[0]].groupby('target').count()[0]\n",
    "    return priors\n",
    "\n",
    "def mnist_transformed(df_input):\n",
    "    df_mnist_train = (df_input.iloc[train_splitloc[0]].drop('target',axis=1) >= 128).astype(int)\n",
    "    df_mnist_test = (df_input.iloc[test_splitloc[0]].drop('target',axis=1) >= 128).astype(int)\n",
    "    return df_mnist_train,df_mnist_test\n",
    "\n",
    "def mnist_train_summary(df_input_train,df_train_target):\n",
    "    #df_mnist_train['target'] = df_mnist['target']\n",
    "    df_input_train['target'] = df_train_target\n",
    "    df_train_summary=df_input_train.groupby('target').sum()\n",
    "    for p in range(len(priors)):\n",
    "        df_train_summary.iloc[p] = (df_train_summary.iloc[p]+0.01)/(priors[p]+0.02)\n",
    "    return df_train_summary\n",
    "\n",
    "\n",
    "def train_class_mean_std(input_train_splitloc,print_ind=False):\n",
    "    dict_train_mean_stdev = {}\n",
    "    eps = 1e-4 #Added a small value in order to avoid the variance to 0 (divisible by zero)\n",
    "    for c in distinct_class:\n",
    "        #print (\"Running for the Class: {}\".format(c))\n",
    "        mean=df_mnist.iloc[input_train_splitloc][df_mnist.iloc[input_train_splitloc]['target'] == c].describe().loc['mean'][:-1]\n",
    "        stdev=df_mnist.iloc[input_train_splitloc][df_mnist.iloc[input_train_splitloc]['target'] == c].describe().loc['std'][:-1]+eps\n",
    "        dict_train_mean_stdev[c] = mean,stdev\n",
    "    if (print_ind):\n",
    "        print (\"Len Train:{}. Number of 0:{} 1:{}\".format(len(input_train_splitloc),df_pima.iloc[input_train_splitloc][df_pima.iloc[input_train_splitloc]['Class'] == 0].shape,df_pima.iloc[input_train_splitloc][df_pima.iloc[input_train_splitloc]['Class'] == 1].shape))\n",
    "    return dict_train_mean_stdev\n",
    "\n",
    "def mnist_cropped_func(input_df,width=20,height=20):\n",
    "    i=0\n",
    "    sr_mnist_cropped = []\n",
    "    df_mnist_cropped = pd.DataFrame()\n",
    "    for k in np.array(input_df.drop('target',axis=1)):\n",
    "        x=k.reshape(28,28)\n",
    "        coord=np.argwhere(x)\n",
    "        x0,y0=np.min(coord,axis=0)\n",
    "        x1,y1=np.max(coord,axis=0)\n",
    "        X_cropped=x[x0:x1,y0:y1]\n",
    "        \n",
    "        dim = (width, height)\n",
    "        \n",
    "        X_stretched=cv2.resize(X_cropped, dim, interpolation = cv2.INTER_NEAREST)\n",
    "        X_stretched=X_stretched.reshape(width*height,)\n",
    "        sr_mnist_cropped.append(X_stretched)\n",
    "    #df_sr_mnist_train_cropped=sr_mnist_train_cropped\n",
    "    df_output_mnist_cropped=pd.DataFrame(sr_mnist_cropped)\n",
    "    df_output_mnist_cropped['target'] = df_mnist['target']\n",
    "    return df_output_mnist_cropped\n",
    "\n",
    "\n",
    "def naive_bayes_pred(input_test_splitloc,input_dict_train_mean_stdev,input_distinct_class):\n",
    "    fold_predict_class = np.zeros((len(input_test_splitloc),len(input_distinct_class)))\n",
    "    for c in input_distinct_class:\n",
    "        exp_nr = -((df_mnist.iloc[input_test_splitloc].drop('target',axis=1)-np.array(input_dict_train_mean_stdev[c][0]))**2)\n",
    "        exp_dn = (2*((dict_train_mean_stdev[c][1]) ** 2 ))\n",
    "        exp = exp_nr / exp_dn\n",
    "        exp = np.exp(exp)\n",
    "        coef = (1/((np.sqrt(2*np.pi))*input_dict_train_mean_stdev[c][1]))\n",
    "        ndf = np.sum(np.log(coef * exp),axis=1)\n",
    "        fold_predict_class[:,c] = ndf\n",
    "    pred_test = pd.Series(pd.DataFrame(fold_predict_class).idxmax(axis=1).values,index=input_test_splitloc)\n",
    "    return pred_test\n",
    "\n",
    "def naive_bayes_bernoulli(df_input,input_test_splitloc,df_input_mnist_test,df_train_summary):\n",
    "    pred_test_val=np.argmax(np.dot((np.log(1-df_train_summary)),(1-df_input_mnist_test).T)+np.dot((np.log(df_train_summary)),(df_input_mnist_test).T),axis=0)\n",
    "    #np.array(df_input.iloc[test_splitloc[0]]['target'])\n",
    "    return np.sum((np.array(df_input.iloc[input_test_splitloc[0]]['target'])) == pred_test_val)/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnist,distinct_class=load_mnist_data() #Load the Dataset\n",
    "train_splitloc,test_splitloc=train_test_split(df_mnist)\n",
    "fold=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder: 0 Train Accuracy: 53.098333333333336  Test Accuracy:51.89\n"
     ]
    }
   ],
   "source": [
    "for f in range(fold): #For each Fold\n",
    "    match_train_class = 0\n",
    "    match_test_class = 0\n",
    "    dict_train_mean_stdev=train_class_mean_std(train_splitloc[f])\n",
    "    pred_train_val=naive_bayes_pred(train_splitloc[f],dict_train_mean_stdev,distinct_class) # Train Accuracy\n",
    "    pred_test_val=naive_bayes_pred(test_splitloc[f],dict_train_mean_stdev,distinct_class) # Test Accuracy\n",
    "\n",
    "    for train_val_loc in train_splitloc[f]:\n",
    "        #print (\"Fold:{} Train Loc:{} Pred:{}  Act:{}\".format(f,train_val_loc,pred_test_val[train_val_loc],df_mnist.iloc[train_val_loc][-1]))\n",
    "        if pred_train_val[train_val_loc] == df_mnist.iloc[train_val_loc][-1]:\n",
    "            match_train_class += 1\n",
    "\n",
    "    for test_val_loc in test_splitloc[f]:\n",
    "        #print (\"Fold:{} Test Loc:{} Pred:{}  Act:{}\".format(f,test_val_loc,pred_test_val[test_val_loc],df_mnist.iloc[test_val_loc][-1]))\n",
    "        if pred_test_val[test_val_loc] == df_mnist.iloc[test_val_loc][-1]:\n",
    "            match_test_class += 1\n",
    "\n",
    "    print (\"folder: {} Train Accuracy: {}  Test Accuracy:{}\".format(f,(match_train_class/len(train_splitloc[f]))*100,(match_test_class/len(test_splitloc[f]))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.38"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#priors=df_mnist.iloc[train_splitloc[0]].groupby('target').count()[0]\n",
    "priors = priors_calc(df_mnist)\n",
    "df_mnist_train,df_mnist_test=mnist_transformed(df_mnist)\n",
    "\n",
    "# df_mnist_train['target'] = df_mnist['target']\n",
    "# df_mnist_train_summary=df_mnist_train.groupby('target').sum()\n",
    "# for p in range(len(priors)):\n",
    "#     df_mnist_train_summary.iloc[p] = (df_mnist_train_summary.iloc[p]+0.01)/(priors[p]+0.02)\n",
    "\n",
    "df_mnist_train_summary=mnist_train_summary(df_mnist_train,df_mnist['target'])\n",
    "\n",
    "naive_bayes_bernoulli(df_mnist,test_splitloc,df_mnist_test,df_mnist_train_summary)\n",
    "\n",
    "# pred_test_val=np.argmax(np.dot((np.log(1-df_mnist_train_summary)),(1-df_mnist_test).T)+np.dot((np.log(df_mnist_train_summary)),(df_mnist_test).T),axis=0)\n",
    "# np.array(df_mnist.iloc[test_splitloc[0]]['target'])\n",
    "# np.sum((np.array(df_mnist.iloc[test_splitloc[0]]['target'])) == pred_test_val)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnist_cropped=mnist_cropped_func(df_mnist,20,20)\n",
    "\n",
    "# i=0\n",
    "# sr_mnist_cropped = []\n",
    "# df_mnist_cropped = pd.DataFrame()\n",
    "# for k in np.array(df_mnist.drop('target',axis=1)):\n",
    "#     x=k.reshape(28,28)\n",
    "#     coord=np.argwhere(x)\n",
    "#     x0,y0=np.min(coord,axis=0)\n",
    "#     x1,y1=np.max(coord,axis=0)\n",
    "#     X_cropped=x[x0:x1,y0:y1]\n",
    "    \n",
    "#     width = 20\n",
    "#     height = 20\n",
    "#     dim = (width, height)\n",
    "\n",
    "#     X_stretched=cv2.resize(X_cropped, dim, interpolation = cv2.INTER_NEAREST)\n",
    "#     X_stretched=X_stretched.reshape(width*height,)\n",
    "#     sr_mnist_cropped.append(X_stretched)\n",
    "#     #df_sr_mnist_train_cropped=sr_mnist_train_cropped\n",
    "# df_mnist_cropped=pd.DataFrame(sr_mnist_cropped)\n",
    "# df_mnist_cropped['target'] = df_mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mnist_cropped_train,df_mnist_cropped_test=mnist_transformed(df_mnist_cropped)\n",
    "df_mnist_cropped_train_summary=mnist_train_summary(df_mnist_cropped_train,df_mnist['target'])\n",
    "naive_bayes_bernoulli(df_mnist_cropped,test_splitloc,df_mnist_cropped_test,df_mnist_cropped_train_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mnist_transformed = (df_mnist_cropped.iloc[train_splitloc[0]].drop('target',axis=1) >= 128).astype(int)\n",
    "# df_mnist_test = (df_mnist_cropped.iloc[test_splitloc[0]].drop('target',axis=1) >= 128).astype(int)\n",
    "# df_mnist_transformed['target'] = df_mnist_cropped['target']\n",
    "# df_mnist_transformed_summary=df_mnist_transformed.groupby('target').sum()\n",
    "# for p in range(len(priors)):\n",
    "#     df_mnist_transformed_summary.iloc[p] = (df_mnist_transformed_summary.iloc[p]+0.01)/(priors[p]+0.02)\n",
    "\n",
    "# pred_test_val=np.argmax(np.dot((np.log(1-df_mnist_transformed_summary)),(1-df_mnist_test).T)+np.dot((np.log(df_mnist_transformed_summary)),(df_mnist_test).T),axis=0)\n",
    "# np.array(df_mnist.iloc[test_splitloc[0]]['target'])\n",
    "# np.sum((np.array(df_mnist.iloc[test_splitloc[0]]['target'])) == pred_test_val)/100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
