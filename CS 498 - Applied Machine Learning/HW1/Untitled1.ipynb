{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_class_mean_std(input_df,input_train_splitloc,impute_ind=False):\n",
    "    dict_train_mean_stdev_calc = {}\n",
    "    dict_train_mean_stdev_impute_calc = {}\n",
    "    for c in distinct_class:\n",
    "        df_pima_train_set = input_df.iloc[input_train_splitloc][input_df.iloc[input_train_splitloc]['Class'] == c]\n",
    "        if (impute_ind):\n",
    "            df_pima_train_set['BloodPressure']=df_pima_train_set['BloodPressure'].replace(0,np.NAN) #impute to NAN, so it won't used in mean/std\n",
    "            df_pima_train_set['SkinThickness']=df_pima_train_set['SkinThickness'].replace(0,np.NAN) #impute to NAN, so it won't used in mean/std\n",
    "            df_pima_train_set['BMI']=df_pima_train_set['BMI'].replace(0,np.NAN) #impute to NAN, so it won't used in mean/std\n",
    "            df_pima_train_set['Age']=df_pima_train_set['Age'].replace(0,np.NAN) #impute to NAN, so it won't used in mean/std\n",
    "        mean=df_pima_train_set.describe().loc['mean'][:-1]\n",
    "        stdev=df_pima_train_set.describe().loc['std'][:-1]\n",
    "        dict_train_mean_stdev_calc[c] = mean,stdev\n",
    "    return dict_train_mean_stdev_calc\n",
    "\n",
    "\n",
    "def gaussian_naive_bayes_pred(input_test_splitloc,input_dict_train_mean_stdev,input_distinct_class):\n",
    "    fold_predict_class = np.zeros((len(input_test_splitloc),len(input_distinct_class)))\n",
    "    for c in input_distinct_class:\n",
    "        exp_nr = -((data.iloc[input_test_splitloc].drop('Class',axis=1)-np.array(input_dict_train_mean_stdev[c][0]))**2)\n",
    "        exp_dn = (2*((dict_train_mean_stdev[c][1]) ** 2 ))\n",
    "        exp = exp_nr / exp_dn\n",
    "        exp = np.exp(exp)\n",
    "        coef = (1/((np.sqrt(2*np.pi))*input_dict_train_mean_stdev[c][1]))\n",
    "        ndf = np.sum(np.log(coef * exp),axis=1)\n",
    "        fold_predict_class[:,c] = ndf\n",
    "    pred_test = pd.Series(pd.DataFrame(fold_predict_class).idxmax(axis=1).values,index=input_test_splitloc)\n",
    "    return pred_test\n",
    "\n",
    "\n",
    "def train_test_split(input_df=None,fold=10,print_ind=False,train_split=80):\n",
    "    train_splitloc = []\n",
    "    test_splitloc  = []\n",
    "    train_end_loc = np.round(input_df.shape[0]*(train_split/100)).astype(int)\n",
    "    for f in range(fold):\n",
    "        loc_arr = np.arange(input_df.shape[0])\n",
    "        np.random.shuffle(loc_arr)\n",
    "        train_splitloc.append(loc_arr[:train_end_loc])\n",
    "        test_splitloc.append(loc_arr[train_end_loc:])\n",
    "    return train_splitloc,test_splitloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder: Gaussian NB Accuracy: 74.67532467532467  Ignore Missing Accuracy:74.67532467532467\n",
      "folder: Gaussian NB Accuracy: 69.48051948051948  Ignore Missing Accuracy:69.48051948051948\n",
      "folder: Gaussian NB Accuracy: 73.20261437908496  Ignore Missing Accuracy:73.8562091503268\n",
      "folder: Gaussian NB Accuracy: 79.73856209150327  Ignore Missing Accuracy:79.73856209150327\n",
      "folder: Gaussian NB Accuracy: 75.16339869281046  Ignore Missing Accuracy:75.81699346405229\n",
      "Gaussian NB Average Accuracy: 74.45208386384857  Ignore Missing Accuracy:74.7135217723453\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/pima-indians-diabetes.csv\")\n",
    "data.columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Class']\n",
    "\n",
    "X = data.drop('Class',axis = 1)\n",
    "y = data['Class']\n",
    "\n",
    "distinct_class=y.unique()\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "no_fold = 5\n",
    "kfold = KFold(no_fold,random_state = 1234)\n",
    "\n",
    "overall_match_class = 0\n",
    "overall_match_class_ignore_missing=0\n",
    "for (train_idx, test_idx) in (kfold.split(data)):\n",
    "    #print (\"Processing for Train:{} Test:{}\".format(len(train_idx), len(test_idx)))\n",
    "    #dict_train_mean_stdev = train_class_mean_std(data,train_idx)\n",
    "    dict_train_mean_stdev = train_class_mean_std(data,train_idx,impute_ind=False)\n",
    "    dict_train_mean_stdev_ignore_missing=train_class_mean_std(data,train_idx,impute_ind=True)\n",
    "    \n",
    "    #pred = gaussian_naive_bayes_pred(test_idx,dict_train_mean_stdev,distinct_class)\n",
    "    \n",
    "    pred_test_val=gaussian_naive_bayes_pred(test_idx,dict_train_mean_stdev,distinct_class)\n",
    "    \n",
    "    pred_test_val_ignore_missing=gaussian_naive_bayes_pred(test_idx,dict_train_mean_stdev_ignore_missing,distinct_class)\n",
    "    \n",
    "    match_class = (np.sum(np.array(pred_test_val) == data.iloc[test_idx]['Class'].values)/len(test_idx))*100\n",
    "    \n",
    "    match_class_ignore_missing=(np.sum(np.array(pred_test_val_ignore_missing) == data.iloc[test_idx]['Class'].values)/len(test_idx))*100\n",
    "    \n",
    "    overall_match_class += match_class\n",
    "    \n",
    "    overall_match_class_ignore_missing += match_class_ignore_missing\n",
    "    \n",
    "    \n",
    "    #print (match_class)\n",
    "    print (\"folder: Gaussian NB Accuracy: {}  Ignore Missing Accuracy:{}\".format(match_class,match_class_ignore_missing))\n",
    "#print (overall_match_class/no_fold)\n",
    "print (\"Gaussian NB Average Accuracy: {}  Ignore Missing Accuracy:{}\".format(overall_match_class/no_fold,overall_match_class_ignore_missing/no_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=10, random_state=1234, shuffle=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_fold = 10\n",
    "kfold = KFold(no_fold,random_state = 1234)\n",
    "kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184\n",
      " 185 186 187 188 189 190 191 192 193 194 195 196] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184\n",
      " 185 186 187 188 189 190 191 192 193 194 195 196] [77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96]\n",
      "[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] [154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171\n",
      " 172 173]\n",
      "[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] [231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248\n",
      " 249 250]\n",
      "[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] [308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325\n",
      " 326 327]\n",
      "[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] [385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402\n",
      " 403 404]\n",
      "[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] [462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479\n",
      " 480 481]\n",
      "[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] [539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
      " 557 558]\n",
      "[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] [615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632\n",
      " 633 634]\n",
      "[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] [691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708\n",
      " 709 710]\n"
     ]
    }
   ],
   "source": [
    "#print (data.shape[0])\n",
    "#print (data.shape[0]*80/100)\n",
    "for (train_idx, test_idx) in (kfold.split(data)):\n",
    "    #print (len(train_idx),len(test_idx))\n",
    "    print (train_idx[90:120], test_idx[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614 153\n",
      "614 153\n",
      "614 153\n",
      "614 153\n",
      "614 153\n"
     ]
    }
   ],
   "source": [
    "train_idx,test_idx=train_test_split(data)\n",
    "print (len(train_idx[0]),len(test_idx[0]))\n",
    "print (len(train_idx[1]),len(test_idx[1]))\n",
    "print (len(train_idx[2]),len(test_idx[2]))\n",
    "print (len(train_idx[3]),len(test_idx[3]))\n",
    "print (len(train_idx[4]),len(test_idx[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushanta/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx in test_idx[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
       "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
       "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
       "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
       "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
       "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
       "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
       "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
       "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
       "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
       "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
       "       611, 612, 613])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([305, 190,  77,  63, 237, 160, 578, 732, 672,  98, 745, 450, 696,\n",
       "       280, 703, 345, 701, 149,   1, 284, 264,  31, 435, 351, 646,  97,\n",
       "       613, 269, 384, 292, 460, 485, 622,  38, 631,  85, 171, 614, 763,\n",
       "       551, 749, 226, 125, 727, 680,  52, 462, 105, 321,  30, 162, 286,\n",
       "       665, 498, 710,  50, 431, 313, 329, 252, 494, 387, 714, 607, 575,\n",
       "       681, 560, 418, 495, 331, 589, 250, 164, 618, 486, 210, 133, 116,\n",
       "       207, 751, 558, 541, 532, 103, 371, 702, 166, 419, 657,  93, 258,\n",
       "        91, 139,  69,  17, 605,  12, 456, 529, 163, 294,  22, 448, 506,\n",
       "       201, 608, 328, 726, 362, 309, 570, 142,  71,  86, 567, 373, 620,\n",
       "        16, 521, 221, 283, 636, 583, 469,  54, 759, 765, 644, 479,  84,\n",
       "       629, 156, 174, 585, 199,  60, 401, 679,  36, 303, 184, 325,  24,\n",
       "        78,   3, 159, 120, 118, 761, 553, 251, 678, 343, 634,  81, 516,\n",
       "       266, 122, 598, 323, 738, 234, 101, 650, 452, 561, 119, 588, 281,\n",
       "       647, 189, 730, 220, 378, 202, 599, 509,  20, 244, 232, 324, 128,\n",
       "       411, 353, 721, 219, 698,  70, 255, 260, 466, 533, 123, 214, 233,\n",
       "       638, 104,   6, 548,  80, 449, 517, 347, 180,  44, 413, 358, 200,\n",
       "       713, 457, 677, 145, 229, 667, 739,  66,  95, 288, 218, 695, 155,\n",
       "       215, 611, 463, 254, 750, 277, 194, 715, 388,  68,  33, 302, 140,\n",
       "        96, 513, 192, 643, 683, 740,  13, 552, 656, 510, 400, 185, 675,\n",
       "       261, 319, 754, 500, 491, 577, 338, 616, 655, 146, 483,  99, 117,\n",
       "       153, 467, 297, 568, 630, 430, 134, 227, 682, 391, 276, 337, 228,\n",
       "        47, 621, 386,  32,   5, 317,  87, 130, 663, 716, 753, 549, 423,\n",
       "       148, 444, 398, 744, 263, 349, 267, 709, 131, 296, 365, 376, 175,\n",
       "       432, 374, 205, 427, 108, 106, 249, 318, 236,  72, 708, 291, 720,\n",
       "       519,  67, 434, 339, 729, 275, 330, 322, 235, 569, 579, 592, 216,\n",
       "        29,  89, 593, 584,  48, 364, 760,  21, 697, 408, 361, 625, 626,\n",
       "       473, 734,  65, 213, 717,  14, 572, 293, 547, 503, 256, 169, 539,\n",
       "       360, 285, 368, 172, 271, 424,  76, 206, 181, 590, 295, 474, 550,\n",
       "       651,  45, 274, 602, 135, 397,  19, 446, 733, 502,  58, 278, 183,\n",
       "       603, 417, 372, 126, 706, 694, 355, 562, 379,  23, 617, 377, 161,\n",
       "       531, 440, 764, 475, 748, 478,   2, 660, 380, 686, 606, 415, 653,\n",
       "       268, 741, 320, 410, 344, 742, 170,   0, 477, 676,  57, 755,  56,\n",
       "        90, 530, 707, 136, 127, 556,  39, 333, 109, 464, 441, 489, 461,\n",
       "       407, 662, 711, 493, 354, 451, 668, 476, 138, 173, 150, 439, 196,\n",
       "        25, 442, 392, 375, 674, 445, 654, 157,  51, 402, 525, 470, 179,\n",
       "       595, 382, 544, 158, 640, 526,  83, 596, 704, 540, 518, 480, 177,\n",
       "       223, 113, 406, 455,  88, 187, 619, 100, 366, 522, 523,  11, 757,\n",
       "       766,  15, 574, 314, 633, 399,  49, 426, 248, 649,  61, 609, 428,\n",
       "       542, 747, 340, 110, 359, 724, 687, 310,  10, 346, 564, 188, 107,\n",
       "       414, 151, 718, 289, 685, 137, 645, 507, 752, 627, 536, 571, 265,\n",
       "       195, 193,  64, 381, 692, 488, 520, 597, 610,  55, 538, 144, 642,\n",
       "       743, 222, 514, 459, 409, 487, 586, 114, 143,   8, 287, 217, 641,\n",
       "       211, 582,   7,  53, 290,  94, 191, 587, 282, 447, 273, 746, 669,\n",
       "       438, 581, 433, 700, 545, 308, 115, 259,  62, 492, 465, 472, 334,\n",
       "       390, 262, 648, 443, 691, 240, 393, 209, 671, 490, 573, 352, 363,\n",
       "       246, 481, 527, 591, 279, 332, 421, 705, 370, 178, 121, 132, 326,\n",
       "       369, 383, 403, 623, 505, 168, 537, 659, 154, 594, 307, 546, 420,\n",
       "       736, 693, 534])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder: Gaussian NB Accuracy: 79.73856209150327  Ignore Missing Accuracy:78.43137254901961\n",
      "folder: Gaussian NB Accuracy: 71.24183006535948  Ignore Missing Accuracy:70.58823529411765\n",
      "folder: Gaussian NB Accuracy: 75.81699346405229  Ignore Missing Accuracy:75.81699346405229\n",
      "folder: Gaussian NB Accuracy: 69.93464052287581  Ignore Missing Accuracy:69.28104575163398\n",
      "folder: Gaussian NB Accuracy: 71.24183006535948  Ignore Missing Accuracy:70.58823529411765\n",
      "folder: Gaussian NB Accuracy: 69.93464052287581  Ignore Missing Accuracy:69.93464052287581\n",
      "folder: Gaussian NB Accuracy: 73.20261437908496  Ignore Missing Accuracy:73.20261437908496\n",
      "folder: Gaussian NB Accuracy: 69.28104575163398  Ignore Missing Accuracy:67.97385620915033\n",
      "folder: Gaussian NB Accuracy: 76.47058823529412  Ignore Missing Accuracy:77.12418300653596\n",
      "folder: Gaussian NB Accuracy: 72.54901960784314  Ignore Missing Accuracy:73.20261437908496\n",
      "Gaussian NB Average Accuracy: 72.94117647058823  Ignore Missing Accuracy:72.61437908496733\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/pima-indians-diabetes.csv\")\n",
    "data.columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Class']\n",
    "\n",
    "X = data.drop('Class',axis = 1)\n",
    "y = data['Class']\n",
    "\n",
    "distinct_class=y.unique()\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "no_fold = 10\n",
    "kfold = KFold(no_fold,random_state = 1234)\n",
    "\n",
    "overall_match_class = 0\n",
    "overall_match_class_ignore_missing=0\n",
    "\n",
    "train_idx,test_idx=train_test_split(data) #Split the Dataset\n",
    "\n",
    "#for (train_idx, test_idx) in (kfold.split(data)):\n",
    "for f in (range(no_fold)):\n",
    "    #print (\"Processing for Train:{} Test:{}\".format(len(train_idx), len(test_idx)))\n",
    "    #dict_train_mean_stdev = train_class_mean_std(data,train_idx)\n",
    "    dict_train_mean_stdev = train_class_mean_std(data,train_idx[f],impute_ind=False)\n",
    "    dict_train_mean_stdev_ignore_missing=train_class_mean_std(data,train_idx[f],impute_ind=True)\n",
    "    \n",
    "    #pred = gaussian_naive_bayes_pred(test_idx,dict_train_mean_stdev,distinct_class)\n",
    "    \n",
    "    pred_test_val=gaussian_naive_bayes_pred(test_idx[f],dict_train_mean_stdev,distinct_class)\n",
    "    \n",
    "    pred_test_val_ignore_missing=gaussian_naive_bayes_pred(test_idx[f],dict_train_mean_stdev_ignore_missing,distinct_class)\n",
    "    \n",
    "    match_class = (np.sum(np.array(pred_test_val) == data.iloc[test_idx[f]]['Class'].values)/len(test_idx[f]))*100\n",
    "    \n",
    "    match_class_ignore_missing=(np.sum(np.array(pred_test_val_ignore_missing) == data.iloc[test_idx[f]]['Class'].values)/len(test_idx[f]))*100\n",
    "    \n",
    "    overall_match_class += match_class\n",
    "    \n",
    "    overall_match_class_ignore_missing += match_class_ignore_missing\n",
    "    \n",
    "    \n",
    "    #print (match_class)\n",
    "    print (\"folder: Gaussian NB Accuracy: {}  Ignore Missing Accuracy:{}\".format(match_class,match_class_ignore_missing))\n",
    "#print (overall_match_class/no_fold)\n",
    "print (\"Gaussian NB Average Accuracy: {}  Ignore Missing Accuracy:{}\".format(overall_match_class/no_fold,overall_match_class_ignore_missing/no_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.49384825700615\n"
     ]
    }
   ],
   "source": [
    "#K FOLD\n",
    "data = pd.read_csv(\"data/pima-indians-diabetes.csv\")\n",
    "data.columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Class']\n",
    "\n",
    "X = data.drop('Class',axis = 1)\n",
    "y = data['Class']\n",
    "\n",
    "distinct_class=y.unique()\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "no_fold = 10\n",
    "kfold = KFold(no_fold,random_state = 1234)\n",
    "\n",
    "match_class = 0\n",
    "overall_match_class = 0\n",
    "for (train_idx, test_idx) in (kfold.split(data)):\n",
    "    #print (\"Processing for Train:{} Test:{}\".format(len(train_idx), len(test_idx)))\n",
    "    nb_clf.fit(X.iloc[train_idx],y.iloc[train_idx])\n",
    "    pred = nb_clf.predict(X.iloc[test_idx])\n",
    "    match_class = sum(pred == y.iloc[test_idx])/len(test_idx)*100\n",
    "    overall_match_class += match_class\n",
    "    #print (match_class)\n",
    "print (overall_match_class/no_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>146</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>75</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>8</td>\n",
       "      <td>167</td>\n",
       "      <td>106</td>\n",
       "      <td>46</td>\n",
       "      <td>231</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.165</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>9</td>\n",
       "      <td>145</td>\n",
       "      <td>80</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.637</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>6</td>\n",
       "      <td>115</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.245</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>132</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.217</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.235</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>10</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.141</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>6</td>\n",
       "      <td>98</td>\n",
       "      <td>58</td>\n",
       "      <td>33</td>\n",
       "      <td>190</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.430</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>9</td>\n",
       "      <td>154</td>\n",
       "      <td>78</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.164</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>6</td>\n",
       "      <td>165</td>\n",
       "      <td>68</td>\n",
       "      <td>26</td>\n",
       "      <td>168</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.631</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0.551</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>106</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.285</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>240</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.880</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>8</td>\n",
       "      <td>91</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0.587</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>6</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.328</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>9</td>\n",
       "      <td>156</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0.230</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.263</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>3</td>\n",
       "      <td>121</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.127</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>58</td>\n",
       "      <td>17</td>\n",
       "      <td>265</td>\n",
       "      <td>24.2</td>\n",
       "      <td>0.614</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>24.2</td>\n",
       "      <td>0.332</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>76</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>49.6</td>\n",
       "      <td>0.364</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>64</td>\n",
       "      <td>39</td>\n",
       "      <td>105</td>\n",
       "      <td>44.6</td>\n",
       "      <td>0.366</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.3</td>\n",
       "      <td>0.536</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>74</td>\n",
       "      <td>26</td>\n",
       "      <td>205</td>\n",
       "      <td>33.2</td>\n",
       "      <td>0.591</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0.314</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0.181</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>26</td>\n",
       "      <td>180</td>\n",
       "      <td>24.1</td>\n",
       "      <td>0.828</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>82</td>\n",
       "      <td>46</td>\n",
       "      <td>180</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0.335</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>8</td>\n",
       "      <td>107</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.856</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>13</td>\n",
       "      <td>158</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.257</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              1       85             66             29        0  26.6   \n",
       "1              8      183             64              0        0  23.3   \n",
       "2              1       89             66             23       94  28.1   \n",
       "3              0      137             40             35      168  43.1   \n",
       "4              5      116             74              0        0  25.6   \n",
       "5              3       78             50             32       88  31.0   \n",
       "6             10      115              0              0        0  35.3   \n",
       "7              2      197             70             45      543  30.5   \n",
       "8              8      125             96              0        0   0.0   \n",
       "9              4      110             92              0        0  37.6   \n",
       "10            10      168             74              0        0  38.0   \n",
       "11            10      139             80              0        0  27.1   \n",
       "12             1      189             60             23      846  30.1   \n",
       "13             5      166             72             19      175  25.8   \n",
       "14             7      100              0              0        0  30.0   \n",
       "15             0      118             84             47      230  45.8   \n",
       "16             7      107             74              0        0  29.6   \n",
       "17             1      103             30             38       83  43.3   \n",
       "18             1      115             70             30       96  34.6   \n",
       "19             3      126             88             41      235  39.3   \n",
       "20             8       99             84              0        0  35.4   \n",
       "21             7      196             90              0        0  39.8   \n",
       "22             9      119             80             35        0  29.0   \n",
       "23            11      143             94             33      146  36.6   \n",
       "24            10      125             70             26      115  31.1   \n",
       "25             7      147             76              0        0  39.4   \n",
       "26             1       97             66             15      140  23.2   \n",
       "27            13      145             82             19      110  22.2   \n",
       "28             5      117             92              0        0  34.1   \n",
       "29             5      109             75             26        0  36.0   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "661            8      167            106             46      231  37.6   \n",
       "662            9      145             80             46      130  37.9   \n",
       "663            6      115             60             39        0  33.7   \n",
       "664            1      112             80             45      132  34.8   \n",
       "665            4      145             82             18        0  32.5   \n",
       "666           10      111             70             27        0  27.5   \n",
       "667            6       98             58             33      190  34.0   \n",
       "668            9      154             78             30      100  30.9   \n",
       "669            6      165             68             26      168  33.6   \n",
       "670            1       99             58             10        0  25.4   \n",
       "671           10       68            106             23       49  35.5   \n",
       "672            3      123            100             35      240  57.3   \n",
       "673            8       91             82              0        0  35.6   \n",
       "674            6      195             70              0        0  30.9   \n",
       "675            9      156             86              0        0  24.8   \n",
       "676            0       93             60              0        0  35.3   \n",
       "677            3      121             52              0        0  36.0   \n",
       "678            2      101             58             17      265  24.2   \n",
       "679            2       56             56             28       45  24.2   \n",
       "680            0      162             76             36        0  49.6   \n",
       "681            0       95             64             39      105  44.6   \n",
       "682            4      125             80              0        0  32.3   \n",
       "683            5      136             82              0        0   0.0   \n",
       "684            2      129             74             26      205  33.2   \n",
       "685            3      130             64              0        0  23.1   \n",
       "686            1      107             50             19        0  28.3   \n",
       "687            1      140             74             26      180  24.1   \n",
       "688            1      144             82             46      180  46.1   \n",
       "689            8      107             80              0        0  24.6   \n",
       "690           13      158            114              0        0  42.3   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "0                       0.351   31  \n",
       "1                       0.672   32  \n",
       "2                       0.167   21  \n",
       "3                       2.288   33  \n",
       "4                       0.201   30  \n",
       "5                       0.248   26  \n",
       "6                       0.134   29  \n",
       "7                       0.158   53  \n",
       "8                       0.232   54  \n",
       "9                       0.191   30  \n",
       "10                      0.537   34  \n",
       "11                      1.441   57  \n",
       "12                      0.398   59  \n",
       "13                      0.587   51  \n",
       "14                      0.484   32  \n",
       "15                      0.551   31  \n",
       "16                      0.254   31  \n",
       "17                      0.183   33  \n",
       "18                      0.529   32  \n",
       "19                      0.704   27  \n",
       "20                      0.388   50  \n",
       "21                      0.451   41  \n",
       "22                      0.263   29  \n",
       "23                      0.254   51  \n",
       "24                      0.205   41  \n",
       "25                      0.257   43  \n",
       "26                      0.487   22  \n",
       "27                      0.245   57  \n",
       "28                      0.337   38  \n",
       "29                      0.546   60  \n",
       "..                        ...  ...  \n",
       "661                     0.165   43  \n",
       "662                     0.637   40  \n",
       "663                     0.245   40  \n",
       "664                     0.217   24  \n",
       "665                     0.235   70  \n",
       "666                     0.141   40  \n",
       "667                     0.430   43  \n",
       "668                     0.164   45  \n",
       "669                     0.631   49  \n",
       "670                     0.551   21  \n",
       "671                     0.285   47  \n",
       "672                     0.880   22  \n",
       "673                     0.587   68  \n",
       "674                     0.328   31  \n",
       "675                     0.230   53  \n",
       "676                     0.263   25  \n",
       "677                     0.127   25  \n",
       "678                     0.614   23  \n",
       "679                     0.332   22  \n",
       "680                     0.364   26  \n",
       "681                     0.366   22  \n",
       "682                     0.536   27  \n",
       "683                     0.640   69  \n",
       "684                     0.591   25  \n",
       "685                     0.314   22  \n",
       "686                     0.181   29  \n",
       "687                     0.828   23  \n",
       "688                     0.335   46  \n",
       "689                     0.856   34  \n",
       "690                     0.257   44  \n",
       "\n",
       "[691 rows x 8 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.83660130718955\n"
     ]
    }
   ],
   "source": [
    "#TRAIN - TEST SPLIT\n",
    "data = pd.read_csv(\"data/pima-indians-diabetes.csv\")\n",
    "data.columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Class']\n",
    "\n",
    "X = data.drop('Class',axis = 1)\n",
    "y = data['Class']\n",
    "\n",
    "distinct_class=y.unique()\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "no_fold = 10\n",
    "kfold = KFold(no_fold,random_state = 1234)\n",
    "\n",
    "match_class = 0\n",
    "overall_match_class = 0\n",
    "\n",
    "train_idx,test_idx=train_test_split(data) #Split the Dataset\n",
    "\n",
    "\n",
    "for f in (range(no_fold)):\n",
    "    #print (\"Processing for Train:{} Test:{}\".format(len(train_idx), len(test_idx)))\n",
    "    nb_clf.fit(X.iloc[train_idx[f]],y.iloc[train_idx[f]])\n",
    "    pred = nb_clf.predict(X.iloc[test_idx[f]])\n",
    "    match_class = sum(pred == y.iloc[test_idx[f]])/len(test_idx[f])*100\n",
    "    overall_match_class += match_class\n",
    "    #print (match_class)\n",
    "print (overall_match_class/no_fold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
