{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso,ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    columns = [\"Col1\",\"Col 2\",\"Col 3\",\"Col 4\",\"Col 5\",\"Col 6\", \"Col 7\", \"Col 8\",\"Col 9\",\"Col 10\"]\n",
    "    data = pd.read_csv(\"/users/Sushanta/Documents/GitHub/Illinois/CS598 Practical Statistical Learning/Project/data/Ames_data.csv\")\n",
    "    testIds = pd.read_csv(\"/users/Sushanta/Documents/GitHub/Illinois/CS598 Practical Statistical Learning/Project/data/project1_testIDs.dat\",sep = \" \", names = columns)\n",
    "    \n",
    "    return data, testIds\n",
    "\n",
    "def created_train_test(data,testIds,j):\n",
    "    j = j-1\n",
    "    test = data.iloc[np.array(testIds)[:,j]]\n",
    "    train = data.drop(np.array(testIds)[:,j], axis=0)\n",
    "    return train,test\n",
    "\n",
    "def onehot_encoding(x_train,x_test):\n",
    "    #number of record\n",
    "    train_num = x_train.shape[0]\n",
    "    test_num = x_test.shape[0]\n",
    "    #Merge the Train & Test\n",
    "    df = [x_train,x_test]\n",
    "    df_train_test = pd.concat(df)\n",
    "    \n",
    "    #Label Encoder to transform the Categoricsal Variable\n",
    "    lbe = LabelEncoder()\n",
    "    for col_name in train.columns[train.dtypes == 'object']:\n",
    "        #col_name = cols+'_Cat'\n",
    "        df_train_test[col_name] = lbe.fit_transform(df_train_test[col_name])\n",
    "        \n",
    "    #Let's drop the column \"Garage_Yr_Blt\" for now, as it ha NaN\n",
    "    df_train_test = df_train_test.drop(['Garage_Yr_Blt'],axis=1)\n",
    "    x_train = df_train_test.iloc[0:train_num]\n",
    "    x_test = df_train_test.iloc[train_num:]\n",
    "    \n",
    "    return x_train,x_test\n",
    "\n",
    "\n",
    "def winsorization(x_train,x_test):\n",
    "    winsorization_cols = ['Lot_Frontage', 'Lot_Area', 'Mas_Vnr_Area', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', \n",
    "                          'Total_Bsmt_SF', 'Second_Flr_SF', 'First_Flr_SF', 'Gr_Liv_Area', 'Garage_Area',\n",
    "                          'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', \n",
    "                          'Screen_Porch', 'Misc_Val']\n",
    "    quan_val = 0.95\n",
    "    for winso_columns in winsorization_cols:\n",
    "        col_quant_value = np.quantile(x_train_transformed[winso_columns],quan_val)\n",
    "        x_train_transformed[winso_columns][x_train_transformed[winso_columns] > col_quant_value] = col_quant_value\n",
    "        x_test_transformed[winso_columns][x_test_transformed[winso_columns] > col_quant_value] = col_quant_value\n",
    "        #print (\"Column : {} 95% Quantile: {}\".format(winso_columns,col_quant_value))\n",
    "        \n",
    "    return x_train,x_test\n",
    "        \n",
    "def lasso_model(x_train,y_train,x_test,y_test,alpha=0.5):\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(x_train,y_train)\n",
    "    y_predict = lasso_model.predict(x_test)\n",
    "    return lasso_model,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in the Training Set: (2051, 83)\n",
      "Number of elements in the Test Set: (879, 83)\n",
      "Number of elements in the Train Transformed Set: (2051, 81)\n",
      "Number of elements in the Test Transformed Set: (879, 81)\n"
     ]
    }
   ],
   "source": [
    "data, testIds = load_data()\n",
    "train,test = created_train_test(data,testIds,j=1)\n",
    "\n",
    "#Print the dataset size\n",
    "print (\"Number of elements in the Training Set: {}\".format(train.shape))\n",
    "print (\"Number of elements in the Test Set: {}\".format(test.shape))\n",
    "\n",
    "#Write to the Train.csv file\n",
    "train.to_csv(\"/users/Sushanta/Documents/GitHub/Illinois/CS598 Practical Statistical Learning/Project/data/train.csv\",index=False)\n",
    "test.to_csv(\"/users/Sushanta/Documents/GitHub/Illinois/CS598 Practical Statistical Learning/Project/data/test.csv\",index=False)\n",
    "\n",
    "y_train = np.log(train['Sale_Price'])\n",
    "x_train = train.drop(['Sale_Price'],axis=1)\n",
    "y_test = np.log(test['Sale_Price'])\n",
    "x_test = test.drop(['Sale_Price'],axis=1)\n",
    "\n",
    "x_train_transformed,x_test_transformed = onehot_encoding(x_train,x_test)\n",
    "x_train_winsor,x_test_winsor = winsorization(x_train_transformed,x_test_transformed)\n",
    "\n",
    "#Print the dataset size\n",
    "print (\"Number of elements in the Train Transformed Set: {}\".format(x_train_transformed.shape))\n",
    "print (\"Number of elements in the Test Transformed Set: {}\".format(x_test_transformed.shape))\n",
    "\n",
    "drop_columns = ['PID','Street', 'Utilities', 'Condition_2', 'Roof_Matl', 'Heating', \n",
    "                'Pool_QC', 'Misc_Feature', 'Low_Qual_Fin_SF', 'Pool_Area', 'Longitude',\n",
    "                'Latitude'\n",
    "                ]\n",
    "x_train_final = x_train_winsor.drop(drop_columns,axis = 1)\n",
    "x_test_final = x_test_winsor.drop(drop_columns,axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for lamda:0.0\n",
      "Lamda: 0.0 - Fold: 1 - Error Test: 0.184\n",
      "Lamda: 0.0 - Fold: 2 - Error Test: 0.136\n",
      "Lamda: 0.0 - Fold: 3 - Error Test: 0.163\n",
      "Lamda: 0.0 - Fold: 4 - Error Test: 0.114\n",
      "Lamda: 0.0 - Fold: 5 - Error Test: 0.142\n",
      "Lamda: 0.0 - Fold: 6 - Error Test: 0.158\n",
      "Lamda: 0.0 - Fold: 7 - Error Test: 0.153\n",
      "Lamda: 0.0 - Fold: 8 - Error Test: 0.151\n",
      "Lamda: 0.0 - Fold: 9 - Error Test: 0.108\n",
      "Lamda: 0.0 - Fold: 10 - Error Test: 0.162\n",
      "Lamda: 0.0 - Error Train: 0.149\n",
      "Lamda: 0.0 - Error Test : 0.146\n",
      "Processing for lamda:1.0\n",
      "Lamda: 1.0 - Fold: 1 - Error Test: 0.218\n",
      "Lamda: 1.0 - Fold: 2 - Error Test: 0.169\n",
      "Lamda: 1.0 - Fold: 3 - Error Test: 0.200\n",
      "Lamda: 1.0 - Fold: 4 - Error Test: 0.139\n",
      "Lamda: 1.0 - Fold: 5 - Error Test: 0.168\n",
      "Lamda: 1.0 - Fold: 6 - Error Test: 0.176\n",
      "Lamda: 1.0 - Fold: 7 - Error Test: 0.180\n",
      "Lamda: 1.0 - Fold: 8 - Error Test: 0.185\n",
      "Lamda: 1.0 - Fold: 9 - Error Test: 0.140\n",
      "Lamda: 1.0 - Fold: 10 - Error Test: 0.195\n",
      "Lamda: 1.0 - Error Train: 0.179\n",
      "Lamda: 1.0 - Error Test : 0.180\n",
      "Processing for lamda:1e-05\n",
      "Lamda: 1e-05 - Fold: 1 - Error Test: 0.184\n",
      "Lamda: 1e-05 - Fold: 2 - Error Test: 0.136\n",
      "Lamda: 1e-05 - Fold: 3 - Error Test: 0.163\n",
      "Lamda: 1e-05 - Fold: 4 - Error Test: 0.114\n",
      "Lamda: 1e-05 - Fold: 5 - Error Test: 0.142\n",
      "Lamda: 1e-05 - Fold: 6 - Error Test: 0.158\n",
      "Lamda: 1e-05 - Fold: 7 - Error Test: 0.153\n",
      "Lamda: 1e-05 - Fold: 8 - Error Test: 0.151\n",
      "Lamda: 1e-05 - Fold: 9 - Error Test: 0.108\n",
      "Lamda: 1e-05 - Fold: 10 - Error Test: 0.162\n",
      "Lamda: 1e-05 - Error Train: 0.149\n",
      "Lamda: 1e-05 - Error Test : 0.146\n",
      "Processing for lamda:0.0001\n",
      "Lamda: 0.0001 - Fold: 1 - Error Test: 0.183\n",
      "Lamda: 0.0001 - Fold: 2 - Error Test: 0.136\n",
      "Lamda: 0.0001 - Fold: 3 - Error Test: 0.163\n",
      "Lamda: 0.0001 - Fold: 4 - Error Test: 0.114\n",
      "Lamda: 0.0001 - Fold: 5 - Error Test: 0.142\n",
      "Lamda: 0.0001 - Fold: 6 - Error Test: 0.158\n",
      "Lamda: 0.0001 - Fold: 7 - Error Test: 0.153\n",
      "Lamda: 0.0001 - Fold: 8 - Error Test: 0.151\n",
      "Lamda: 0.0001 - Fold: 9 - Error Test: 0.108\n",
      "Lamda: 0.0001 - Fold: 10 - Error Test: 0.162\n",
      "Lamda: 0.0001 - Error Train: 0.149\n",
      "Lamda: 0.0001 - Error Test : 0.146\n",
      "Processing for lamda:0.0002\n",
      "Lamda: 0.0002 - Fold: 1 - Error Test: 0.183\n",
      "Lamda: 0.0002 - Fold: 2 - Error Test: 0.136\n",
      "Lamda: 0.0002 - Fold: 3 - Error Test: 0.163\n",
      "Lamda: 0.0002 - Fold: 4 - Error Test: 0.114\n",
      "Lamda: 0.0002 - Fold: 5 - Error Test: 0.142\n",
      "Lamda: 0.0002 - Fold: 6 - Error Test: 0.158\n",
      "Lamda: 0.0002 - Fold: 7 - Error Test: 0.153\n",
      "Lamda: 0.0002 - Fold: 8 - Error Test: 0.151\n",
      "Lamda: 0.0002 - Fold: 9 - Error Test: 0.108\n",
      "Lamda: 0.0002 - Fold: 10 - Error Test: 0.162\n",
      "Lamda: 0.0002 - Error Train: 0.149\n",
      "Lamda: 0.0002 - Error Test : 0.145\n",
      "Processing for lamda:0.0003\n",
      "Lamda: 0.0003 - Fold: 1 - Error Test: 0.183\n",
      "Lamda: 0.0003 - Fold: 2 - Error Test: 0.136\n",
      "Lamda: 0.0003 - Fold: 3 - Error Test: 0.163\n",
      "Lamda: 0.0003 - Fold: 4 - Error Test: 0.114\n",
      "Lamda: 0.0003 - Fold: 5 - Error Test: 0.142\n",
      "Lamda: 0.0003 - Fold: 6 - Error Test: 0.157\n",
      "Lamda: 0.0003 - Fold: 7 - Error Test: 0.153\n",
      "Lamda: 0.0003 - Fold: 8 - Error Test: 0.151\n",
      "Lamda: 0.0003 - Fold: 9 - Error Test: 0.107\n",
      "Lamda: 0.0003 - Fold: 10 - Error Test: 0.162\n",
      "Lamda: 0.0003 - Error Train: 0.149\n",
      "Lamda: 0.0003 - Error Test : 0.145\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------\n",
    "#\n",
    "# Shrinking Methods (Lasso)\n",
    "#\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "split_ = 10\n",
    "lamda_count_ = 0\n",
    "alpha_ = np.array([0,1,0.00001,0.0001,0.0002,0.0003])\n",
    "#alpha_ = np.array([1,0.00001,0.0001,0.0002,0.0003,0.001,0.002,0.003,0.01,0.02])\n",
    "\n",
    "kf = KFold(n_splits=split_)\n",
    "\n",
    "y_train_actual_lamda = np.zeros((x_train_final.shape[0],alpha_.shape[0]))\n",
    "y_train_predict_lamda = np.zeros((x_train_final.shape[0],alpha_.shape[0]))\n",
    "y_test_predict_lamda = np.zeros((x_test_final.shape[0],alpha_.shape[0]))\n",
    "\n",
    "for lamda in alpha_:\n",
    "    print (\"Processing for lamda:{}\".format(lamda))\n",
    "    \n",
    "    fold_ = 0\n",
    "    y_test_predict_kfold = np.zeros((x_test_final.shape[0],split_))\n",
    "\n",
    "    y_train_predict_array = np.array(())\n",
    "    y_train_actual_array = np.array(())\n",
    "    for (train_idx,test_idx) in kf.split(x_train_final,y_train):\n",
    "        #print (test_idx.shape)\n",
    "        #print(fold_)\n",
    "        lasso_model = Lasso(alpha=lamda)\n",
    "        lasso_model.fit(x_train_final.iloc[train_idx],y_train.iloc[train_idx])\n",
    "        y_train_predict = lasso_model.predict(x_train_final.iloc[test_idx])\n",
    "        y_test_predict  = lasso_model.predict(x_test_final)\n",
    "        \n",
    "        y_train_actual_array = np.append(y_train_actual_array,y_train.iloc[test_idx])\n",
    "        y_train_predict_array = np.append(y_train_predict_array,y_train_predict)\n",
    "        \n",
    "        y_test_predict_kfold[:,fold_] =  y_test_predict\n",
    "        \n",
    "        \n",
    "        print (\"Lamda: {} - Fold: {} - Error Test: {:.3f}\".format(lamda,fold_+1,mean_squared_error(y_train.iloc[test_idx], y_train_predict, squared=False)))\n",
    "        \n",
    "        fold_ = fold_ + 1\n",
    "    \n",
    "    y_train_actual_lamda[:,lamda_count_] = y_train_actual_array\n",
    "    y_train_predict_lamda[:,lamda_count_] = y_train_predict_array\n",
    "    \n",
    "    y_test_predict_lamda[:,lamda_count_] = np.mean(y_test_predict_kfold,axis=1)\n",
    "    \n",
    "    \n",
    "    print (\"Lamda: {} - Error Train: {:.3f}\".format(lamda,mean_squared_error(y_train, y_train_predict_lamda[:,lamda_count_], squared=False)))\n",
    "    print (\"Lamda: {} - Error Test : {:.3f}\".format(lamda,mean_squared_error(y_test, y_test_predict_lamda[:,lamda_count_], squared=False)))\n",
    "    \n",
    "    lamda_count_ = lamda_count_ + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for max_depth:16\n",
      "Max_Depth: 16 - Fold: 1 - Error Test: 0.191\n",
      "Max_Depth: 16 - Fold: 2 - Error Test: 0.141\n",
      "Max_Depth: 16 - Fold: 3 - Error Test: 0.172\n",
      "Max_Depth: 16 - Fold: 4 - Error Test: 0.108\n",
      "Max_Depth: 16 - Fold: 5 - Error Test: 0.137\n",
      "Max_Depth: 16 - Fold: 6 - Error Test: 0.143\n",
      "Max_Depth: 16 - Fold: 7 - Error Test: 0.152\n",
      "Max_Depth: 16 - Fold: 8 - Error Test: 0.159\n",
      "Max_Depth: 16 - Fold: 9 - Error Test: 0.102\n",
      "Max_Depth: 16 - Fold: 10 - Error Test: 0.157\n",
      "Max Depth: 16 - Error Train: 0.148\n",
      "Max Depth: 16 - Error Test : 0.144\n",
      "Processing for max_depth:18\n",
      "Max_Depth: 18 - Fold: 1 - Error Test: 0.191\n",
      "Max_Depth: 18 - Fold: 2 - Error Test: 0.140\n",
      "Max_Depth: 18 - Fold: 3 - Error Test: 0.170\n",
      "Max_Depth: 18 - Fold: 4 - Error Test: 0.110\n",
      "Max_Depth: 18 - Fold: 5 - Error Test: 0.137\n",
      "Max_Depth: 18 - Fold: 6 - Error Test: 0.143\n",
      "Max_Depth: 18 - Fold: 7 - Error Test: 0.151\n",
      "Max_Depth: 18 - Fold: 8 - Error Test: 0.157\n",
      "Max_Depth: 18 - Fold: 9 - Error Test: 0.102\n",
      "Max_Depth: 18 - Fold: 10 - Error Test: 0.157\n",
      "Max Depth: 18 - Error Train: 0.148\n",
      "Max Depth: 18 - Error Test : 0.144\n",
      "Processing for max_depth:24\n",
      "Max_Depth: 24 - Fold: 1 - Error Test: 0.189\n",
      "Max_Depth: 24 - Fold: 2 - Error Test: 0.140\n",
      "Max_Depth: 24 - Fold: 3 - Error Test: 0.170\n",
      "Max_Depth: 24 - Fold: 4 - Error Test: 0.109\n",
      "Max_Depth: 24 - Fold: 5 - Error Test: 0.137\n",
      "Max_Depth: 24 - Fold: 6 - Error Test: 0.142\n",
      "Max_Depth: 24 - Fold: 7 - Error Test: 0.152\n",
      "Max_Depth: 24 - Fold: 8 - Error Test: 0.159\n",
      "Max_Depth: 24 - Fold: 9 - Error Test: 0.102\n",
      "Max_Depth: 24 - Fold: 10 - Error Test: 0.156\n",
      "Max Depth: 24 - Error Train: 0.148\n",
      "Max Depth: 24 - Error Test : 0.144\n",
      "Processing for max_depth:28\n",
      "Max_Depth: 28 - Fold: 1 - Error Test: 0.189\n",
      "Max_Depth: 28 - Fold: 2 - Error Test: 0.141\n",
      "Max_Depth: 28 - Fold: 3 - Error Test: 0.170\n",
      "Max_Depth: 28 - Fold: 4 - Error Test: 0.110\n",
      "Max_Depth: 28 - Fold: 5 - Error Test: 0.137\n",
      "Max_Depth: 28 - Fold: 6 - Error Test: 0.141\n",
      "Max_Depth: 28 - Fold: 7 - Error Test: 0.152\n",
      "Max_Depth: 28 - Fold: 8 - Error Test: 0.160\n",
      "Max_Depth: 28 - Fold: 9 - Error Test: 0.102\n",
      "Max_Depth: 28 - Fold: 10 - Error Test: 0.156\n",
      "Max Depth: 28 - Error Train: 0.148\n",
      "Max Depth: 28 - Error Test : 0.144\n",
      "Processing for max_depth:30\n",
      "Max_Depth: 30 - Fold: 1 - Error Test: 0.189\n",
      "Max_Depth: 30 - Fold: 2 - Error Test: 0.141\n",
      "Max_Depth: 30 - Fold: 3 - Error Test: 0.170\n",
      "Max_Depth: 30 - Fold: 4 - Error Test: 0.110\n",
      "Max_Depth: 30 - Fold: 5 - Error Test: 0.137\n",
      "Max_Depth: 30 - Fold: 6 - Error Test: 0.141\n",
      "Max_Depth: 30 - Fold: 7 - Error Test: 0.152\n",
      "Max_Depth: 30 - Fold: 8 - Error Test: 0.160\n",
      "Max_Depth: 30 - Fold: 9 - Error Test: 0.102\n",
      "Max_Depth: 30 - Fold: 10 - Error Test: 0.156\n",
      "Max Depth: 30 - Error Train: 0.148\n",
      "Max Depth: 30 - Error Test : 0.144\n",
      "Processing for max_depth:38\n",
      "Max_Depth: 38 - Fold: 1 - Error Test: 0.189\n",
      "Max_Depth: 38 - Fold: 2 - Error Test: 0.141\n",
      "Max_Depth: 38 - Fold: 3 - Error Test: 0.170\n",
      "Max_Depth: 38 - Fold: 4 - Error Test: 0.110\n",
      "Max_Depth: 38 - Fold: 5 - Error Test: 0.137\n",
      "Max_Depth: 38 - Fold: 6 - Error Test: 0.141\n",
      "Max_Depth: 38 - Fold: 7 - Error Test: 0.152\n",
      "Max_Depth: 38 - Fold: 8 - Error Test: 0.160\n",
      "Max_Depth: 38 - Fold: 9 - Error Test: 0.102\n",
      "Max_Depth: 38 - Fold: 10 - Error Test: 0.156\n",
      "Max Depth: 38 - Error Train: 0.148\n",
      "Max Depth: 38 - Error Test : 0.144\n",
      "Processing for max_depth:50\n",
      "Max_Depth: 50 - Fold: 1 - Error Test: 0.189\n",
      "Max_Depth: 50 - Fold: 2 - Error Test: 0.141\n",
      "Max_Depth: 50 - Fold: 3 - Error Test: 0.170\n",
      "Max_Depth: 50 - Fold: 4 - Error Test: 0.110\n",
      "Max_Depth: 50 - Fold: 5 - Error Test: 0.137\n",
      "Max_Depth: 50 - Fold: 6 - Error Test: 0.141\n",
      "Max_Depth: 50 - Fold: 7 - Error Test: 0.152\n",
      "Max_Depth: 50 - Fold: 8 - Error Test: 0.160\n",
      "Max_Depth: 50 - Fold: 9 - Error Test: 0.102\n",
      "Max_Depth: 50 - Fold: 10 - Error Test: 0.156\n",
      "Max Depth: 50 - Error Train: 0.148\n",
      "Max Depth: 50 - Error Test : 0.144\n",
      "Processing for max_depth:60\n",
      "Max_Depth: 60 - Fold: 1 - Error Test: 0.189\n",
      "Max_Depth: 60 - Fold: 2 - Error Test: 0.141\n",
      "Max_Depth: 60 - Fold: 3 - Error Test: 0.170\n",
      "Max_Depth: 60 - Fold: 4 - Error Test: 0.110\n",
      "Max_Depth: 60 - Fold: 5 - Error Test: 0.137\n",
      "Max_Depth: 60 - Fold: 6 - Error Test: 0.141\n",
      "Max_Depth: 60 - Fold: 7 - Error Test: 0.152\n",
      "Max_Depth: 60 - Fold: 8 - Error Test: 0.160\n",
      "Max_Depth: 60 - Fold: 9 - Error Test: 0.102\n",
      "Max_Depth: 60 - Fold: 10 - Error Test: 0.156\n",
      "Max Depth: 60 - Error Train: 0.148\n",
      "Max Depth: 60 - Error Test : 0.144\n",
      "Processing for max_depth:70\n",
      "Max_Depth: 70 - Fold: 1 - Error Test: 0.189\n",
      "Max_Depth: 70 - Fold: 2 - Error Test: 0.141\n",
      "Max_Depth: 70 - Fold: 3 - Error Test: 0.170\n",
      "Max_Depth: 70 - Fold: 4 - Error Test: 0.110\n",
      "Max_Depth: 70 - Fold: 5 - Error Test: 0.137\n",
      "Max_Depth: 70 - Fold: 6 - Error Test: 0.141\n",
      "Max_Depth: 70 - Fold: 7 - Error Test: 0.152\n",
      "Max_Depth: 70 - Fold: 8 - Error Test: 0.160\n",
      "Max_Depth: 70 - Fold: 9 - Error Test: 0.102\n",
      "Max_Depth: 70 - Fold: 10 - Error Test: 0.156\n",
      "Max Depth: 70 - Error Train: 0.148\n",
      "Max Depth: 70 - Error Test : 0.144\n",
      "Processing for max_depth:90\n",
      "Max_Depth: 90 - Fold: 1 - Error Test: 0.189\n",
      "Max_Depth: 90 - Fold: 2 - Error Test: 0.141\n",
      "Max_Depth: 90 - Fold: 3 - Error Test: 0.170\n",
      "Max_Depth: 90 - Fold: 4 - Error Test: 0.110\n",
      "Max_Depth: 90 - Fold: 5 - Error Test: 0.137\n",
      "Max_Depth: 90 - Fold: 6 - Error Test: 0.141\n",
      "Max_Depth: 90 - Fold: 7 - Error Test: 0.152\n",
      "Max_Depth: 90 - Fold: 8 - Error Test: 0.160\n",
      "Max_Depth: 90 - Fold: 9 - Error Test: 0.102\n",
      "Max_Depth: 90 - Fold: 10 - Error Test: 0.156\n",
      "Max Depth: 90 - Error Train: 0.148\n",
      "Max Depth: 90 - Error Test : 0.144\n",
      "Processing for max_depth:120\n",
      "Max_Depth: 120 - Fold: 1 - Error Test: 0.189\n",
      "Max_Depth: 120 - Fold: 2 - Error Test: 0.141\n",
      "Max_Depth: 120 - Fold: 3 - Error Test: 0.170\n",
      "Max_Depth: 120 - Fold: 4 - Error Test: 0.110\n",
      "Max_Depth: 120 - Fold: 5 - Error Test: 0.137\n",
      "Max_Depth: 120 - Fold: 6 - Error Test: 0.141\n",
      "Max_Depth: 120 - Fold: 7 - Error Test: 0.152\n",
      "Max_Depth: 120 - Fold: 8 - Error Test: 0.160\n",
      "Max_Depth: 120 - Fold: 9 - Error Test: 0.102\n",
      "Max_Depth: 120 - Fold: 10 - Error Test: 0.156\n",
      "Max Depth: 120 - Error Train: 0.148\n",
      "Max Depth: 120 - Error Test : 0.144\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------\n",
    "#\n",
    "# Random Forest Regressor\n",
    "#\n",
    "#------------------------------------------------------------------------\n",
    "split_ = 10\n",
    "max_depth_count_ = 0\n",
    "max_depth_ = np.array([16,18,24,28,30,90,120])\n",
    "\n",
    "kf = KFold(n_splits=split_)\n",
    "\n",
    "y_train_actual_max_depth = np.zeros((x_train_final.shape[0],max_depth_.shape[0]))\n",
    "y_train_predict_max_depth = np.zeros((x_train_final.shape[0],max_depth_.shape[0]))\n",
    "y_test_predict_max_depth = np.zeros((x_test_final.shape[0],max_depth_.shape[0]))\n",
    "\n",
    "for depth in max_depth_:\n",
    "    print (\"Processing for max_depth:{}\".format(depth))\n",
    "    \n",
    "    fold_ = 0\n",
    "    y_test_predict_kfold = np.zeros((x_test_final.shape[0],split_))\n",
    "\n",
    "    y_train_predict_array = np.array(())\n",
    "    y_train_actual_array = np.array(())\n",
    "    for (train_idx,test_idx) in kf.split(x_train_final,y_train):\n",
    "        rf_model = RandomForestRegressor(max_depth=depth,random_state=125247)\n",
    "        rf_model.fit(x_train_final.iloc[train_idx],y_train.iloc[train_idx])\n",
    "        y_train_predict = rf_model.predict(x_train_final.iloc[test_idx])\n",
    "        y_test_predict  = rf_model.predict(x_test_final)\n",
    "        \n",
    "        y_train_actual_array = np.append(y_train_actual_array,y_train.iloc[test_idx])\n",
    "        y_train_predict_array = np.append(y_train_predict_array,y_train_predict)\n",
    "        \n",
    "        y_test_predict_kfold[:,fold_] =  y_test_predict\n",
    "        \n",
    "        \n",
    "        print (\"Max_Depth: {} - Fold: {} - Error Test: {:.3f}\".format(depth,fold_+1,mean_squared_error(y_train.iloc[test_idx], y_train_predict, squared=False)))\n",
    "        \n",
    "        fold_ = fold_ + 1\n",
    "    \n",
    "    y_train_actual_max_depth[:,max_depth_count_] = y_train_actual_array\n",
    "    y_train_predict_max_depth[:,max_depth_count_] = y_train_predict_array\n",
    "    \n",
    "    y_test_predict_max_depth[:,max_depth_count_] = np.mean(y_test_predict_kfold,axis=1)\n",
    "    \n",
    "    \n",
    "    print (\"Max Depth: {} - Error Train: {:.3f}\".format(depth,mean_squared_error(y_train, y_train_predict_max_depth[:,max_depth_count_], squared=False)))\n",
    "    print (\"Max Depth: {} - Error Test : {:.3f}\".format(depth,mean_squared_error(y_test, y_test_predict_max_depth[:,max_depth_count_], squared=False)))\n",
    "    \n",
    "    max_depth_count_ = max_depth_count_ + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for lamda:0.0\n",
      "Lamda: 0.0 - Fold: 1 - Error Test: 0.184\n",
      "Lamda: 0.0 - Fold: 2 - Error Test: 0.136\n",
      "Lamda: 0.0 - Fold: 3 - Error Test: 0.163\n",
      "Lamda: 0.0 - Fold: 4 - Error Test: 0.114\n",
      "Lamda: 0.0 - Fold: 5 - Error Test: 0.142\n",
      "Lamda: 0.0 - Fold: 6 - Error Test: 0.158\n",
      "Lamda: 0.0 - Fold: 7 - Error Test: 0.153\n",
      "Lamda: 0.0 - Fold: 8 - Error Test: 0.151\n",
      "Lamda: 0.0 - Fold: 9 - Error Test: 0.108\n",
      "Lamda: 0.0 - Fold: 10 - Error Test: 0.162\n",
      "Lamda: 0.0 - Error Train: 0.149\n",
      "Lamda: 0.0 - Error Test : 0.146\n",
      "Processing for lamda:1.0\n",
      "Lamda: 1.0 - Fold: 1 - Error Test: 0.213\n",
      "Lamda: 1.0 - Fold: 2 - Error Test: 0.160\n",
      "Lamda: 1.0 - Fold: 3 - Error Test: 0.187\n",
      "Lamda: 1.0 - Fold: 4 - Error Test: 0.133\n",
      "Lamda: 1.0 - Fold: 5 - Error Test: 0.163\n",
      "Lamda: 1.0 - Fold: 6 - Error Test: 0.168\n",
      "Lamda: 1.0 - Fold: 7 - Error Test: 0.174\n",
      "Lamda: 1.0 - Fold: 8 - Error Test: 0.179\n",
      "Lamda: 1.0 - Fold: 9 - Error Test: 0.133\n",
      "Lamda: 1.0 - Fold: 10 - Error Test: 0.192\n",
      "Lamda: 1.0 - Error Train: 0.172\n",
      "Lamda: 1.0 - Error Test : 0.176\n",
      "Processing for lamda:0.2\n",
      "Lamda: 0.2 - Fold: 1 - Error Test: 0.210\n",
      "Lamda: 0.2 - Fold: 2 - Error Test: 0.156\n",
      "Lamda: 0.2 - Fold: 3 - Error Test: 0.181\n",
      "Lamda: 0.2 - Fold: 4 - Error Test: 0.132\n",
      "Lamda: 0.2 - Fold: 5 - Error Test: 0.163\n",
      "Lamda: 0.2 - Fold: 6 - Error Test: 0.164\n",
      "Lamda: 0.2 - Fold: 7 - Error Test: 0.172\n",
      "Lamda: 0.2 - Fold: 8 - Error Test: 0.178\n",
      "Lamda: 0.2 - Fold: 9 - Error Test: 0.128\n",
      "Lamda: 0.2 - Fold: 10 - Error Test: 0.192\n",
      "Lamda: 0.2 - Error Train: 0.169\n",
      "Lamda: 0.2 - Error Test : 0.175\n",
      "Processing for lamda:0.02\n",
      "Lamda: 0.02 - Fold: 1 - Error Test: 0.197\n",
      "Lamda: 0.02 - Fold: 2 - Error Test: 0.146\n",
      "Lamda: 0.02 - Fold: 3 - Error Test: 0.168\n",
      "Lamda: 0.02 - Fold: 4 - Error Test: 0.122\n",
      "Lamda: 0.02 - Fold: 5 - Error Test: 0.148\n",
      "Lamda: 0.02 - Fold: 6 - Error Test: 0.160\n",
      "Lamda: 0.02 - Fold: 7 - Error Test: 0.164\n",
      "Lamda: 0.02 - Fold: 8 - Error Test: 0.171\n",
      "Lamda: 0.02 - Fold: 9 - Error Test: 0.109\n",
      "Lamda: 0.02 - Fold: 10 - Error Test: 0.174\n",
      "Lamda: 0.02 - Error Train: 0.158\n",
      "Lamda: 0.02 - Error Test : 0.158\n",
      "Processing for lamda:0.0002\n",
      "Lamda: 0.0002 - Fold: 1 - Error Test: 0.183\n",
      "Lamda: 0.0002 - Fold: 2 - Error Test: 0.136\n",
      "Lamda: 0.0002 - Fold: 3 - Error Test: 0.163\n",
      "Lamda: 0.0002 - Fold: 4 - Error Test: 0.114\n",
      "Lamda: 0.0002 - Fold: 5 - Error Test: 0.142\n",
      "Lamda: 0.0002 - Fold: 6 - Error Test: 0.158\n",
      "Lamda: 0.0002 - Fold: 7 - Error Test: 0.153\n",
      "Lamda: 0.0002 - Fold: 8 - Error Test: 0.151\n",
      "Lamda: 0.0002 - Fold: 9 - Error Test: 0.108\n",
      "Lamda: 0.0002 - Fold: 10 - Error Test: 0.162\n",
      "Lamda: 0.0002 - Error Train: 0.149\n",
      "Lamda: 0.0002 - Error Test : 0.146\n",
      "Processing for lamda:2e-05\n",
      "Lamda: 2e-05 - Fold: 1 - Error Test: 0.184\n",
      "Lamda: 2e-05 - Fold: 2 - Error Test: 0.136\n",
      "Lamda: 2e-05 - Fold: 3 - Error Test: 0.163\n",
      "Lamda: 2e-05 - Fold: 4 - Error Test: 0.114\n",
      "Lamda: 2e-05 - Fold: 5 - Error Test: 0.142\n",
      "Lamda: 2e-05 - Fold: 6 - Error Test: 0.158\n",
      "Lamda: 2e-05 - Fold: 7 - Error Test: 0.153\n",
      "Lamda: 2e-05 - Fold: 8 - Error Test: 0.151\n",
      "Lamda: 2e-05 - Fold: 9 - Error Test: 0.108\n",
      "Lamda: 2e-05 - Fold: 10 - Error Test: 0.162\n",
      "Lamda: 2e-05 - Error Train: 0.149\n",
      "Lamda: 2e-05 - Error Test : 0.146\n",
      "Processing for lamda:2e-06\n",
      "Lamda: 2e-06 - Fold: 1 - Error Test: 0.184\n",
      "Lamda: 2e-06 - Fold: 2 - Error Test: 0.136\n",
      "Lamda: 2e-06 - Fold: 3 - Error Test: 0.163\n",
      "Lamda: 2e-06 - Fold: 4 - Error Test: 0.114\n",
      "Lamda: 2e-06 - Fold: 5 - Error Test: 0.142\n",
      "Lamda: 2e-06 - Fold: 6 - Error Test: 0.158\n",
      "Lamda: 2e-06 - Fold: 7 - Error Test: 0.153\n",
      "Lamda: 2e-06 - Fold: 8 - Error Test: 0.151\n",
      "Lamda: 2e-06 - Fold: 9 - Error Test: 0.108\n",
      "Lamda: 2e-06 - Fold: 10 - Error Test: 0.162\n",
      "Lamda: 2e-06 - Error Train: 0.149\n",
      "Lamda: 2e-06 - Error Test : 0.146\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------\n",
    "#\n",
    "# Elastic Nets\n",
    "#\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "split_ = 10\n",
    "lamda_count_ = 0\n",
    "alpha_ = np.array([0,1,0.2,0.02,0.0002,0.00002,0.000002])\n",
    "#alpha_ = np.array([1,0.00001,0.0001,0.0002,0.0003,0.001,0.002,0.003,0.01,0.02])\n",
    "\n",
    "kf = KFold(n_splits=split_)\n",
    "\n",
    "y_train_actual_en_lamda = np.zeros((x_train_final.shape[0],alpha_.shape[0]))\n",
    "y_train_predict_en_lamda = np.zeros((x_train_final.shape[0],alpha_.shape[0]))\n",
    "y_test_predict_en_lamda = np.zeros((x_test_final.shape[0],alpha_.shape[0]))\n",
    "\n",
    "for lamda in alpha_:\n",
    "    print (\"Processing for lamda:{}\".format(lamda))\n",
    "    \n",
    "    fold_ = 0\n",
    "    y_test_predict_en_kfold = np.zeros((x_test_final.shape[0],split_))\n",
    "\n",
    "    y_train_predict_en_array = np.array(())\n",
    "    y_train_actual_en_array = np.array(())\n",
    "    for (train_idx,test_idx) in kf.split(x_train_final,y_train):\n",
    "        #print (test_idx.shape)\n",
    "        #print(fold_)\n",
    "        en_model = ElasticNet(alpha=lamda)\n",
    "        en_model.fit(x_train_final.iloc[train_idx],y_train.iloc[train_idx])\n",
    "        y_train_predict = en_model.predict(x_train_final.iloc[test_idx])\n",
    "        y_test_predict  = en_model.predict(x_test_final)\n",
    "        \n",
    "        y_train_actual_en_array = np.append(y_train_actual_en_array,y_train.iloc[test_idx])\n",
    "        y_train_predict_en_array = np.append(y_train_predict_en_array,y_train_predict)\n",
    "        \n",
    "        y_test_predict_en_kfold[:,fold_] =  y_test_predict\n",
    "        \n",
    "        \n",
    "        print (\"Lamda: {} - Fold: {} - Error Test: {:.3f}\".format(lamda,fold_+1,mean_squared_error(y_train.iloc[test_idx], y_train_predict, squared=False)))\n",
    "        \n",
    "        fold_ = fold_ + 1\n",
    "    \n",
    "    y_train_actual_en_lamda[:,lamda_count_] = y_train_actual_en_array\n",
    "    y_train_predict_en_lamda[:,lamda_count_] = y_train_predict_en_array\n",
    "    \n",
    "    y_test_predict_en_lamda[:,lamda_count_] = np.mean(y_test_predict_en_kfold,axis=1)\n",
    "    \n",
    "    \n",
    "    print (\"Lamda: {} - Error Train: {:.3f}\".format(lamda,mean_squared_error(y_train, y_train_predict_en_lamda[:,lamda_count_], squared=False)))\n",
    "    print (\"Lamda: {} - Error Test : {:.3f}\".format(lamda,mean_squared_error(y_test, y_test_predict_en_lamda[:,lamda_count_], squared=False)))\n",
    "    \n",
    "    lamda_count_ = lamda_count_ + 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
