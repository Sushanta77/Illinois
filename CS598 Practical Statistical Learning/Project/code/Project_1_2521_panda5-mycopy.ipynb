{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso,ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_name):\n",
    "    columns = [\"Col1\",\"Col 2\",\"Col 3\",\"Col 4\",\"Col 5\",\"Col 6\", \"Col 7\", \"Col 8\",\"Col 9\",\"Col 10\"]\n",
    "    data = pd.read_csv(folder_name+\"Ames_data.csv\")\n",
    "    testIds = pd.read_csv(folder_name+\"project1_testIDs.dat\",sep = \" \", names = columns)\n",
    "    \n",
    "    return data, testIds\n",
    "\n",
    "def created_train_test(data,testIds,j):\n",
    "    j = j-1\n",
    "    test = data.iloc[np.array(testIds)[:,j]]\n",
    "    train = data.drop(np.array(testIds)[:,j], axis=0)\n",
    "    return train,test\n",
    "\n",
    "def create_folders_for_train_test_files(data,testIds,folder_name):\n",
    "    for i in np.arange(10):\n",
    "        folder = i+1\n",
    "        train,test = created_train_test(data,testIds,j=folder)\n",
    "        test_y = pd.DataFrame({'Sale_Price':test['Sale_Price']})\n",
    "        test = test.drop(['Sale_Price'],axis=1)\n",
    "        print (\"Folder: {} Created - Training Set Size:{} - Test Set Size:{}\".format(folder,train.shape,test.shape))\n",
    "        \n",
    "        folder_name_final_ = folder_name+\"folder_\"+np.str(folder)\n",
    "        #Create the Directory, if not exists\n",
    "        if not os.path.exists(folder_name_final_):\n",
    "            os.mkdir(folder_name_final_)\n",
    "\n",
    "        train.to_csv(folder_name_final_+\"/train.csv\",index=False)\n",
    "        test.to_csv(folder_name_final_+\"/test.csv\",index=False)\n",
    "        test_y.to_csv(folder_name_final_+\"/y_test.csv\",index=False)\n",
    "    return True\n",
    "    \n",
    "\n",
    "def onehot_encoding(x_train_input,x_test_input):\n",
    "    train_num = x_train_input.shape[0]\n",
    "    test_num = x_test_input.shape[0]\n",
    "    df = [x_train_input,x_test_input]\n",
    "    df_train_test = pd.concat(df)\n",
    "    \n",
    "    #Below columns needs to be dropped because of High Imbalance in data\n",
    "    #\"Garage_Yr_Blt\" for now, as it has lots of NaN\n",
    "    \n",
    "    #Fill the na values to \"0\" for the feature 'Garage_Yr_Blt'\n",
    "    df_train_test['Garage_Yr_Blt'] = df_train_test['Garage_Yr_Blt'].fillna(0)\n",
    "    \n",
    "    drop_columns = ['Street', 'Utilities', 'Condition_2', 'Roof_Matl', 'Heating', \n",
    "                    'Pool_QC', 'Misc_Feature', 'Low_Qual_Fin_SF', 'Pool_Area', 'Longitude',\n",
    "                    'Latitude','Land_Slope','Bsmt_Half_Bath','Three_season_porch','Misc_Val'\n",
    "                    #,'Garage_Yr_Blt'\n",
    "                    ]\n",
    "    #Let's drop the column\n",
    "    df_train_test = df_train_test.drop(drop_columns,axis=1)\n",
    "    \n",
    "    #Label Encoder to transform the Categoricsal Variable\n",
    "    #lbe = LabelEncoder() -- This is to create the dummy value for all the Categorical value\n",
    "    ohe = OneHotEncoder()\n",
    "    \n",
    "    for col_name in df_train_test.columns[df_train_test.dtypes == 'object']:\n",
    "        df_get_dummies = pd.get_dummies(df_train_test[col_name],drop_first=True,prefix=col_name)\n",
    "        df_train_test=pd.concat([df_train_test,df_get_dummies],axis=1)\n",
    "        \n",
    "    #Drop all the categorical columns, as we have created the dummies columns\n",
    "    drop_cat_col_name= []\n",
    "    for col_name in df_train_test.columns[df_train_test.dtypes == 'object']:\n",
    "        drop_cat_col_name = np.append(drop_cat_col_name,col_name)\n",
    "    \n",
    "    df_train_test = df_train_test.drop(drop_cat_col_name,axis=1)\n",
    "    \n",
    "    #Split the Train & Test Data\n",
    "    x_train_return = df_train_test.iloc[0:train_num]\n",
    "    x_test_return = df_train_test.iloc[train_num:]\n",
    "    \n",
    "    return x_train_return,x_test_return\n",
    "\n",
    "\n",
    "def winsorization(x_train_input,x_test_input):\n",
    "    #Purposefully, removed the column = \"Three_season_porch\", \"Misc_Val\"\n",
    "    winsorization_cols = ['Lot_Frontage', 'Lot_Area', 'Mas_Vnr_Area', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', \n",
    "                          'Total_Bsmt_SF', 'Second_Flr_SF', 'First_Flr_SF', 'Gr_Liv_Area', 'Garage_Area',\n",
    "                          'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch',  \n",
    "                          'Screen_Porch']\n",
    "    quan_val = 0.95\n",
    "    for winso_columns in winsorization_cols:\n",
    "        col_quant_value = np.quantile(x_train_input[winso_columns],quan_val)\n",
    "        x_train_input[winso_columns][x_train_input[winso_columns] > col_quant_value] = col_quant_value\n",
    "        x_test_input[winso_columns][x_test_input[winso_columns] > col_quant_value] = col_quant_value\n",
    "        #print (\"Column : {} 95% Quantile: {}\".format(winso_columns,col_quant_value))\n",
    "        \n",
    "    return x_train_input,x_test_input\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "#\n",
    "# Shrinking Methods (Lasso)\n",
    "#\n",
    "#------------------------------------------------------------------------\n",
    "def lasso_model(x_train_lasso,y_train_lasso,x_test_lasso,y_test_lasso,print_ind=False):\n",
    "    \n",
    "    x_train_lasso_PID = x_train_lasso['PID']\n",
    "    x_test_lasso_PID = x_test_lasso['PID']\n",
    "    \n",
    "    x_train_lasso = x_train_lasso.drop(['PID'],axis=1)\n",
    "    x_test_lasso = x_test_lasso.drop(['PID'],axis=1)\n",
    "\n",
    "    split_ = 10\n",
    "    alpha_ = 0.0001\n",
    "    fold_ = 0\n",
    "    kf = KFold(n_splits=split_)\n",
    "\n",
    "    y_train_actual_lasso = np.zeros((x_train_lasso.shape[0],1))\n",
    "    y_train_predict_lasso = np.zeros((x_train_lasso.shape[0],1))\n",
    "    y_test_predict_lasso = np.zeros((x_test_lasso.shape[0],1))\n",
    "\n",
    "    y_test_predict_kfold = np.zeros((x_test_lasso.shape[0],split_))\n",
    "\n",
    "    y_train_predict_array = np.array(())\n",
    "    y_train_actual_array = np.array(())\n",
    "    for (train_idx,test_idx) in kf.split(x_train_lasso,y_train_lasso):\n",
    "        lasso_model = Lasso(alpha=alpha_)\n",
    "        lasso_model.fit(x_train_lasso.iloc[train_idx],y_train_lasso.iloc[train_idx])\n",
    "        y_train_predict = lasso_model.predict(x_train_lasso.iloc[test_idx])\n",
    "        y_test_predict  = lasso_model.predict(x_test_lasso)\n",
    "\n",
    "        y_train_actual_array = np.append(y_train_actual_array,y_train_lasso.iloc[test_idx])\n",
    "        y_train_predict_array = np.append(y_train_predict_array,y_train_predict)\n",
    "\n",
    "        y_test_predict_kfold[:,fold_] =  y_test_predict\n",
    "        \n",
    "        if (print_ind):\n",
    "            print (\"Lasso - Fold: {} - Error Validation: {:.3f}, Error Test: {:.3f}\".format(fold_,mean_squared_error(y_train_lasso.iloc[test_idx], y_train_predict, squared=False),mean_squared_error(y_test_lasso, y_test_predict, squared=False)))\n",
    "        fold_ = fold_ + 1\n",
    "\n",
    "    y_train_actual_lasso[:,0] = y_train_actual_array\n",
    "    y_train_predict_lasso[:,0] = y_train_predict_array\n",
    "\n",
    "    y_test_predict_lasso[:,0] = np.mean(y_test_predict_kfold,axis=1)\n",
    "    \n",
    "    df_submission = pd.DataFrame({'PID':x_test_lasso_PID,'Sale_Price':round(np.exp(pd.Series(y_test_predict_lasso[:,0])),1)})\n",
    "    \n",
    "    rmse_train = mean_squared_error(y_train_lasso, y_train_predict_lasso[:,0], squared=False)\n",
    "    rmse_test = mean_squared_error(y_test_lasso, y_test_predict_lasso[:,0], squared=False)\n",
    "    \n",
    "    if (print_ind):\n",
    "        print (\"Lasso - Lamda: {} - Overall Train Error: {:.3f} - Overall Test Error: {:.3f}\".format(alpha_,rmse_train,rmse_test))\n",
    "        \n",
    "    return rmse_train, rmse_test, df_submission\n",
    "\n",
    "    \n",
    "#------------------------------------------------------------------------\n",
    "#\n",
    "# Boosting Model (Xgboost)\n",
    "#\n",
    "#------------------------------------------------------------------------\n",
    "def xgboost_model(x_train_xgboost,y_train_xgboost,x_test_xgboost,y_test_xgboost,print_ind=False):\n",
    "    split_ = 10\n",
    "    max_depth_count_ = 0\n",
    "    colsample_bytree_ = 0.1\n",
    "    learning_rate_ = 0.04\n",
    "    max_depth_ = 25\n",
    "    alpha_ = 1\n",
    "    fold_ = 0\n",
    "    kf = KFold(n_splits=split_)\n",
    "    \n",
    "    x_train_xgboost_PID = x_train_xgboost['PID']\n",
    "    x_test_xgboost_PID = x_test_xgboost['PID']\n",
    "    \n",
    "    x_train_xgboost = x_train_xgboost.drop(['PID'],axis=1)\n",
    "    x_test_xgboost = x_test_xgboost.drop(['PID'],axis=1)\n",
    "    \n",
    "    y_train_actual_xgboost = np.zeros((x_train_xgboost.shape[0],1))\n",
    "    y_train_predict_xgboost = np.zeros((x_train_xgboost.shape[0],1))\n",
    "    y_test_predict_xgboost = np.zeros((x_test_xgboost.shape[0],1))\n",
    "\n",
    "    y_test_predict_kfold = np.zeros((x_test_xgboost.shape[0],split_))\n",
    "\n",
    "    y_train_predict_array = np.array(())\n",
    "    y_train_actual_array = np.array(())\n",
    "    for (train_idx,test_idx) in kf.split(x_train_xgboost,y_train_xgboost):\n",
    "        xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', \n",
    "                                  colsample_bytree = 0.1, \n",
    "                                  learning_rate = 0.04,\n",
    "                                  max_depth = 25, \n",
    "                                  alpha = 1, \n",
    "                                  n_estimators = 1000)\n",
    "\n",
    "        xg_reg.fit(x_train_xgboost.iloc[train_idx],y_train_xgboost.iloc[train_idx])\n",
    "        y_train_predict = xg_reg.predict(x_train_xgboost.iloc[test_idx])\n",
    "        y_test_predict  = xg_reg.predict(x_test_xgboost)\n",
    "\n",
    "        y_train_actual_array = np.append(y_train_actual_array,y_train_xgboost.iloc[test_idx])\n",
    "        y_train_predict_array = np.append(y_train_predict_array,y_train_predict)\n",
    "\n",
    "        y_test_predict_kfold[:,fold_] =  y_test_predict\n",
    "        \n",
    "        \n",
    "        if (print_ind):\n",
    "            print (\"Xgboost - Fold: {} - Error Validation: {:.3f}, Error Test: {:.3f}\".format(fold_,mean_squared_error(y_train_xgboost.iloc[test_idx], y_train_predict, squared=False),mean_squared_error(y_test_xgboost, y_test_predict, squared=False)))\n",
    "            \n",
    "        fold_ = fold_ + 1\n",
    "\n",
    "    y_train_actual_xgboost[:,0] = y_train_actual_array\n",
    "    y_train_predict_xgboost[:,0] = y_train_predict_array\n",
    "\n",
    "    y_test_predict_xgboost[:,0] = np.mean(y_test_predict_kfold,axis=1)\n",
    "    \n",
    "    df_submission = pd.DataFrame({'PID':x_test_xgboost_PID,'Sale_Price':round(np.exp(pd.Series(y_test_predict_xgboost[:,0])),1)})\n",
    "    \n",
    "    rmse_train = mean_squared_error(y_train_xgboost, y_train_predict_xgboost[:,0], squared=False)\n",
    "    rmse_test = mean_squared_error(y_test_xgboost, y_test_predict_xgboost[:,0], squared=False)\n",
    "    \n",
    "    \n",
    "    if (print_ind):\n",
    "        print (\"Xgboost - Lamda: {} - Overall Error Train: {:.3f} - Overall Error Test : {:.3f}\".format(alpha_,rmse_train,rmse_test))\n",
    "    \n",
    "    return rmse_train,rmse_test,df_submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: 1 Created - Training Set Size:(2051, 83) - Test Set Size:(879, 82)\n",
      "Folder: 2 Created - Training Set Size:(2051, 83) - Test Set Size:(879, 82)\n",
      "Folder: 3 Created - Training Set Size:(2051, 83) - Test Set Size:(879, 82)\n",
      "Folder: 4 Created - Training Set Size:(2051, 83) - Test Set Size:(879, 82)\n",
      "Folder: 5 Created - Training Set Size:(2051, 83) - Test Set Size:(879, 82)\n",
      "Folder: 6 Created - Training Set Size:(2051, 83) - Test Set Size:(879, 82)\n",
      "Folder: 7 Created - Training Set Size:(2051, 83) - Test Set Size:(879, 82)\n",
      "Folder: 8 Created - Training Set Size:(2051, 83) - Test Set Size:(879, 82)\n",
      "Folder: 9 Created - Training Set Size:(2051, 83) - Test Set Size:(879, 82)\n",
      "Folder: 10 Created - Training Set Size:(2051, 83) - Test Set Size:(879, 82)\n"
     ]
    }
   ],
   "source": [
    "#Load the Data\n",
    "folder_name = \"/users/Sushanta/Documents/GitHub/Illinois/CS598 Practical Statistical Learning/Project/data/\"\n",
    "#Load the dataset\n",
    "data, testIds = load_data(folder_name)\n",
    "#Create the 10 Folders and dump its associated train.csv and test.csv\n",
    "return_output = create_folders_for_train_test_files(data,\n",
    "                                                    testIds,\n",
    "                                                    folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder:1 |-| Lasso Train Error:0.126,Lasso Test Error:0.124 |-| Xgboost Train Error:0.129,Xgboost Test Error:0.127\n",
      "Folder:2 |-| Lasso Train Error:0.129,Lasso Test Error:0.114 |-| Xgboost Train Error:0.136,Xgboost Test Error:0.116\n",
      "Folder:3 |-| Lasso Train Error:0.127,Lasso Test Error:0.124 |-| Xgboost Train Error:0.131,Xgboost Test Error:0.127\n",
      "Folder:4 |-| Lasso Train Error:0.120,Lasso Test Error:0.133 |-| Xgboost Train Error:0.126,Xgboost Test Error:0.135\n",
      "Folder:5 |-| Lasso Train Error:0.122,Lasso Test Error:0.131 |-| Xgboost Train Error:0.125,Xgboost Test Error:0.136\n",
      "Folder:6 |-| Lasso Train Error:0.126,Lasso Test Error:0.124 |-| Xgboost Train Error:0.129,Xgboost Test Error:0.127\n",
      "Folder:7 |-| Lasso Train Error:0.129,Lasso Test Error:0.114 |-| Xgboost Train Error:0.135,Xgboost Test Error:0.116\n",
      "Folder:8 |-| Lasso Train Error:0.127,Lasso Test Error:0.124 |-| Xgboost Train Error:0.131,Xgboost Test Error:0.126\n"
     ]
    }
   ],
   "source": [
    "print_ind = False\n",
    "for i in np.arange(10):\n",
    "\n",
    "    train = pd.read_csv(folder_name+\"folder_\"+np.str(i+1)+\"/\"+\"train.csv\")\n",
    "    x_test = pd.read_csv(folder_name+\"folder_\"+np.str(i+1)+\"/\"+\"test.csv\")\n",
    "    y_test = pd.read_csv(folder_name+\"folder_\"+np.str(i+1)+\"/\"+\"y_test.csv\")\n",
    "    \n",
    "    #print (\"Folder :{} - Train Set Size:{} Test Set Size :{}\".format(i,train.shape,test.shape))\n",
    "    \n",
    "    y_train = np.log(train['Sale_Price'])\n",
    "    x_train = train.drop(['Sale_Price'],axis=1)\n",
    "    y_test = np.log(y_test)\n",
    "    #x_test = test.drop(['Sale_Price'],axis=1)\n",
    "    \n",
    "    x_train_onehot,x_test_onehot = onehot_encoding(x_train,x_test)\n",
    "    \n",
    "    if (print_ind):\n",
    "        print (\"After One Hot - Train:{} Test:{}\".format(x_train_onehot.shape,x_test_onehot.shape))\n",
    "    \n",
    "    x_train_final,x_test_final = winsorization(x_train_onehot,x_test_onehot)\n",
    "    \n",
    "    if (print_ind):\n",
    "        print (\"After Winsor  - Train:{} Test:{}\".format(x_train_final.shape,x_test_final.shape))\n",
    "        \n",
    "    #Calling the Model - 1\n",
    "    rmse_train_lasso,rmse_test_lasso,df_submission_lasso = lasso_model(x_train_final,y_train,x_test_final,y_test)\n",
    "    #rmse_train_lasso,rmse_test_lasso,df_submission_lasso = lasso_model(x_train_onehot,y_train,x_test_onehot,y_test)\n",
    "    #Calling the Model - 2    \n",
    "    rmse_train_xgboost,rmse_test_xgboost,df_submission_xgboost = xgboost_model(x_train_final,y_train,x_test_final,y_test)\n",
    "    #rmse_train_xgboost,rmse_test_xgboost,df_submission_xgboost = xgboost_model(x_train_onehot,y_train,x_test_onehot,y_test)\n",
    "    \n",
    "    #Write the Submission File into the Folder\n",
    "    df_submission_lasso.to_csv((folder_name+\"folder_\"+np.str(i+1)+\"/\"+\"mysubmission1.txt\"),index=False)\n",
    "    df_submission_xgboost.to_csv((folder_name+\"folder_\"+np.str(i+1)+\"/\"+\"mysubmission2.txt\"),index=False)\n",
    "    \n",
    "    print (\"Folder:{} |-| Lasso Train Error:{:.3f},Lasso Test Error:{:.3f} |-| Xgboost Train Error:{:.3f},Xgboost Test Error:{:.3f}\".format(i+1,rmse_train_lasso,rmse_test_lasso,rmse_train_xgboost,rmse_test_xgboost))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After One Hot - Train:(2051, 267) Test:(879, 267)\n",
    "#After Winsor  - Train:(2051, 267) Test:(879, 267)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder:1 |-| Lasso Train Error:0.126,Lasso Test Error:0.124 |-| Xgboost Train Error:0.129,Xgboost Test Error:0.127\n",
    "Folder:2 |-| Lasso Train Error:0.129,Lasso Test Error:0.114 |-| Xgboost Train Error:0.136,Xgboost Test Error:0.116\n",
    "Folder:3 |-| Lasso Train Error:0.127,Lasso Test Error:0.124 |-| Xgboost Train Error:0.131,Xgboost Test Error:0.127\n",
    "Folder:4 |-| Lasso Train Error:0.120,Lasso Test Error:0.133 |-| Xgboost Train Error:0.126,Xgboost Test Error:0.135\n",
    "Folder:5 |-| Lasso Train Error:0.122,Lasso Test Error:0.131 |-| Xgboost Train Error:0.125,Xgboost Test Error:0.136\n",
    "Folder:6 |-| Lasso Train Error:0.126,Lasso Test Error:0.124 |-| Xgboost Train Error:0.129,Xgboost Test Error:0.127\n",
    "Folder:7 |-| Lasso Train Error:0.129,Lasso Test Error:0.114 |-| Xgboost Train Error:0.135,Xgboost Test Error:0.116\n",
    "Folder:8 |-| Lasso Train Error:0.127,Lasso Test Error:0.124 |-| Xgboost Train Error:0.131,Xgboost Test Error:0.126\n",
    "Folder:9 |-| Lasso Train Error:0.120,Lasso Test Error:0.133 |-| Xgboost Train Error:0.127,Xgboost Test Error:0.136\n",
    "Folder:10 |-| Lasso Train Error:0.122,Lasso Test Error:0.131 |-| Xgboost Train Error:0.125,Xgboost Test Error:0.136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder 1  - RMSE Lasso:0.124 - RMSE Xgboost:0.126\n",
    "#Folder 2  - RMSE Lasso:0.114 - RMSE Xgboost:0.114\n",
    "#Folder 3  - RMSE Lasso:0.126 - RMSE Xgboost:0.126\n",
    "#Folder 4  - RMSE Lasso:0.132 - RMSE Xgboost:0.132\n",
    "#Folder 5  - RMSE Lasso:0.131 - RMSE Xgboost:0.131\n",
    "#Folder 6  - RMSE Lasso:0.124 - RMSE Xgboost:0.124\n",
    "#Folder 7  - RMSE Lasso:0.114 - RMSE Xgboost:0.114\n",
    "#Folder 8  - RMSE Lasso:0.126 - RMSE Xgboost:0.126\n",
    "#Folder 9  - RMSE Lasso:0.132 - RMSE Xgboost:0.132\n",
    "#Folder 10 - RMSE Lasso:0.131 - RMSE Xgboost:0.131"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
