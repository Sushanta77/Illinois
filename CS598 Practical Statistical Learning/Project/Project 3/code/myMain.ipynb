{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import ttest_ind\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train_test(x_train, x_test):\n",
    "    \n",
    "    #Remove the HTML tags from the review\n",
    "    x_train[\"review\"] = x_train[\"review\"].str.replace('<br /><br />',' ')\n",
    "    x_test [\"review\"] = x_test[\"review\"].str.replace('<br /><br />',' ')\n",
    "\n",
    "    #Defined the Stopwords\n",
    "    stop_words=['the','with','he','she','also','made','had','out','in','his','hers','there','was','then'] \n",
    "    \n",
    "    #Tfidf Vectorization\n",
    "    cv = TfidfVectorizer(stop_words=stop_words, ngram_range=(1,2), min_df=20, max_df=0.3)\n",
    "    X_train = cv.fit_transform(train[\"review\"]).toarray()\n",
    "    X_test  = cv.transform(test[\"review\"]).toarray()\n",
    "    \n",
    "    #Extract the Vocabulary Size\n",
    "    vocab = np.array(cv.get_feature_names())\n",
    "\n",
    "    return X_train,X_test, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Vocab\n",
    "myvocab_list = np.loadtxt('myvocab.txt', dtype=np.str, delimiter='\\n')\n",
    "\n",
    "#Load the Train, Test, Test_y data\n",
    "train = pd.read_csv(\"train.tsv\",sep = \"\\t\")\n",
    "test = pd.read_csv(\"test.tsv\", sep = \"\\t\")\n",
    "\n",
    "#Retrieve the y_Train and y_test\n",
    "y_train = train[\"sentiment\"]\n",
    "\n",
    "#Remove the Stopwords and TFIDF Vectorization\n",
    "X_train,X_test,vocab = prep_train_test(train.copy(), test.copy())\n",
    "indices = np.where(np.in1d(vocab, myvocab_list))[0]\n",
    "X_train = X_train[:, indices].copy()\n",
    "X_test  = X_test [:, indices].copy()\n",
    "    \n",
    "#Logistic Model Building\n",
    "model = LogisticRegression(penalty='l2',C=17, random_state=125247)\n",
    "_ = model.fit(X_train, y_train)\n",
    "probs = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "df_probs = pd.DataFrame(probs)\n",
    "df_probs = df_probs.rename(columns={0:'prob'})\n",
    "\n",
    "mysubmission = pd.concat([test[[\"id\"]], df_probs.reindex(test[[\"id\"]].index)], axis=1)\n",
    "\n",
    "mysubmission.to_csv(\"mysubmission.txt\",sep=\"\\t\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
