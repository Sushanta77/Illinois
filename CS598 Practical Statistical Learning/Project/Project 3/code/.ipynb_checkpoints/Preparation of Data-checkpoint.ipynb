{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/alldata.tsv\",sep=\"\\t\")\n",
    "testIds = pd.read_csv(\"../data/splits_S21.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sushanta/Documents/GitHub_Old/Illinois/CS598 Practical Statistical Learning/Project/Project 3/code\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sushanta/Documents/GitHub_Old/Illinois/CS598 Practical Statistical Learning/Project/Project 3/data\n"
     ]
    }
   ],
   "source": [
    "cd ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 261992\r\n",
      "-rwxr-xr-x@ 1 sushanta  staff  66212309 Oct 19  2019 \u001b[31mIMDB Dataset.csv\u001b[m\u001b[m\r\n",
      "-rw-r--r--@ 1 sushanta  staff  66264462 Apr 19 18:47 alldata.tsv\r\n",
      "-rw-r--r--@ 1 sushanta  staff    722219 Apr 19 18:59 splits_S21.csv\r\n",
      "-rw-r--r--@ 1 sushanta  staff     18785 Apr 26 14:18 myvocab.txt\r\n",
      "drwxr-xr-x  5 sushanta  staff       160 Apr 26 15:46 \u001b[34msplit_0\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  5 sushanta  staff       160 Apr 26 15:46 \u001b[34msplit_1\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  5 sushanta  staff       160 Apr 26 15:46 \u001b[34msplit_2\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  5 sushanta  staff       160 Apr 26 15:46 \u001b[34msplit_3\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  5 sushanta  staff       160 Apr 26 15:46 \u001b[34msplit_4\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -ltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(5):\n",
    "    print (\"Split:{}\".format(i))\n",
    "    test_ids = np.array(testIds)[:,i]\n",
    "    test_ids_index = pd.Int64Index(test_ids)\n",
    "    test_ids_index_bool = data.index.isin(test_ids_index)\n",
    "    train = data[~data[\"id\"].isin(test_ids)][[\"id\", \"sentiment\", \"review\"]]\n",
    "    test = data[data[\"id\"].isin(test_ids)][[\"id\", \"review\"]]\n",
    "    test_y = data[data[\"id\"].isin(test_ids)][[\"id\", \"sentiment\", \"score\"]]\n",
    "    \n",
    "    #Create the Folder (if not exists)\n",
    "    dir = \"../data/split_\"+str(i)\n",
    "    print (\"Dir:{}\".format(dir))\n",
    "    if not(os.path.exists(dir)):\n",
    "        os.mkdir(dir)\n",
    "    train.to_csv(\"../data/split_\"+str(i)+\"/train.tsv\",sep=\"\\t\",index=False)\n",
    "    test.to_csv(\"../data/split_\"+str(i)+\"/test.tsv\",sep=\"\\t\",index=False)\n",
    "    test_y.to_csv(\"../data/split_\"+str(i)+\"/test_y.tsv\",sep=\"\\t\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "# End of the Code of the Data Preperation\n",
    "#---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_square_bracket(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "\n",
    "def simple_stemer(text):\n",
    "    ps = PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def remove_noise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_square_bracket(text)\n",
    "    #text = simple_stemer(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_special_characters(text)\n",
    "    return text\n",
    "\n",
    "def vocab_list_creation(text):\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Naturally film  main themes mortality  nostalg...\n",
       "1        movie disaster within disaster film full great...\n",
       "2         movie kids saw tonight child loved it one poi...\n",
       "3        Afraid Dark left impression several different ...\n",
       "4        accurate depiction small time mob life filmed ...\n",
       "                               ...                        \n",
       "49995    seems like consideration gone IMDb reviews fil...\n",
       "49996     believe made film Completely unnecessary firs...\n",
       "49997    Guy loser  get girls  needs build  picked stro...\n",
       "49998    30 minute documentary Buuel made early 1930  o...\n",
       "49999    saw movie child broke heart  story unfinished ...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             completeness\n",
       "1                               Diverting Scares movieEven\n",
       "2            Milne \\WinniethePooh Tigger Kanga faceI Lumpy\n",
       "3                         monsterAt bead sympatheticAfraid\n",
       "4                                               agoA Pesce\n",
       "                               ...                        \n",
       "49995    sourceHere tDress interestOne manNot thoughUnl...\n",
       "49996                                           Daeseleire\n",
       "49997                                      Animal\\ nice310\n",
       "49998             receded chides Teaching shortsightedness\n",
       "49999    unfairness Chirin Chirin \\maybe tomorrow\\ intr...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review\"].apply(lambda x: \" \".join(x for x in x.split() if x not in final_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"../data/split_0/train.csv\")\n",
    "x_test = pd.read_csv(\"../data/split_0/test.csv\")\n",
    "y_train = pd.read_csv(\"../data/split_0/test_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape: (25000, 3)\n",
      "X Test Shape: (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "print (\"X Train Shape: {}\".format(x_train.shape))\n",
    "print (\"X Test Shape: {}\".format(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_train.append(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data['review'] = x_data[\"review\"].apply(remove_noise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data[\"review\"] = x_data[\"review\"].apply(lambda x: \" \".join(x for x in x.split() if x not in final_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "tokenizer = ToktokTokenizer()\n",
    "tokens = tokenizer.tokenize(data[\"review\"][0])\n",
    "tokens = [token.strip() for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data[\"review\"].apply(remove_noise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Naturally film  main themes mortality  nostalg...\n",
       "1        Afraid Dark left impression several different ...\n",
       "2        one biggest misfires ever  script nice could e...\n",
       "3        one movies watched  wondered  watch  find inte...\n",
       "4        movie dreadful Biblically inaccurate Moses 80 ...\n",
       "                               ...                        \n",
       "24995    Sometimes wonder people get funding create mov...\n",
       "24996    student film  several years concept cyber  kun...\n",
       "24997    Unimaginably stupid  redundant humiliating clo...\n",
       "24998    seems like consideration gone IMDb reviews fil...\n",
       "24999    Guy loser  get girls  needs build  picked stro...\n",
       "Name: review, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
    "cv_train_reviews=cv.fit_transform(x_data['review'][:25000])\n",
    "cv_test_reviews=cv.fit_transform(x_data['review'][25000:])\n",
    "#cv_test_reviews=cv.fit_transform(x_data[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x4335253 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4335253 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv_train_reviews\n",
    "cv_test_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "lr_bow=lr.fit(cv_train_reviews,x_train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12527\n",
       "0    12473\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 4335253 features per sample; expecting 4344131",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-392-65e4641c5bae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_test_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 273\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 4335253 features per sample; expecting 4344131"
     ]
    }
   ],
   "source": [
    "pd.Series(lr.predict(cv_test_reviews)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12527\n",
       "1    12473\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Series(' '.join(data[\"review\"]).split()).value_counts().reset_index()\n",
    "df = df.rename(columns={'index':'Word',0:'Word_Count'})\n",
    "final_word = set(df[df['Word_Count'] > 10]['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31652"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Word_Count'] > 10].to_csv(\"../data/myvocab.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11       1681\n",
       "12       1419\n",
       "13       1264\n",
       "14       1112\n",
       "15       1066\n",
       "         ... \n",
       "17776       1\n",
       "1368        1\n",
       "9500        1\n",
       "3321        1\n",
       "2049        1\n",
       "Name: Word_Count, Length: 1665, dtype: int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Word_Count'] > 10]['Word_Count'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
