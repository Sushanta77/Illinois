{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Python Packages required to run this program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import ttest_ind\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the all Data TSV file and Extract the \"Sentiment\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Train, Test, Test_y data\n",
    "x_data = pd.read_csv(\"../data/alldata.tsv\",sep=\"\\t\")\n",
    "y_train = x_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the following trasnformation in the \"review\" text\n",
    "(1) Remove all the HTML tags <br /><br />\n",
    "\n",
    "(2) Using the TErm Frequency (TF) and Inverted Document Frequency (IDF) to Vectorized the Text. In the same time, remove the stopwords which is defined in the stop_words list\n",
    "\n",
    "(3) Convert the Input data into the transformed Tfidf Vectorized data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data[\"review\"] = x_data[\"review\"].str.replace('<br /><br />',' ')\n",
    "#Define the stopwords\n",
    "stop_words=['the','with','he','she','also','made','had','out','in','his','hers','there','was','then'] \n",
    "\n",
    "#Tfidf Vectorizer\n",
    "cv = TfidfVectorizer(stop_words=stop_words, ngram_range=(1,2), min_df=20, max_df=0.3)\n",
    "#Transform the Data in Tfidf Vector\n",
    "X_data = cv.fit_transform(x_data[\"review\"]).toarray()\n",
    "#Get the Vocablist\n",
    "vocab = np.array(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the ttest_ind from the scipy packages to calculate the  T-test for the means of two independent samples\n",
    "\n",
    "(1) Generate & Store the tstat score against each word retrieved from the above code\n",
    "\n",
    "(2) Generate & Store the tstat score with absolute value for each word retrieved from the above code\n",
    "\n",
    "(3) Sort the value based on the magn_tstat in descending order\n",
    "\n",
    "(4) Pick the first 1999 vocab from the list based on the magn_tstat values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = ttest_ind(X_data[y_train==1, :], X_data[y_train==0, :])\n",
    "\n",
    "voc_df = pd.DataFrame({'tstat': t_test.statistic, 'word': vocab})\n",
    "voc_df['magn_tstat'] = voc_df.tstat.abs()\n",
    "voc_df = voc_df.sort_values('magn_tstat',ascending=False)\n",
    "\n",
    "\n",
    "voc_df = voc_df.head(1999)\n",
    "#voc_df['weight'] = np.power((voc_df.magn_tstat - voc_df.magn_tstat.min()), 1.2)\n",
    "#voc_df['weight'] = (voc_df['weight'] / voc_df.weight.max() * 21 * np.sign(voc_df.tstat)).round(4)\n",
    "\n",
    "#voc_df[['word','weight']].to_csv('../data/word_weights.csv', index=False)\n",
    "np.savetxt('../data/myvocab.txt',voc_df.word.values, fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
