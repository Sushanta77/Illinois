{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Used in Coding Assignment\n",
    "Below code is for import all Python Packages\n",
    "Below Packges have imported & its purpose\n",
    "\n",
    "(1) numpy - numerical python scripts, to store array, list and other data\n",
    "\n",
    "(2) scipy.stats - multivariate_normal to calculate the probability density function (pdf)\n",
    "\n",
    "(2) matplotlib.pyplot - matplotlib's Pyplot packages to plot the data with the predicted mean from the EM's algo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Name = \"log_sub_exp\"\n",
    "Below Function - \"generate_center\" is to generate the 20 Centers\n",
    "\n",
    "The function takes the following inpurt and return the 20 2 dimensional array\n",
    "\n",
    "(1) n = Number of Centers to generate. It will be 20\n",
    "\n",
    "(2) mu1 = The mean against which 10 centers will be generated. It will be (0,1)\n",
    "\n",
    "(3) mu2 = The mean against which 10 centers will be generated. It will be (1,0)\n",
    "\n",
    "(4) sigma = The standard deviation against which the centers will be generated\n",
    "\n",
    "\n",
    "# Function Name = \"loglikelihood\"\n",
    "\n",
    "\n",
    "The function generates the 20 centers, 10 centers from mean = (0,1) and other 10 center would be from the mean = (1,0) with standard devitation of 0.5. Both the center (10 each) needs to be appended and return back to the caller\n",
    "\n",
    "The numpy function np.random.normal is used to generate the centers.\n",
    "\n",
    "The function would be called from the caller with seed, so it would be consistently same accross multiple runs\n",
    "\n",
    "Following formula is used to generate the 20 centers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(Z):\n",
    "    #Compute log(\\sum_i exp(Z_i)) for Z (array)\n",
    "    return np.max(Z) + np.log(np.sum(np.exp(Z - np.max(Z))))\n",
    "\n",
    "def loglikelihood(data, weights, means, covs):\n",
    "    #Compute the loglikelihood of the data for a Gaussian mixture model\n",
    "    num_clusters = len(means)\n",
    "    num_dim = len(data[0])\n",
    "    \n",
    "    ll = 0\n",
    "    for d in data:\n",
    "        \n",
    "        Z = np.zeros(num_clusters)\n",
    "        for k in range(num_clusters):\n",
    "            \n",
    "            # Compute (x-mu)^T * Sigma^{-1} * (x-mu)\n",
    "            delta = np.array(d) - means[k]\n",
    "            exponent_term = np.dot(delta.T, np.dot(np.linalg.inv(covs[k]), delta))\n",
    "            \n",
    "            # Compute loglikelihood contribution for this data point and this cluster\n",
    "            Z[k] += np.log(weights[k])\n",
    "            Z[k] -= 1/2. * (num_dim * np.log(2*np.pi) + np.log(np.linalg.det(covs[k])) + exponent_term)\n",
    "            \n",
    "        # Increment loglikelihood contribution of this data point across all clusters\n",
    "        ll += log_sum_exp(Z)\n",
    "        \n",
    "    return ll"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Name = \"EStep\"\n",
    "\n",
    "Below Function - \"generate_data\" is to generate data for training & test sets\n",
    "The function takes the following inpurt and return the training & test data of 2 dimensions\n",
    "\n",
    "(1) n = Number of Centers to generate. It will be 100 for training and 5000 for tests. As for each class we need to generate the data of this size\n",
    "\n",
    "(2) center = Pass the entire 20 centers which is generated from the above function\n",
    "\n",
    "(3) sigma = the standard deviation against which the training & test will be generated\n",
    "\n",
    "\n",
    "The function takes a random number from the centers (1st 10 for the Class 0 and next 10 for the Class 1) and generates the trainning and test sets. For the training sets, 100 data will be generated with class 0 (from the random centers choose from the 1st 10 centers) and next 100 data will be generated with class 1 (from the random centers choose from the last 10 centers). Both the data vertically stacked and sends to the caller. The same will be done for the test sets, now instead of 100 each, it will be 5000 for the class 0 and next 5000 for the class 1.\n",
    "\n",
    "Following is the formula to generate the mean however the mean would be used from the centers rather (0,1) or (1,0) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E-step\n",
    "def EStep(data, init_means, init_covariances, init_weights):\n",
    "    \n",
    "    # initialize the variable\n",
    "    means = init_means[:]\n",
    "    covariances = init_covariances[:]\n",
    "    weights = init_weights[:]\n",
    "    \n",
    "    num_data = len(data)\n",
    "    num_dim = len(data[0])    \n",
    "    num_clusters = len(means)\n",
    "\n",
    "    # Initialize resp\n",
    "    resp = np.zeros((num_data, num_clusters))\n",
    "    \n",
    "    #Loop\n",
    "    for j in range(num_data):\n",
    "        for k in range(num_clusters):\n",
    "            resp[j, k] = weights[k]*multivariate_normal.pdf(data[j],means[k],covariances[k])\n",
    "        row_sums = resp.sum(axis=1)[:, np.newaxis]\n",
    "        resp = resp / row_sums # normalize the responsibility\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Name = \"MStep\"\n",
    "\n",
    "Below Function - \"generate_data\" is to generate data for training & test sets\n",
    "The function takes the following inpurt and return the training & test data of 2 dimensions\n",
    "\n",
    "(1) n = Number of Centers to generate. It will be 100 for training and 5000 for tests. As for each class we need to generate the data of this size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M-step        \n",
    "def MStep(data, init_means, init_covariances, init_weights, resp):\n",
    "    \n",
    "    # Make copies of initial parameters, which we will update during each iteration\n",
    "    means = init_means[:]\n",
    "    covariances = init_covariances[:]\n",
    "    weights = init_weights[:]\n",
    "\n",
    "    num_data = len(data)\n",
    "    num_dim = len(data[0])    \n",
    "    num_clusters = len(means)\n",
    "    \n",
    "    # Initialize some useful variables\n",
    "    ll = loglikelihood(data, weights, means, covariances)\n",
    "    ll_trace = [ll]\n",
    "    \n",
    "    counts = np.sum(resp, axis=0)\n",
    "    \n",
    "    for k in range(num_clusters):\n",
    "        weights[k] = counts[k]/num_data\n",
    "        weighted_sum = 0\n",
    "        for j in range(num_data):\n",
    "            weighted_sum += (resp[j,k]*data[j])\n",
    "        means[k] = weighted_sum/counts[k]\n",
    "\n",
    "        weighted_sum = np.zeros((num_dim, num_dim))\n",
    "        for j in range(num_data):\n",
    "            weighted_sum += (resp[j,k]*np.outer(data[j]-means[k],data[j]-means[k]))\n",
    "        covariances[k] = weighted_sum/counts[k]\n",
    "\n",
    "    # Compute the loglikelihood at this iteration\n",
    "    ll_latest = loglikelihood(data, weights, means, covariances)\n",
    "    ll_trace.append(ll_latest)\n",
    "\n",
    "    ll = ll_latest\n",
    "    \n",
    "    out = {'weights': weights, 'means': means, 'covs': covariances, 'loglik': ll_trace, 'resp': resp}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myEM(data, init_means, init_covariances, init_weights, maxiter=20):\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        response = EStep(data, init_means, init_covariances, init_weights)\n",
    "        out = MStep(data, init_means, init_covariances, init_weights, response)\n",
    "        print(\"Iteration : {} - weights:{} means:{} sigma:{}\".format(i,out['weights'],out['means'],out['covs']))\n",
    "        \n",
    "        #plt.figure(figsize=(12,8))\n",
    "        #plt.scatter(X[:,0],X[:,1])\n",
    "        #plt.scatter(means[0][0], means[0][1], color = \"red\")\n",
    "        #plt.scatter(means[1][0], means[1][1],color=\"orange\")\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Function\n",
    "\n",
    "### Load the Data (Faithful.txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully...\n",
      "First 10 rows from the Faithful Dataset\n",
      "[[ 1.8   54.   ]\n",
      " [ 3.333 74.   ]\n",
      " [ 2.283 62.   ]\n",
      " [ 4.533 85.   ]\n",
      " [ 2.883 55.   ]\n",
      " [ 4.7   88.   ]\n",
      " [ 3.6   85.   ]\n",
      " [ 1.95  51.   ]\n",
      " [ 4.35  85.   ]\n",
      " [ 1.833 54.   ]]\n",
      "------------------------------------------\n",
      "Size of the Dataset is: (272, 2)\n"
     ]
    }
   ],
   "source": [
    "#Load the Data\n",
    "X = np.loadtxt('../data/Faithful.txt')\n",
    "print (\"Data Loaded Successfully...\")\n",
    "print (\"First 10 rows from the Faithful Dataset\")\n",
    "print (X[1:11,:])\n",
    "print (\"------------------------------------------\")\n",
    "print (\"Size of the Dataset is: {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Function myFunc (Two Cluster)\n",
    "\n",
    "(1) weights / prob = \n",
    "          [0.50062804,0.49937196]\n",
    "\n",
    "(2) means = \n",
    "          [3.4459639,69.8433735]\n",
    "          [3.6217053,72.1578947]\n",
    "          [3.3893617,70.5531915]\n",
    "\n",
    "(3) covariances / sigma = \n",
    "          [1.2877935,13.842302]\n",
    "          [13.8423020,183.208932]\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 1 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 2 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 3 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 4 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 5 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 6 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 7 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 8 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 9 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 10 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 11 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 12 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 13 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 14 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 15 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 16 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 17 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 18 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 19 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "weight: [0.5006526542469939, 0.49934734575300627]\n",
      "means: [array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])]\n",
      "sigma: [array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n"
     ]
    }
   ],
   "source": [
    "#Two Cluster Initialization\n",
    "init_weights = [0.50062804,0.49937196]\n",
    "init_means = [np.array([3.467750,70.132353]),np.array([3.5078162,71.6617647])]\n",
    "init_covs = [np.array([[1.2975376,13.9110994],[13.911099,183.559040]])]*2\n",
    "\n",
    "itmax = 20\n",
    "out = myEM(data=X, init_means = init_means, init_covariances = init_covs, init_weights = init_weights, maxiter=itmax)\n",
    "print (\"------------------------------------------------------------------------------------------------------------\")\n",
    "print (\"weight: {}\".format(out['weights']))\n",
    "print (\"means: {}\".format(out['means']))\n",
    "print (\"sigma: {}\".format(out['covs']))\n",
    "print (\"------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Function myFunc (Three Cluster)\n",
    "\n",
    "##### Below are the Initialization of the Parameters\n",
    "(1) weights / prob = \n",
    "          [0.30514706,0.34926471,0.34558824]\n",
    "\n",
    "(2) means = \n",
    "          [3.4459639,69.8433735]\n",
    "          [3.6217053,72.1578947]\n",
    "          [3.3893617,70.5531915]\n",
    "\n",
    "(3) covariances / sigma = \n",
    "          [1.2877935,13.842302]\n",
    "          [13.8423020,183.208932]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 1 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 2 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 3 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 4 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 5 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 6 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 7 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 8 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 9 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 10 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 11 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 12 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 13 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 14 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 15 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 16 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 17 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 18 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n",
      "Iteration : 19 - weights:[0.5006526542469939, 0.49934734575300627] means:[array([ 3.46776969, 70.13260977]), array([ 3.5078488 , 71.66350617])] sigma:[array([[  1.32238528,  14.18954649],\n",
      "       [ 14.18954649, 185.91012994]]), array([[  1.27262438,  13.63188485],\n",
      "       [ 13.63188485, 181.19953113]])]\n"
     ]
    }
   ],
   "source": [
    "#Three Cluster Initialization\n",
    "initial_weights = [0.30514706,0.34926471,0.34558824]\n",
    "initial_means = [np.array([3.4459639,69.8433735]),np.array([3.6217053,72.1578947]),np.array([3.3893617,70.5531915])]\n",
    "initial_covs = [np.array([[1.2877935,13.842302],[13.8423020,183.208932]])]*3\n",
    "\n",
    "itmax = 20\n",
    "out = myEM(data=X, init_means = init_means, init_covariances = init_covs, init_weights = init_weights, maxiter=itmax)\n",
    "print (\"------------------------------------------------------------------------------------------------------------\")\n",
    "print (\"weight: {}\".format(out['weights']))\n",
    "print (\"means: {}\".format(out['means']))\n",
    "print (\"sigma: {}\".format(out['covs']))\n",
    "print (\"------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
