{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(Z):\n",
    "    \"\"\" Compute log(\\sum_i exp(Z_i)) for some array Z.\"\"\"\n",
    "    return np.max(Z) + np.log(np.sum(np.exp(Z - np.max(Z))))\n",
    "\n",
    "def loglikelihood(data, weights, means, covs):\n",
    "    \"\"\" Compute the loglikelihood of the data for a Gaussian mixture model with the given parameters. \"\"\"\n",
    "    num_clusters = len(means)\n",
    "    num_dim = len(data[0])\n",
    "    \n",
    "    ll = 0\n",
    "    for d in data:\n",
    "        \n",
    "        Z = np.zeros(num_clusters)\n",
    "        for k in range(num_clusters):\n",
    "            \n",
    "            # Compute (x-mu)^T * Sigma^{-1} * (x-mu)\n",
    "            delta = np.array(d) - means[k]\n",
    "            exponent_term = np.dot(delta.T, np.dot(np.linalg.inv(covs[k]), delta))\n",
    "            \n",
    "            # Compute loglikelihood contribution for this data point and this cluster\n",
    "            Z[k] += np.log(weights[k])\n",
    "            Z[k] -= 1/2. * (num_dim * np.log(2*np.pi) + np.log(np.linalg.det(covs[k])) + exponent_term)\n",
    "            \n",
    "        # Increment loglikelihood contribution of this data point across all clusters\n",
    "        ll += log_sum_exp(Z)\n",
    "        \n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d0d4c54ee07a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'means' is not defined"
     ]
    }
   ],
   "source": [
    "len(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM(data, init_means, init_covariances, init_weights, maxiter=20):\n",
    "    \n",
    "    # Make copies of initial parameters, which we will update during each iteration\n",
    "    means = init_means[:]\n",
    "    covariances = init_covariances[:]\n",
    "    weights = init_weights[:]\n",
    "    \n",
    "    # Infer dimensions of dataset and the number of clusters\n",
    "    num_data = len(data)\n",
    "    num_dim = len(data[0])\n",
    "    num_clusters = len(means)\n",
    "    \n",
    "    # Initialize some useful variables\n",
    "    resp = np.zeros((num_data, num_clusters))\n",
    "    ll = loglikelihood(data, weights, means, covariances)\n",
    "    ll_trace = [ll]\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        # E-step: compute responsibilities\n",
    "        for j in range(num_data):\n",
    "            for k in range(num_clusters):\n",
    "                resp[j, k] = weights[k]*multivariate_normal.pdf(data[j],means[k],covariances[k])\n",
    "        row_sums = resp.sum(axis=1)[:, np.newaxis]\n",
    "        resp = resp / row_sums # normalize over all possible cluster assignments\n",
    "\n",
    "        # M-step\n",
    "        counts = np.sum(resp, axis=0)\n",
    "        print (\"num_data:{}\".format(num_data))\n",
    "        for k in range(num_clusters):\n",
    "            weights[k] = counts[k]/num_data\n",
    "            weighted_sum = 0\n",
    "            for j in range(num_data):\n",
    "                weighted_sum += (resp[j,k]*data[j])\n",
    "            means[k] = weighted_sum/counts[k]\n",
    "            \n",
    "            weighted_sum = np.zeros((num_dim, num_dim))\n",
    "            for j in range(num_data):\n",
    "                weighted_sum += (resp[j,k]*np.outer(data[j]-means[k],data[j]-means[k]))\n",
    "            covariances[k] = weighted_sum/counts[k]\n",
    "        \n",
    "        # Compute the loglikelihood at this iteration\n",
    "        ll_latest = loglikelihood(data, weights, means, covariances)\n",
    "        ll_trace.append(ll_latest)\n",
    "        \n",
    "        ll = ll_latest\n",
    "    \n",
    "        print(\"Iteration : {} - means:{}\".format(i,means))\n",
    "        \n",
    "        #plt.figure(figsize=(12,8))\n",
    "        #plt.scatter(X[:,0],X[:,1])\n",
    "        #plt.scatter(means[0][0], means[0][1], color = \"red\")\n",
    "        #plt.scatter(means[1][0], means[1][1],color=\"orange\")\n",
    "    \n",
    "    out = {'weights': weights, 'means': means, 'covs': covariances, 'loglik': ll_trace, 'resp': resp}\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Data\n",
    "X = np.loadtxt('data/Faithful.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_data:272\n",
      "Iteration : 0 - means:[array([ 3.44630616, 69.85042535]), array([ 3.62064297, 72.13856517]), array([ 3.39011184, 70.56633575])]\n",
      "num_data:272\n",
      "Iteration : 1 - means:[array([ 3.43660804, 69.72137797]), array([ 3.63621595, 72.31525135]), array([ 3.38291679, 70.50148676])]\n",
      "num_data:272\n",
      "Iteration : 2 - means:[array([ 3.42351954, 69.54024329]), array([ 3.65789994, 72.5610335 ]), array([ 3.37254255, 70.41275219])]\n",
      "num_data:272\n",
      "Iteration : 3 - means:[array([ 3.40734429, 69.31384542]), array([ 3.68530248, 72.8707839 ]), array([ 3.35908913, 70.29901903])]\n",
      "num_data:272\n",
      "Iteration : 4 - means:[array([ 3.38730876, 69.03567538]), array([ 3.71981131, 73.26035801]), array([ 3.34179192, 70.14953437])]\n",
      "num_data:272\n",
      "Iteration : 5 - means:[array([ 3.36210127, 68.69296379]), array([ 3.76375171, 73.75592376]), array([ 3.31936386, 69.94808391])]\n",
      "num_data:272\n",
      "Iteration : 6 - means:[array([ 3.32966354, 68.26506744]), array([ 3.82072231, 74.39698842]), array([ 3.28975384, 69.67039693])]\n",
      "num_data:272\n",
      "Iteration : 7 - means:[array([ 3.28662509, 67.71834342]), array([ 3.89638639, 75.24372346]), array([ 3.24955994, 69.27808805])]\n",
      "num_data:272\n",
      "Iteration : 8 - means:[array([ 3.2271988 , 66.99649833]), array([ 3.99939969, 76.38335738]), array([ 3.19287862, 68.70767886])]\n",
      "num_data:272\n",
      "Iteration : 9 - means:[array([ 3.14136429, 66.00610873]), array([ 4.13878439, 77.89252676]), array([ 3.10942852, 67.85519658])]\n",
      "num_data:272\n",
      "Iteration : 10 - means:[array([ 3.01379978, 64.60267536]), array([ 4.29213061, 79.5018736 ]), array([ 2.9845948 , 66.57653643])]\n",
      "num_data:272\n",
      "Iteration : 11 - means:[array([ 2.82703645, 62.54090149]), array([ 4.35923861, 80.25155553]), array([ 2.80996593, 64.70310109])]\n",
      "num_data:272\n",
      "Iteration : 12 - means:[array([ 2.64982729, 60.53767485]), array([ 4.3783634 , 80.51678625]), array([ 2.65269955, 62.98244303])]\n",
      "num_data:272\n",
      "Iteration : 13 - means:[array([ 2.5126902 , 58.93667152]), array([ 4.38289988, 80.62268721]), array([ 2.53800246, 61.72630396])]\n",
      "num_data:272\n",
      "Iteration : 14 - means:[array([ 2.38652085, 57.42886384]), array([ 4.37902035, 80.65139466]), array([ 2.44095755, 60.64204472])]\n",
      "num_data:272\n",
      "Iteration : 15 - means:[array([ 2.261296  , 55.93659719]), array([ 4.36830537, 80.61944284]), array([ 2.34897975, 59.57623635])]\n",
      "num_data:272\n",
      "Iteration : 16 - means:[array([ 2.14953404, 54.66439454]), array([ 4.35088286, 80.51572023]), array([ 2.27041851, 58.61081686])]\n",
      "num_data:272\n",
      "Iteration : 17 - means:[array([ 2.06434875, 53.81590456]), array([ 4.33200387, 80.39179473]), array([ 2.22816722, 57.96332374])]\n",
      "num_data:272\n",
      "Iteration : 18 - means:[array([ 2.0107823 , 53.42804613]), array([ 4.31804003, 80.29420471]), array([ 2.23352002, 57.8139088 ])]\n",
      "num_data:272\n",
      "Iteration : 19 - means:[array([ 1.98003614, 53.3049878 ]), array([ 4.31128663, 80.23636033]), array([ 2.27944563, 58.13167198])]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(234)\n",
    "\n",
    "#Two Cluster\n",
    "#initial_means = [np.array([3.467750,70.132353]),np.array([3.5078162,71.6617647])]\n",
    "#initial_covs = [np.array([[1.2975376,13.9110994],[13.911099,183.559040]])]*2\n",
    "#initial_weights = [0.50062804,0.49937196]\n",
    "\n",
    "#Three Cluster\n",
    "initial_means = [np.array([3.4459639,69.8433735]),np.array([3.6217053,72.1578947]),np.array([3.3893617,70.5531915])]\n",
    "initial_covs = [np.array([[1.2877935,13.842302],[13.8423020,183.208932]])]*3\n",
    "initial_weights = [0.30514706,0.34926471,0.34558824]\n",
    "\n",
    "# Run EM \n",
    "results = EM(X, initial_means, initial_covs, initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24232013605095637, 0.6304087799254683, 0.12727108402357576]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.98003614, 53.3049878 ]),\n",
       " array([ 4.31128663, 80.23636033]),\n",
       " array([ 2.27944563, 58.13167198])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['means']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03776105,  0.12703753],\n",
       "       [ 0.12703753, 27.07162665]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['covs'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
