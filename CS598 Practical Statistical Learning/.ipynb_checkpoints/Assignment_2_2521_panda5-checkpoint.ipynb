{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordinateDescentLasso:\n",
    "    def __init__(self, lamda: float = 1.0, max_iter: int = 1000, fit_intercept: bool = True) -> None:\n",
    "        self.lamda: float = lamda\n",
    "        self.max_iter: int = max_iter\n",
    "        self.fit_intercept: bool = fit_intercept\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "\n",
    "        \n",
    "    def _lasso_threshold(self, x: float, lambda_: float) -> float:\n",
    "        if x > 0.0 and lambda_ < abs(x):\n",
    "            return x - lambda_\n",
    "        elif x < 0.0 and lambda_ < abs(x):\n",
    "            return x + lambda_\n",
    "        else:\n",
    "            return 0.0\n",
    "        \n",
    "        \n",
    "    def Lasso_fit(self,X,y):\n",
    "        if self.fit_intercept:\n",
    "            X = np.column_stack((np.ones(len(X)), X))\n",
    "            \n",
    "        beta = np.zeros(X.shape[1])\n",
    "        if self.fit_intercept:\n",
    "            beta[0] = np.sum(y - np.dot(X[:, 1:], beta[1:])) / (X.shape[0])\n",
    "            \n",
    "        for iteration in range(self.max_iter):\n",
    "            start = 1 if self.fit_intercept else 0\n",
    "            for j in range(start, len(beta)):\n",
    "                tmp_beta = beta.copy()\n",
    "                tmp_beta[j] = 0.0\n",
    "                r_j = y - np.dot(X, tmp_beta)\n",
    "                arg1 = np.dot(X[:, j], r_j)\n",
    "                arg2 = self.lamda * X.shape[0]\n",
    "                \n",
    "                beta[j] = self._lasso_threshold(arg1, arg2) / (X[:, j]**2).sum()\n",
    "                \n",
    "                if self.fit_intercept:\n",
    "                    beta[0] = np.sum(y - np.dot(X[:, 1:], beta[1:])) / (X.shape[0])\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            self.intercept_ = beta[0]\n",
    "            self.coef_ = beta[1:]\n",
    "        else:\n",
    "            self.coef_ = beta\n",
    "\n",
    "        return self     \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Load the datasets\n",
    "    dataset = pd.read_csv(\"/users/Sushanta/Documents/GitHub/Illinois/CS598 Practical Statistical Learning/Coding2_myData.csv\")\n",
    "    X = np.array(dataset[dataset.columns[:-1]])\n",
    "    y = np.array(dataset['Y'])\n",
    "    feature_names = dataset.columns\n",
    "    \n",
    "    #Standardize the X, Mean 0, and Std\n",
    "    X = (X - X.mean(axis=0, keepdims=True)) / X.std(axis=0, keepdims=True)\n",
    "    \n",
    "    m,n = X.shape\n",
    "    #initial_theta = np.ones((n,1))\n",
    "    theta_list_scratch = list()\n",
    "    theta_list_sklearn = list()\n",
    "    \n",
    "    #Define the lamda values\n",
    "    log_lam_seq = np.linspace(-1, -8, num = 80)\n",
    "    lam_seq = np.exp(log_lam_seq)\n",
    "    i = 1\n",
    "    \n",
    "    #Loop for each Lamda, there are 80 Lamda\n",
    "    for l in lam_seq:\n",
    "        if (np.mod(i,10) == 0):\n",
    "            print (\"Processing for Lamda Sequence - {}\".format(i))\n",
    "            \n",
    "        model_scratch = CoordinateDescentLasso(lamda=l)\n",
    "        model_scratch.Lasso_fit(X, y)\n",
    "        theta_list_scratch.append(model_scratch.coef_)\n",
    "        \n",
    "        model_sklearn = Lasso(alpha=l)\n",
    "        model_sklearn.fit(X,y)\n",
    "        theta_list_sklearn.append(model_sklearn.coef_)\n",
    "        \n",
    "        i=i+1\n",
    "        \n",
    "    theta_scratch = np.stack(theta_list_scratch).T\n",
    "    theta_sklearn = np.stack(theta_list_sklearn).T\n",
    "    \n",
    "    p, _ = theta_scratch.shape\n",
    "    plt.figure(figsize = (12,8))\n",
    "    \n",
    "    for i in range(p):\n",
    "        plt.plot(log_lam_seq, theta_scratch[i, :], label = dataset.columns[i])\n",
    "\n",
    "    plt.xlabel('Log Lambda')\n",
    "    plt.ylabel('Coefficients')\n",
    "    plt.title('Lasso Paths - Numpy implementation')\n",
    "    plt.legend()\n",
    "    plt.axis('tight')    \n",
    "    \n",
    "\n",
    "    plt.figure(figsize = (12,8))\n",
    "    \n",
    "    for i in range(p):\n",
    "        plt.plot(log_lam_seq, theta_sklearn[i, :], label = dataset.columns[i])\n",
    "\n",
    "    plt.xlabel('Log Lambda')\n",
    "    plt.ylabel('Coefficients')\n",
    "    plt.title('Lasso Paths - Sklearn implementation')\n",
    "    plt.legend()\n",
    "    plt.axis('tight')\n",
    "    \n",
    "    \n",
    "    print (\"Differnece between Numpy Implementation & Sklearn Implementation - Thea Absoulute value is: {}\".format(abs(theta_scratch - theta_sklearn).max()))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
