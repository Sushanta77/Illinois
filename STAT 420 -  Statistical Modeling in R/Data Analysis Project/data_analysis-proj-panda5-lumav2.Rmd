---
title: 'Data Analysis Project - STAT 420 - Group Project'
author: "Luma Vasiljevic(lumav2), Sushanta Panda(panda5)"
date: 
output:
  html_document:
    theme: flatly
    toc: yes
    fig_width: 10
    fig_height: 5
  pdf_document:
    toc: yes
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
library(knitr)
opts_chunk$set(cache = TRUE, autodep = TRUE)
```

# Introduction


###Description of the dataset:
Forced Expiratory Volume (FEV) is an index of pulmonary function that measures the volume of the air expelled after one second of constant effort. The data contains the determinations of FEB on 654 children ages 6 – 22 who are seen in childhood respiratory disease study in 1980 in East Boston, Massachusetts. The data are part of a larger study to follow the change in pulmonary function over time in children.

#####**Dataset Link: **
http://www.statsci.org/data/general/fev.html

#####**Variables in the Dataset:**

```{r include=FALSE}
Variable = data.frame(
  VariableName = c("ID","Age", "Height", "Sex", "Smoker", "FEV"),
  Category = c("Numeric","Numeric", "Numeric", "Categorical", "Categorical", "Numeric"),
  Description = c("Uniquely Identified Row","Age of the child", "Height of the child in inches", "Sex of the child ", "Whether the child is a non-smoker or current smoker", "FEV of the child in litres")
)
```


```{r echo=FALSE}
library(knitr)
kable(Variable, format = "pandoc",padding = 2)
```

#####**Background information of the dataset:**

The data contains the determinations of FEB on 654 children ages 6 – 22 who are seen in childhood respiratory disease study in 1980 in East Boston, Massachusetts. The data are part of a larger study to follow the change in pulmonary function over time in children

Note: No citation required for this source (http://www.statsci.org/data/general/fev.html)


###Why is it interesting:
This dataset has chosen by us because of personal interests, whether we can predict the child’s FEV with the help of the available predictor, rather going for a Pulmonary Function Test, which will identify any pulmonary disease of a child. And secondly, to do statistical analysis on what are the predictors responsible to increase / decrease the pulmonary function of the child and try to find answer on these lines.

###Why are we creating a model of this Data:
In order to **predict the child's Forced Exporatory Volume (FEV)** based on the Child's Age, Height, Sex and whether the child is a smoker or not. This will help for kick-start the treatment of the child based on the FEV reading, rather going throgh the Pulmonary Function test.


###Goal of the Model:
The goal of the model is to find the best model after going through the several methods, which predict the child's FEV with minimal error. The best model would have the lowest Root Mean Square Error (RMSE) against Leave One Out cross validation (LOOCV).


# Methods
We will be doing several data analysis and methods in this section, where each section will be describing what's the part of the tasks.

###Load FEV data, Observations:

```{r}
childfev = read.csv("http://www.statsci.org/data/general/fev.txt",
                    sep = "\t",
                    quote = "\"",
                    comment.char = "",
                    stringsAsFactors = FALSE)
childfev$Sex = as.factor(childfev$Sex)
childfev$Smoker = as.factor(childfev$Smoker)
str(childfev)
dim(childfev)
head(childfev$FEV,10)
```

From the dataset, it observered data, Age, Heigh is a numerical variable, where as Sex / Smoker field is a categorical variable. The FEV is the numerical **response** variable.

#####**Load FEV data**
```{r fig.height=7, fig.width=7}
pairs(childfev[c('Age','FEV','Height','Sex','Smoker')], col = "darkgrey")
```

From the pairs plot, it sees there is a clear signs of linear releationship between FEV and Height. However there is no clear sign of linear relationship between FEV and Age variable. The 2 categorical variable `Sex` and `Smoker` seems to have 2 distinct data. Let's explore this

**Let's check the Correlation Matrix to explore what's the co-relation among the variables**
```{r}
cor(childfev[c('Age','Height','FEV')])
```
It seems that what the pair plot shows seems correct, from the corelation matrix it also suggests that `Age` and `Height` are higly corelation with `FEV` response, as well as among it self,  We need to explore the variance inflation factor (VIF) while creating our model in further.


#####**Categorical Data of Sex and Smoker**
```{r}
table(childfev$Sex)
table(childfev$Smoker)
```

###Model 1 - Multiple Linear Regression (MLR) FEV data:
Let's start with the Multiple Linear Regression (MLR) against all the predictor (Except the ID), to predict the FEV as the response

```{r}
mlr_model = lm(FEV ~ Age + Height + Sex + Smoker, data = childfev)
summary(mlr_model)
```

It seems that the `Model 1 - Multiple Linear Regression` is significance including all the predictor of the model is significance too. Let's explore other methods to dig down

#####**Assumption of the Model**
Let's verify the Assumption of the Model
 - Constant Varience
 - Normality 

**Let's plot Plotted Versus Residul Plot to see the distribution**
```{r}
par(mfrow = c(1,2))
plot(resid(mlr_model)~fitted(mlr_model), ylab = "residuals", xlab = "fitted", cex = 1, pch = 1, col = "darkgrey", main = "Residuals Versis Fitted Model")
abline(h = 0, lwd = 2, col = "darkorange")

qqnorm(resid(mlr_model), cex = 1, pch = 1, col = "darkgrey")
qqline(resid(mlr_model), lwd = 2, col = "darkorange")
```

From the above residuals versus fitted plot, it seems the **constant variance assumption is suspect**, as the residuals are not equally distributed. 

This is the same case for the Q-Q plot, where both the tail seems to the a little fat tails, which tells us that **normality assuption seems suspect** for the model.

Let's do the BP Test and Shapiro Test to gather some more evidence

```{r warning=FALSE}
library(lmtest)
bptest(mlr_model)
```

The BP Test is very low which confirms that **constant variance is suspect**

```{r}
shapiro.test(resid(mlr_model))
```

The shapiro test also seems lkow, which confirms that the **normality assumption also seems suspect**

#####**RSS, RMSE and RMSE LOOCV**
Let'e calculate the RSS, RMSE and RMSE LOOCV of the model
**RSS**
```{r}
sum((resid(mlr_model))^2)
```

**RMSE**
```{r}
sqrt(mean(sum((resid(mlr_model))^2)))
```

**RMSE LOOCV**
```{r}
sqrt(mean((resid(mlr_model)/(1-hatvalues(mlr_model)))^2))
```

```{r include=FALSE}
df_mlr_model = data.frame(
  Metric = c("RSS","RMSE", "RMSE LOOCV"),
  Value = c(sum((resid(mlr_model))^2),sqrt(mean(sum((resid(mlr_model))^2))),sqrt(mean((resid(mlr_model)/(1-hatvalues(mlr_model)))^2)))
)
```

```{r echo=FALSE}
library(knitr)
kable(df_mlr_model, format = "pandoc",padding = 2)
```

###Model 2 - Transformation of response variable FEV (Logarithimic):
Let's explore whether transformation of the response variable `FEV` has any siginificance to improve the score (low RMSE LOOCV)


Let's first plot the histogram of the `FEV` response variable with and without the logarathimic value

```{r}
par(mfrow=c(1,2))
hist(childfev$FEV,
     xlab = 'FEV response Variable Data',
     probability = TRUE,
     breaks = 20,
     col = "darkgrey",
     name = "Original FEV response")

hist(log(childfev$FEV),
     xlab = 'log(FEV) response Variable Data',     
     breaks = 20,
     col = "darkgrey",
     name = "Logarithimic FEV response")
```

It seems that after the logarithimic transformation the `FEV` response doesn't seems to be normal distibution. Hence let's not explore the lograthimic transformation for the `FEV` response variable

###Model 3 - Polynomial Transformation of Numeric Predictor
Let's explore the polynomial transformation of the predictor to see whether we can able to find the best model which lower the RMSE LOOCV

We will carry out the following methods to identify the best model
 - Lowest RMSE LOOCV 
 - Highest R2 and Adjusted R2
 - Lowest Average Percentage Error
 - Anova F Test P value


```{r}
poly2_model = lm(FEV ~ Sex + Smoker + Age + Height + I(Age^2) + I(Height^2) , data = childfev)
poly3_model = lm(FEV ~ Sex + Smoker + Age + Height + I(Age^2) + I(Height^2) + I(Age^3) + I(Height^3) , data = childfev)
poly4_model = lm(FEV ~ Sex + Smoker + Age + Height + I(Age^2) + I(Height^2) + I(Age^3) + I(Height^3) + I(Age^4) + I(Height^4), data = childfev)
poly5_model = lm(FEV ~ Sex + Smoker + Age + Height + I(Age^2) + I(Height^2) + I(Age^3) + I(Height^3) + I(Age^4) + I(Height^4) + I(Age^5) + I(Height^5), data = childfev)
poly6_model = lm(FEV ~ Sex + Smoker + Age + Height + I(Age^2) + I(Height^2) + I(Age^3) + I(Height^3) + I(Age^4) + I(Height^4) + I(Age^5) + I(Height^5) + I(Age^6) + I(Height^6), data = childfev)
```

```{r include=FALSE}
#Split the data into 80% (Train Set), 20% (Test Set)
set.seed(420)
childfev_trn_idx  = sample(nrow(childfev), size = trunc(0.80 * nrow(childfev)))
childfev_trn_data = childfev[childfev_trn_idx, ]
childfev_tst_data = childfev[-childfev_trn_idx, ]

#Function to calculate average percent error
average_percent_error = function(actual, predicted) {
  100 * mean((abs(actual - predicted)) / actual)
}
```

```{r include=FALSE}
train_test_error_poly_model = rep(0,5)
r2_poly_model = rep(0,5)
adjr2_poly_model = rep(0,5)

#Populate train_test_error_model
train_test_error_poly_model[1] = average_percent_error(childfev_tst_data$FEV, predict(mlr_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_poly_model[2] = average_percent_error(childfev_tst_data$FEV, predict(poly2_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_poly_model[3] = average_percent_error(childfev_tst_data$FEV, predict(poly3_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_poly_model[4] = average_percent_error(childfev_tst_data$FEV, predict(poly4_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_poly_model[5] = average_percent_error(childfev_tst_data$FEV, predict(poly5_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_poly_model[6] = average_percent_error(childfev_tst_data$FEV, predict(poly6_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))

#R2
r2_poly_model[1] = summary(mlr_model)$r.squared
r2_poly_model[2] = summary(poly2_model)$r.squared
r2_poly_model[3] = summary(poly3_model)$r.squared
r2_poly_model[4] = summary(poly4_model)$r.squared
r2_poly_model[5] = summary(poly5_model)$r.squared
r2_poly_model[6] = summary(poly6_model)$r.squared

#Adjusted R2
adjr2_poly_model[1] = summary(mlr_model)$adj.r.squared
adjr2_poly_model[2] = summary(poly2_model)$adj.r.squared
adjr2_poly_model[3] = summary(poly3_model)$adj.r.squared
adjr2_poly_model[4] = summary(poly4_model)$adj.r.squared
adjr2_poly_model[5] = summary(poly5_model)$adj.r.squared
adjr2_poly_model[6] = summary(poly6_model)$adj.r.squared
```

```{r include=FALSE}
#Creating Empty list
rss_poly_model = rep(0,5)
rmse_poly_model = rep(0,5)
rmse_loocv_poly_model = rep(0,5)

#Populate RSS
rss_poly_model[1] = sum((resid(mlr_model))^2)
rss_poly_model[2] = sum((resid(poly2_model))^2)
rss_poly_model[3] = sum((resid(poly3_model))^2)
rss_poly_model[4] = sum((resid(poly4_model))^2)
rss_poly_model[5] = sum((resid(poly5_model))^2)
rss_poly_model[6] = sum((resid(poly6_model))^2)

#Populate RMSE
rmse_poly_model[1] = sqrt(mean(sum((resid(mlr_model))^2)))
rmse_poly_model[2] = sqrt(mean(sum((resid(poly2_model))^2)))
rmse_poly_model[3] = sqrt(mean(sum((resid(poly3_model))^2)))
rmse_poly_model[4] = sqrt(mean(sum((resid(poly4_model))^2)))
rmse_poly_model[5] = sqrt(mean(sum((resid(poly5_model))^2)))
rmse_poly_model[6] = sqrt(mean(sum((resid(poly6_model))^2)))

#Populate RMSE LOOC
rmse_loocv_poly_model[1] = sqrt(mean((resid(mlr_model)/(1-hatvalues(mlr_model)))^2))
rmse_loocv_poly_model[2] = sqrt(mean((resid(poly2_model)/(1-hatvalues(poly2_model)))^2))
rmse_loocv_poly_model[3] = sqrt(mean((resid(poly3_model)/(1-hatvalues(poly3_model)))^2))
rmse_loocv_poly_model[4] = sqrt(mean((resid(poly4_model)/(1-hatvalues(poly4_model)))^2))
rmse_loocv_poly_model[5] = sqrt(mean((resid(poly5_model)/(1-hatvalues(poly4_model)))^2))
rmse_loocv_poly_model[6] = sqrt(mean((resid(poly6_model)/(1-hatvalues(poly6_model)))^2))
```

```{r echo=FALSE}
black = "#2C3E50"
grey = "#ECF0F1"
green = "#009999"
purple = "#990073"
blue = "blue4"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
polynomial_degree = 1:6
plot(polynomial_degree, rss_poly_model, type = "b",
       ylim = c(min(rss_poly_model), max(rss_poly_model)), col = purple, lwd = 2,
       xlab = "Polynomial Degree", ylab = "Residual Sum Square (RSS)", main = "RSS Vs Polynomial Degree")

plot(polynomial_degree, rmse_poly_model, type = "b",
       ylim = c(min(rmse_poly_model), max(rmse_poly_model)), col = green, lwd = 2,
       xlab = "Polynomial Degree", ylab = "Root Mean Square (RMSE)", main = "RMSE Vs Polynomial Degree")

plot(polynomial_degree, rmse_loocv_poly_model, type = "b",
       ylim = c(min(rmse_loocv_poly_model), max(rmse_loocv_poly_model)), col = blue, lwd = 2,
       xlab = "Polynomial Degree", ylab = "Root Mean Square (RMSE) LOOCV", main = "RMSE LOOCV Vs Polynomial Degree")
```

It seems that as the Polynomial degree increases, the `RSS` and `RMSE` decreases, which should be as the model becomes more and more complex, the error will decreased. However the RMSE LOOCV seems **increases** after the Polynomial degree 2. Hence it's not been seen good, if we increase the model beyond degree 2, as the Root Mean Square Error (RMSE) Leave One Out Cross Validation Error increases.

Let's see what happens to the R2 and Adjusted R2 when the polynomail degree increases. Also let's see what will be the Average Percentage Error, when the Polynomail degree increases. 


```{r echo=FALSE}
gold = "gold4"
red = "darkred"
orchid = "darkorchid2"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
polynomial_degree = 1:6
plot(polynomial_degree, r2_poly_model, type = "b",
       ylim = c(min(r2_poly_model), max(r2_poly_model)), col = gold, lwd = 2,
       xlab = "Polynomial Degree", ylab = "R2", main = "R2 Vs Polynomial Degree")

plot(polynomial_degree, adjr2_poly_model, type = "b",
       ylim = c(min(adjr2_poly_model), max(adjr2_poly_model)), col = red, lwd = 2,
       xlab = "Polynomial Degree", ylab = "Adjusted R2", main = "Adjusted R2 Vs Polynomial Degree")

plot(polynomial_degree, train_test_error_poly_model, type = "b",
       ylim = c(min(train_test_error_poly_model), max(train_test_error_poly_model)), col = orchid, lwd = 2,
       xlab = "Polynomial Degree", ylab = "Average Percent Error", main = "Average Percent Error Vs Polynomial Degree")
```

It seems the R2 keeps increasing as the Polynomial degree increases. However adjusted R2 seems mostly fixed on/beyond Polynomial degree 2. Which kind of gives enough evidence to go for the model having Polynomail degree 2. 

The 3rd plot which gives the average percentage of error, which is calculated from the below formula

which depicts that the percentage of error doesn't decrease after Polynomial degree 2, and increased. This also have inclination towards the Polynomial Regression model with Degree 2.

Let's do an Inova F Test to compare these models, to see whether the Polynomial degree has significance or not.

#####**Anova F Test**
```{r echo=FALSE}
anova_poly_p_value = rep(0,4)
anova_poly_p_value[1] = anova(mlr_model,poly2_model)$'Pr(>F)'[2]
anova_poly_p_value[2] = anova(poly2_model,poly3_model)$'Pr(>F)'[2]
anova_poly_p_value[3] = anova(poly2_model,poly4_model)$'Pr(>F)'[2]
anova_poly_p_value[4] = anova(poly2_model,poly5_model)$'Pr(>F)'[2]
anova_poly_p_value[5] = anova(poly2_model,poly6_model)$'Pr(>F)'[2]

red = "firebrick4"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
polynomial_degree = 1:5
plot(polynomial_degree, anova_poly_p_value, type = "b",
       ylim = c(min(anova_poly_p_value), max(anova_poly_p_value)), col = red, lwd = 2,
       xlab = "Model Participate in Anova F Test", ylab = "Anova P Value", main = "Anova P Value Vs Model Comparision")
abline (h = 0.05, lwd = 1, lty = 2, col = "darkgreen")
legend("topleft", legend=c("p value","alpha(0.05)"), col = c("firebrick4","darkgreen"),lty = c(1,2))

```

Each point shows the `p value` comes from the Anova F Test between `Polynomial Regresssion of degree 1` Vs `Polynomial Regresssion of degree 2` and rest all points are between `Polynomial Regresssion of degree 2` and `Polynomial Regresssion of degree 3/4/5/6`. It clearly observed that for alpha value **`0.05`** we **failed to reject all hypothesis** of estimated parameters to be zero for Polynomial of degree more than 2. 

Let's see the comparision of the data in actual between all the models, to concrete the Model with Polynomial regression of degree 2 is the best model

```{r include=FALSE}
df_compare_anova_polynomial = data.frame(
  ID        = c("1","2","3","4","5","6"),
  Interaction_Model = c("MLR","Polynomial Degree 2","Polynomial Degree 3", "Polynomial Degree 4", "Polynomial Degree 5", "Polynomial Degree 6"),
  rss        = c(rss_poly_model[1],rss_poly_model[2],rss_poly_model[3],rss_poly_model[4],rss_poly_model[5],rss_poly_model[6]),
  rmse       = c(rmse_poly_model[1],rmse_poly_model[2],rmse_poly_model[3],rmse_poly_model[4],rmse_poly_model[5],rmse_poly_model[6]),
  rmse_loocv = c(rmse_loocv_poly_model[1],rmse_loocv_poly_model[2],rmse_loocv_poly_model[3],rmse_loocv_poly_model[4],rmse_loocv_poly_model[5],rmse_loocv_poly_model[6]), 
  r2         = c(r2_poly_model[1],r2_poly_model[2],r2_poly_model[3],r2_poly_model[4],r2_poly_model[5],r2_poly_model[6]),
  adj_r2     = c(adjr2_poly_model[1],adjr2_poly_model[2],adjr2_poly_model[3],adjr2_poly_model[4],adjr2_poly_model[5],adjr2_poly_model[6])
)
```

```{r echo=FALSE}
library(knitr)
kable(df_compare_anova_polynomial, format = "pandoc",padding = 2)
```

It seems even though ANOVA F Test suugest to Model 10 is significance (`3 Way`), the RMSE LOOCV is small (not that though) against Model 8. We will keep these 2 modesl (`Model 8` and `Model 10`) are the best model, which we will explore further


It also clearly gives confidence that Polynomial degree 2 would be the best model, from the following methods which we have tested
 - Lowest RMSE LOOCV 
 - Highest R2 and Adjusted R2
 - Lowest Average Percentage Error
 - Anova F Test P value


###Model 4 - Interaction between Predictors:
Following are the exploration needs to be done as part of the Interaction between the predictors
 - Interaction between Numerical Predictor (Age, Height) and Categorical Predictor (Sex, Smoker) - One at a Time
 - Interaction between Numerical Predictors (Age, Height) it self
 - Interaction between all of the them 2 way and 3 way.
 - Carry out Inova F Test and RMSE LOOCV and Average Percentage Error to find out what's the best model

#####**Interaction Model:**
```{r}
model_age_sex = lm(FEV ~ (Age + Sex) ^ 2 , data = childfev)
model_age_smoker = lm(FEV ~ (Age + Smoker) ^ 2 , data = childfev)
model_age_sex_smoker = lm(FEV ~ Age + Sex + Smoker + Age:Sex + Age:Smoker , data = childfev)
model_height_sex = lm(FEV ~ (Height + Sex) ^ 2 , data = childfev)
model_height_smoker = lm(FEV ~ (Height + Smoker) ^ 2 , data = childfev)
model_height_sex_smoker = lm(FEV ~ Height + Sex + Smoker + Height:Sex + Height:Smoker , data = childfev)
model_all_int_except_age_height = lm(FEV ~ Age + Height + Sex + Smoker + Age:Sex + Age:Smoker + Height:Sex + Height:Smoker, data = childfev) 
model_all_int_with_age_height = lm(FEV ~ Age + Height + Sex + Smoker + Age:Sex + Age:Smoker + Height:Sex + Height:Smoker + Age:Height, data = childfev) 
model_all_2way = lm(FEV ~ (Age + Height + Sex + Smoker) ^ 2, data = childfev) 
model_all_3way = lm(FEV ~ (Age + Height + Sex + Smoker) ^ 3, data = childfev)
```

```{r echo=FALSE}
#For Age Vs FEV
pink = "deeppink"
blue = "dodgerblue"
par(mfrow = c(1, 4), oma = c(0, 0, 5, 0))
typecol = c("deeppink","dodgerblue")
plot(FEV ~ Age, data = childfev, col = typecol, pch = c(1,2), main = "Age Vs Fev")
grid()
int_female = summary(model_age_sex)$coefficient[1,1]
int_male = summary(model_age_sex)$coefficient[1,1] + summary(model_age_sex)$coefficient[3,1]
slope_female = summary(model_age_sex)$coefficient[2,1]
slope_male = summary(model_age_sex)$coefficient[2,1] + summary(model_age_sex)$coefficient[4,1]
abline(int_female,slope_female, lwd = 2, col = pink, lty = 2)
abline(int_male,slope_male, lwd = 2, col = blue, lty = 2)
legend("topleft",legend=c("Female","Male"),col = c("deeppink","dodgerblue"), pch=c(1,2))

gold = "gold2"
green = "darkolivegreen"
typecol = c("gold2","darkolivegreen")
plot(FEV ~ Age, data = childfev, col = typecol, pch = c(1,2), main = "Age Vs Fev")
grid()
int_smoker = summary(model_age_smoker)$coefficient[1,1]
int_nonsmoker = summary(model_age_smoker)$coefficient[1,1] + summary(model_age_smoker)$coefficient[3,1]
slope_smoker = summary(model_age_smoker)$coefficient[2,1]
slope_nonsmoker = summary(model_age_smoker)$coefficient[2,1] + summary(model_age_smoker)$coefficient[4,1]
abline(int_smoker,slope_smoker, lwd = 2, col = gold, lty = 2)
abline(int_nonsmoker,slope_nonsmoker, lwd = 2, col = green, lty = 2)
legend("topleft",legend=c("Smoker","Non-Smoker"),col = c("gold2","darkolivegreen"), pch=c(1,2))

#For Height Vs FEV
pink = "orangered"
blue = "yellowgreen"
typecol = c("orangered","yellowgreen")
plot(FEV ~ Height, data = childfev, col = typecol, pch = c(1,2), main = "Height Vs Fev")
grid()
int_female = summary(model_height_sex)$coefficient[1,1]
int_male = summary(model_height_sex)$coefficient[1,1] + summary(model_height_sex)$coefficient[3,1]
slope_female = summary(model_height_sex)$coefficient[2,1]
slope_male = summary(model_height_sex)$coefficient[2,1] + summary(model_height_sex)$coefficient[4,1]
abline(int_female,slope_female, lwd = 2, col = pink, lty = 2)
abline(int_male,slope_male, lwd = 2, col = blue, lty = 2)
legend("topleft",legend=c("Female","Male"),col = c("orangered","yellowgreen"), pch=c(1,2))

gold = "tan1"
green = "slateblue4"
typecol = c("tan1","slateblue4")
plot(FEV ~ Height, data = childfev, col = typecol, pch = c(1,2), main = "Heighte Vs Fev")
grid()
int_smoker = summary(model_height_smoker)$coefficient[1,1]
int_nonsmoker = summary(model_height_smoker)$coefficient[1,1] + summary(model_height_smoker)$coefficient[3,1]
slope_smoker = summary(model_height_smoker)$coefficient[2,1]
slope_nonsmoker = summary(model_height_smoker)$coefficient[2,1] + summary(model_height_smoker)$coefficient[4,1]
abline(int_smoker,slope_smoker, lwd = 2, col = gold, lty = 2)
abline(int_nonsmoker,slope_nonsmoker, lwd = 2, col = green, lty = 2)
legend("topleft",legend=c("Smoker","Non-Smoker"),col = c("tan1","slateblue4"), pch=c(1,2))
```

It seems that the interaction between the `Age` with categorical variable (Sex and Smoker) has changed the estimates drasticallly, than the interaction between `Height` with the Categorical variable (Sex and Smoker).

Let's conduct the Anova F Test to verify, which interaction is significance and which is not

#####**Anova F Test**
```{r echo=FALSE}
anova_int_p_value = rep(0,9)
anova_int_p_value[1] = anova(model_age_sex,model_age_sex_smoker)$'Pr(>F)'[2]
anova_int_p_value[2] = anova(model_age_smoker,model_age_sex_smoker)$'Pr(>F)'[2]
anova_int_p_value[3] = anova(model_height_sex,model_height_sex_smoker)$'Pr(>F)'[2]
anova_int_p_value[4] = anova(model_height_smoker,model_height_sex_smoker)$'Pr(>F)'[2]
anova_int_p_value[5] = anova(model_age_sex_smoker,model_all_int_except_age_height)$'Pr(>F)'[2]
anova_int_p_value[6] = anova(model_height_sex,model_all_int_except_age_height)$'Pr(>F)'[2]
anova_int_p_value[7] = anova(model_height_sex_smoker,model_all_int_except_age_height)$'Pr(>F)'[2]
anova_int_p_value[8] = anova(model_all_int_except_age_height,model_all_int_with_age_height)$'Pr(>F)'[2]
anova_int_p_value[9] = anova(model_all_int_with_age_height,model_all_2way)$'Pr(>F)'[2] #Relation between Sex and Smoker is non-Significant
anova_int_p_value[10] = anova(model_all_int_with_age_height,model_all_3way)$'Pr(>F)'[2] #Certainly this is one of the best model
```


```{r include=FALSE}
df_compare_anova_interaction = data.frame(
  ID = c("1","2","3","4","5","6","7","8","9","10"),
  null_Model = c("Age+Sex+Age:Sex","Age+Smoker+Age:Smoker","Height+Sex+Height:Sex","Height+Smoker+Height:Smoker",
                 "Age+Sex+Smoker+Age:Sex+Age:Smoker","Height+Sex+Height:Sex","Height+Sex+Smoker+Height:Sex+Height:Smoker",
                 "Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker","Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker+Age:Height",
                 "Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker+Age:Height"),
  full_Model = c("Age+Sex+Smoker+Age:Sex+Age:Smoker","Age+Sex+Smoker+Age:Sex+Age:Smoker","Height+Sex+Smoker+Height:Sex+Height:Smoker",
                 "Height+Sex+Smoker+Height:Sex+Height:Smoker","Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker",
                 "Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker","Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker",
                 "Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker+Age:Height","2 way","3 way"),
  p_value = c(anova_int_p_value[1],anova_int_p_value[2],anova_int_p_value[3],anova_int_p_value[4],anova_int_p_value[5],anova_int_p_value[6],anova_int_p_value[7],
              anova_int_p_value[8],anova_int_p_value[9],anova_int_p_value[10]
              ),
  descision = c("Age+Sex+Smoker+Age:Sex+Age:Smoker","Age+Sex+Smoker+Age:Sex+Age:Smoker","Height+Sex+Height:Sex",
                "Height+Sex+Smoker+Height:Sex+Height:Smoker","Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker",
                "Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker","Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker",
                "Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker+Age:Height","Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker+Age:Height",
                "3way")
)
```

```{r echo=FALSE}
library(knitr)
kable(df_compare_anova_interaction, format = "pandoc",padding = 2)
```

It seems the 3 way interaction seems significance among all the interaction between the numeric and categorical variable.

Let's see how these model perform on the RSS, RMSE, RMSE LOOCV and 


```{r include=FALSE}
train_test_error_int_model = rep(0,10)
r2_int_model = rep(0,10)
adjr2_int_model = rep(0,10)

#Populate train_test_error_model
train_test_error_int_model[1] = average_percent_error(childfev_tst_data$FEV, predict(model_age_sex, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_int_model[2] = average_percent_error(childfev_tst_data$FEV, predict(model_age_smoker, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_int_model[3] = average_percent_error(childfev_tst_data$FEV, predict(model_age_sex_smoker, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_int_model[4] = average_percent_error(childfev_tst_data$FEV, predict(model_height_sex, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_int_model[5] = average_percent_error(childfev_tst_data$FEV, predict(model_height_smoker, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_int_model[6] = average_percent_error(childfev_tst_data$FEV, predict(model_height_sex_smoker, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_int_model[7] = average_percent_error(childfev_tst_data$FEV, predict(model_all_int_except_age_height, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_int_model[8] = average_percent_error(childfev_tst_data$FEV, predict(model_all_int_with_age_height, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_int_model[9] = average_percent_error(childfev_tst_data$FEV, predict(model_all_2way, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_int_model[10] = average_percent_error(childfev_tst_data$FEV, predict(model_all_3way, childfev_tst_data[c("Age","Height","Sex","Smoker")]))

#R2
r2_int_model[1] = summary(model_age_sex)$r.squared
r2_int_model[2] = summary(model_age_smoker)$r.squared
r2_int_model[3] = summary(model_age_sex_smoker)$r.squared
r2_int_model[4] = summary(model_height_sex)$r.squared
r2_int_model[5] = summary(model_height_smoker)$r.squared
r2_int_model[6] = summary(model_height_sex_smoker)$r.squared
r2_int_model[7] = summary(model_all_int_except_age_height)$r.squared
r2_int_model[8] = summary(model_all_int_with_age_height)$r.squared
r2_int_model[9] = summary(model_all_2way)$r.squared
r2_int_model[10] = summary(model_all_3way)$r.squared

#Adjusted R2
adjr2_int_model[1] = summary(model_age_sex)$adj.r.squared
adjr2_int_model[2] = summary(model_age_smoker)$adj.r.squared
adjr2_int_model[3] = summary(model_age_sex_smoker)$adj.r.squared
adjr2_int_model[4] = summary(model_height_sex)$adj.r.squared
adjr2_int_model[5] = summary(model_height_smoker)$adj.r.squared
adjr2_int_model[6] = summary(model_height_sex_smoker)$adj.r.squared
adjr2_int_model[7] = summary(model_all_int_except_age_height)$adj.r.squared
adjr2_int_model[8] = summary(model_all_int_with_age_height)$adj.r.squared
adjr2_int_model[9] = summary(model_all_2way)$adj.r.squared
adjr2_int_model[10] = summary(model_all_3way)$adj.r.squared
```

```{r include=FALSE}
#Creating Empty list
rss_int_model = rep(0,10)
rmse_int_model = rep(0,10)
rmse_loocv_int_model = rep(0,10)

#Populate RSS
rss_int_model[1] = sum((resid(model_age_sex))^2)
rss_int_model[2] = sum((resid(model_age_smoker))^2)
rss_int_model[3] = sum((resid(model_age_sex_smoker))^2)
rss_int_model[4] = sum((resid(model_height_sex))^2)
rss_int_model[5] = sum((resid(model_height_smoker))^2)
rss_int_model[6] = sum((resid(model_height_sex_smoker))^2)
rss_int_model[7] = sum((resid(model_all_int_except_age_height))^2)
rss_int_model[8] = sum((resid(model_all_int_with_age_height))^2)
rss_int_model[9] = sum((resid(model_all_2way))^2)
rss_int_model[10] = sum((resid(model_all_3way))^2)

#Populate RMSE
rmse_int_model[1] = sqrt(mean(sum((resid(model_age_sex))^2)))
rmse_int_model[2] = sqrt(mean(sum((resid(model_age_smoker))^2)))
rmse_int_model[3] = sqrt(mean(sum((resid(model_age_sex_smoker))^2)))
rmse_int_model[4] = sqrt(mean(sum((resid(model_height_sex))^2)))
rmse_int_model[5] = sqrt(mean(sum((resid(model_height_smoker))^2)))
rmse_int_model[6] = sqrt(mean(sum((resid(model_height_sex_smoker))^2)))
rmse_int_model[7] = sqrt(mean(sum((resid(model_all_int_except_age_height))^2)))
rmse_int_model[8] = sqrt(mean(sum((resid(model_all_int_with_age_height))^2)))
rmse_int_model[9] = sqrt(mean(sum((resid(model_all_2way))^2)))
rmse_int_model[10] = sqrt(mean(sum((resid(model_all_2way))^2)))

#Populate RMSE LOOC
rmse_loocv_int_model[1] = sqrt(mean((resid(model_age_sex)/(1-hatvalues(model_age_sex)))^2))
rmse_loocv_int_model[2] = sqrt(mean((resid(model_age_smoker)/(1-hatvalues(model_age_smoker)))^2))
rmse_loocv_int_model[3] = sqrt(mean((resid(model_age_sex_smoker)/(1-hatvalues(model_age_sex_smoker)))^2))
rmse_loocv_int_model[4] = sqrt(mean((resid(model_height_sex)/(1-hatvalues(model_height_sex)))^2))
rmse_loocv_int_model[5] = sqrt(mean((resid(model_height_smoker)/(1-hatvalues(model_height_smoker)))^2))
rmse_loocv_int_model[6] = sqrt(mean((resid(model_height_sex_smoker)/(1-hatvalues(model_height_sex_smoker)))^2))
rmse_loocv_int_model[7] = sqrt(mean((resid(model_all_int_except_age_height)/(1-hatvalues(model_all_int_except_age_height)))^2))
rmse_loocv_int_model[8] = sqrt(mean((resid(model_all_int_with_age_height)/(1-hatvalues(model_all_int_with_age_height)))^2))
rmse_loocv_int_model[9] = sqrt(mean((resid(model_all_2way)/(1-hatvalues(model_all_2way)))^2))
rmse_loocv_int_model[10] = sqrt(mean((resid(model_all_2way)/(1-hatvalues(model_all_2way)))^2))
```

```{r echo=FALSE}
black = "#2C3E50"
grey = "#ECF0F1"
green = "#009999"
purple = "#990073"
blue = "blue4"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
Interaction_Model = 1:10
plot(Interaction_Model, rss_int_model, type = "b",
       ylim = c(min(rss_int_model), max(rss_int_model)), col = purple, lwd = 2,
       xlab = "Interaction Model", ylab = "Residual Sum Square (RSS)", main = "RSS Vs Interaction Model")

plot(Interaction_Model, rmse_int_model, type = "b",
       ylim = c(min(rmse_int_model), max(rmse_int_model)), col = green, lwd = 2,
       xlab = "Interaction Model", ylab = "Root Mean Square (RMSE)", main = "RMSE Vs Interaction Model")

plot(Interaction_Model, rmse_loocv_int_model, type = "b",
       ylim = c(min(rmse_loocv_int_model), max(rmse_loocv_int_model)), col = blue, lwd = 2,
       xlab = "Interaction Model", ylab = "Root Mean Square (RMSE) LOOCV", main = "RMSE LOOCV Vs Interaction Model")
```

It seems that as the Interaction increased, the `RSS` and `RMSE` decreases, which should be as the model becomes more and more complex, the error will decreased. Also the RMSE LOOCV also **decreases** with increase in Interaction, however the RMSE LOOCV increased slighly after the Model 9 

Let's see what happens to the R2 and Adjusted R2 when the polynomail degree increases. Also let's see what will be the Average Percentage Error, when the Polynomail degree increases. 


```{r echo=FALSE}
gold = "gold4"
red = "darkred"
orchid = "darkorchid2"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
Interaction_Model = 1:10
plot(Interaction_Model, r2_int_model, type = "b",
       ylim = c(min(r2_int_model), max(r2_int_model)), col = gold, lwd = 2,
       xlab = "Interaction Model", ylab = "R2", main = "R2 Vs Interaction Model")

plot(Interaction_Model, adjr2_int_model, type = "b",
       ylim = c(min(adjr2_int_model), max(adjr2_int_model)), col = red, lwd = 2,
       xlab = "Interaction Model", ylab = "Adjusted R2", main = "Adjusted R2 Vs Interaction Model")

plot(Interaction_Model, train_test_error_int_model, type = "b",
       ylim = c(min(train_test_error_int_model), max(train_test_error_int_model)), col = orchid, lwd = 2,
       xlab = "Interaction Model", ylab = "Average Percent Error", main = "Average Percent Error Vs Interaction Model")
```

It seems the R2 and adjusted R2 keeps increasing as the Polynomial degree increases. Also the error rate is also decreasing as the interaction increases. However after the Model 9 the Error rate increases slightly as the interaction increases

Let's see the comparision of the data in actual between all the models, to see what's the best finalize model

```{r include=FALSE}
df_compare_anova_interaction = data.frame(
  ID = c("1","2","3","4","5","6","7","8","9","10"),
  Interaction_Model = c("Age+Sex+Age:Sex","Age+Smoker+Age:Smoker","Age+Sex+Smoker+Age:Sex+Age:Smoker","Height+Sex+Height:Sex","Height+Smoker+Height:Smoker",
                        "Height+Sex+Smoker+Height:Sex+Height:Smoker","Age+Height+Sex+Smoker+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker",
                        "Age+Height+Sex+Smoker+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker+Age:Height","2 Way", "3 Way"),
  rss = c(rss_int_model[1],rss_int_model[2],rss_int_model[3],rss_int_model[4],rss_int_model[5],rss_int_model[6],rss_int_model[7],rss_int_model[8],rss_int_model[9],rss_int_model[10]),
  rmse = c(rmse_int_model[1],rmse_int_model[2],rmse_int_model[3],rmse_int_model[4],rmse_int_model[5],rmse_int_model[6],rmse_int_model[7],rmse_int_model[8],rmse_int_model[9],rmse_int_model[10]),
  rmse_loocv = c(rmse_loocv_int_model[1],rmse_loocv_int_model[2],rmse_loocv_int_model[3],rmse_loocv_int_model[4],rmse_loocv_int_model[5],rmse_loocv_int_model[6],rmse_loocv_int_model[7],rmse_loocv_int_model[8],rmse_loocv_int_model[9],rmse_loocv_int_model[10]), 
  r2 = c(r2_int_model[1],r2_int_model[2],r2_int_model[3],r2_int_model[4],r2_int_model[5],r2_int_model[6],r2_int_model[7],r2_int_model[8],r2_int_model[9],r2_int_model[10]),
  adj_r2 = c(adjr2_int_model[1],adjr2_int_model[2],adjr2_int_model[3],adjr2_int_model[4],adjr2_int_model[5],adjr2_int_model[6],adjr2_int_model[7],adjr2_int_model[8],adjr2_int_model[9],adjr2_int_model[10])
)
```

```{r echo=FALSE}
library(knitr)
kable(df_compare_anova_interaction, format = "pandoc",padding = 2)
```

It kind of confirmation that Polynomial regression with degree 2 is lowest RMSE LOOCV. We have decided to see it's the best model.

###Model 5 - Creation of Big Model (Polynomial + Interaction), Stepwise via AIC / BIC:
Let's create a big model, with Polynomial of degree 3 and 3 way interaction between categorical-to-categorical, categorical-to-numeric, numeric-to-numeric and see it's score. 

Also create few models with combination from the previous model (which treat as good model)
 - Polynomial degree 2 + Interaction Model 8 
 - Polynomial degree 2 + Interaction Model 9 (2 way interaction)
 - Polynomial degree 2 + Interaction Model 10 (3 way interaction)

#####**Big Model: + 3 other model**

```{r}
big_model = lm(FEV ~ (Age + Height + Sex + Smoker) ^ 3 + I(Age^2) + I(Height^2) + I(Age^3) + I(Height^3), data = childfev) # Big Model - Polynomial degree 3 + 3 Way Interaction
poly2_int_model8 = lm(FEV ~ Age + Height + Sex + Smoker + Age:Sex + Age:Smoker + Height:Sex + Height:Smoker + Age:Height , data = childfev) # Polynomial degree 2 + All Interaction Except Sex:Smoker
poly2_int_model9 = lm(FEV ~ (Age + Height + Sex + Smoker) ^ 2, data = childfev) # Polynomial degree 2 + 2 Way Interaction
poly2_int_model10 = lm(FEV ~ (Age + Height + Sex + Smoker) ^ 3, data = childfev) # Polynomial degree 2 + 3 Way Interaction
```

Let's compare with the good model from the Interaction model and Polynomial Regression Model, to see which one is siginificance

```{r echo=FALSE}
anova_final_p_value = rep(0,7)
anova_final_p_value[1] = anova(poly2_model,big_model)$'Pr(>F)'[2] #Polynomial Model With Degree 2
anova_final_p_value[2] = anova(model_all_int_with_age_height,big_model)$'Pr(>F)'[2] #Interacton Model 8 (All Interaction Except Sex:Smoker)
anova_final_p_value[3] = anova(model_all_2way,big_model)$'Pr(>F)'[2] #Interacton Model 9 (2 way Interaction Model)
anova_final_p_value[4] = anova(model_all_3way,big_model)$'Pr(>F)'[2] #Interacton Model 10 (3 way Interaction Model)

anova_final_p_value[5] = anova(poly2_int_model8,big_model)$'Pr(>F)'[2] # Polynomial degree 2 + All Interaction Except Sex:Smoker
anova_final_p_value[6] = anova(poly2_int_model9,big_model)$'Pr(>F)'[2] # Polynomial degree 2 + 2 Way Interaction
anova_final_p_value[7] = anova(poly2_int_model10,big_model)$'Pr(>F)'[2] # Polynomial degree 2 + 3 Way Interaction
```

Let's do the AIC and BIC to see what' the outcome, after do the ANOVA F Test.

#####**AIC, BIC of the Big Model:**
```{r include=FALSE}
n = length(resid(big_model))
big_model_aic = step(big_model, direction = "backward", trace = 0)
big_model_bic = step(big_model, direction = "backward", k = log(n), trace = 0)
```

```{r include=FALSE}
poly2_int_model8_aic = step(poly2_int_model8, direction = "backward", trace = 0)
poly2_int_model8_bic = step(poly2_int_model8, direction = "backward", k = log(n), trace = 0)

poly2_int_model9_aic = step(poly2_int_model9, direction = "backward", trace = 0)
poly2_int_model9_bic = step(poly2_int_model9, direction = "backward", k = log(n), trace = 0)

poly2_int_model10_aic = step(poly2_int_model10, direction = "backward", trace = 0)
poly2_int_model10_bic = step(poly2_int_model10, direction = "backward", k = log(n), trace = 0)
```

**ANOVA F Test of the AIC/BIC**
```{r include=FALSE}
anova_final_p_value[8] = anova(big_model_aic,big_model)$'Pr(>F)'[2] # Big Model AIC
anova_final_p_value[9] = anova(big_model_bic,big_model)$'Pr(>F)'[2] # Big Model BIC

anova_final_p_value[10] = anova(poly2_int_model8_aic,big_model)$'Pr(>F)'[2]
anova_final_p_value[11] = anova(poly2_int_model8_bic,big_model)$'Pr(>F)'[2]
anova_final_p_value[12] = anova(poly2_int_model9_aic,big_model)$'Pr(>F)'[2]
anova_final_p_value[13] = anova(poly2_int_model9_bic,big_model)$'Pr(>F)'[2]
anova_final_p_value[14] = anova(poly2_int_model10_aic,big_model)$'Pr(>F)'[2]
anova_final_p_value[15] = anova(poly2_int_model10_bic,big_model)$'Pr(>F)'[2]
```


```{r include=FALSE}
df_compare_anova_final = data.frame(
  ID = c("1","2","3","4","5","6","7","8","9","10","11","12","13","14","15"),
  null_Model = c("Polynomial Degree 2","All Interaction Except Sex:Smoker","2 way","3 way",
                 "Polynomial Degree 2 + All Interaction Except Sex:Smoker","Polynomial Degree 2 + 2 way",
                 "Polynomial Degree 2 + 3 way","Big Model - AIC", "Big Model - BIC",
                 "AIC - Polynomial Degree 2 + All Interaction Except Sex:Smoker","BIC - Polynomial Degree 2 + All Interaction Except Sex:Smoker",
                 "AIC - Polynomial Degree 2 + 2 way","BIC- Polynomial Degree 2 + 2 way",
                 "AIC - Polynomial Degree 2 + 3 way","BIC - Polynomial Degree 2 + 3 way"),
  full_Model = c("Big Model","Big Model","Big Model","Big Model","Big Model",
                 "Big Model","Big Model","Big Model","Big Model","Big Model","Big Model",
                 "Big Model","Big Model","Big Model","Big Model"),
  p_value = c(anova_final_p_value[1],anova_final_p_value[2],anova_final_p_value[3],anova_final_p_value[4],
              anova_final_p_value[5],anova_final_p_value[6],anova_final_p_value[7],anova_final_p_value[8],
              anova_final_p_value[9],anova_final_p_value[10],anova_final_p_value[11],anova_final_p_value[12],
              anova_final_p_value[13],anova_final_p_value[14],anova_final_p_value[15]),
  descision = c("Big Model","Big Model","Big Model","3 way","Big Model","Big Model","Polynomial Degree 2 + 3 way","Big Model - AIC","Big Model - BIC","Big Model","Big Model","Big Model","Big Model","AIC - Polynomial Degree 2 + 3 way","BIC - Polynomial Degree 2 + 3 way")
)
```

```{r echo=FALSE}
library(knitr)
kable(df_compare_anova_final, format = "pandoc",padding = 2)
```

From the above table (Anova F Test), It sees the Big Table or the 3 Way Interaction or 3 Way Interaction + Polynomial degree 2 is of higher significance.


#####**RSS, RMSE and RMSE LOOCV**
Let'e calculate the RSS, RMSE and RMSE LOOCV of the model
**RSS**
```{r}
sum((resid(big_model))^2)
```

**RMSE**
```{r}
sqrt(mean(sum((resid(big_model))^2)))
```

**RMSE LOOCV**
```{r}
sqrt(mean((resid(big_model)/(1-hatvalues(big_model)))^2))
```

```{r include=FALSE}
df_big_model = data.frame(
  Metric = c("RSS","RMSE", "RMSE LOOCV"),
  Value = c(sum((resid(big_model))^2),sqrt(mean(sum((resid(big_model))^2))),sqrt(mean((resid(big_model)/(1-hatvalues(big_model)))^2)))
)
```

```{r echo=FALSE}
library(knitr)
kable(df_big_model, format = "pandoc",padding = 2)
```

The RMSE LOOCV seems better than that of `Multiple Linear Regression`. We will compare at the last while making the decission around models


#####**Reduced Big Model via AIC :**

```{r}
big_model = lm(FEV ~ (Age + Height + Sex + Smoker) ^ 3 + poly(Age,3) + poly(Height,3), data = childfev)
big_model_aic = step(big_model, direction = "backward", trace = 0)
summary(big_model_aic)
```

It seems the quadratic model is significance with low p value **<2e-16**, including all the predictors are significance though except `Age` where the p value is around `r summary(big_model_aic)$coefficientp[2,4]`

#####**RSS, RMSE and RMSE LOOCV**
Let'e calculate the RSS, RMSE and RMSE LOOCV of the model
**RSS**
```{r}
sum((resid(big_model_aic))^2)
```

**RMSE**
```{r}
sqrt(mean(sum((resid(big_model_aic))^2)))
```

**RMSE LOOCV**
```{r}
sqrt(mean((resid(big_model_aic)/(1-hatvalues(big_model_aic)))^2))
```

```{r include=FALSE}
df_big_model_aic = data.frame(
  Metric = c("RSS","RMSE", "RMSE LOOCV"),
  Value = c(sum((resid(big_model_aic))^2),sqrt(mean(sum((resid(big_model_aic))^2))),sqrt(mean((resid(big_model_aic)/(1-hatvalues(big_model_aic)))^2)))
)
```

```{r echo=FALSE}
library(knitr)
kable(df_big_model_aic, format = "pandoc",padding = 2)
```

The RMSE LOOCV seems better than that of `Multiple Linear Regression`. We will compare at the last while making the decission around models


###Compare RSS, RMSE, RMSE LOOCV - All Models:

```{r eval=FALSE, include=FALSE}
compare_model = data.frame(
  Model = c("mlr","quad", "cube", "high_poly", "i2_way_int","i3_way_int","i4_way_int","big_model","big_model_aic"),
  No_Of_Parameters = c(length(coef(mlr_model)),length(coef(quad_model)),length(coef(cube_model)),length(coef(high_model)),length(coef(two_int_model)),length(coef(three_int_model)),length(coef(four_int_model)),length(coef(big_model)),length(coef(big_model_aic))),
  RSS = c(sum((resid(mlr_model))^2),sum((resid(quad_model))^2),sum((resid(cube_model))^2),sum((resid(high_model))^2),sum((resid(two_int_model))^2),sum((resid(three_int_model))^2),sum((resid(four_int_model))^2),sum((resid(big_model))^2),sum((resid(big_model_aic))^2)),
  RMSE = c(sqrt(mean(sum((resid(mlr_model))^2))),sqrt(mean(sum((resid(quad_model))^2))),sqrt(mean(sum((resid(cube_model))^2))),sqrt(mean(sum((resid(high_model))^2))),sqrt(mean(sum((resid(two_int_model))^2))),sqrt(mean(sum((resid(three_int_model))^2))),sqrt(mean(sum((resid(four_int_model))^2))),sqrt(mean(sum((resid(big_model))^2))),sqrt(mean(sum((resid(big_model_aic))^2)))),
  RMSE_LOOCV = c(sqrt(mean((resid(mlr_model)/(1-hatvalues(mlr_model)))^2)),sqrt(mean((resid(quad_model)/(1-hatvalues(quad_model)))^2)),sqrt(mean((resid(cube_model)/(1-hatvalues(cube_model)))^2)),sqrt(mean((resid(high_model)/(1-hatvalues(high_model)))^2)),sqrt(mean((resid(two_int_model)/(1-hatvalues(two_int_model)))^2)),sqrt(mean((resid(three_int_model)/(1-hatvalues(three_int_model)))^2)),sqrt(mean((resid(four_int_model)/(1-hatvalues(four_int_model)))^2)),sqrt(mean((resid(big_model)/(1-hatvalues(big_model)))^2)),sqrt(mean((resid(big_model_aic)/(1-hatvalues(big_model_aic)))^2)))  
  )
```


```{r eval=FALSE, include=FALSE}
library(knitr)
kable(compare_model, format = "pandoc",padding = 2)
```

From the above it seems the best model is the big model reduced via AIC. Let's check 


###Residual Diagnostic - All Models:



###Outlier Diagnostic - All Models:



###Model Selection - All Models: