---
title: 'Data Analysis Project - STAT 420 - Group Project'
author: "Luma Vasiljevic(lumav2), Sushanta Panda(panda5)"
date: 
output:
  html_document:
    theme: flatly
    toc: yes
    fig_width: 10
    fig_height: 5
  pdf_document:
    toc: yes
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
library(knitr)
opts_chunk$set(cache = TRUE, autodep = TRUE)
```

# Introduction


###Description of the dataset:
Forced Expiratory Volume (FEV) is an index of pulmonary function that measures the volume of the air expelled after one second of constant effort. The data contains the determinations of FEB on 654 children ages 6 – 22 who are seen in childhood respiratory disease study in 1980 in East Boston, Massachusetts. The data are part of a larger study to follow the change in pulmonary function over time in children.

#####**Dataset Link: **
http://www.statsci.org/data/general/fev.html

#####**Variables in the Dataset:**

```{r include=FALSE}
Variable = data.frame(
  VariableName = c("ID","Age", "Height", "Sex", "Smoker", "FEV"),
  Category = c("Numeric","Numeric", "Numeric", "Categorical", "Categorical", "Numeric"),
  Description = c("Uniquely Identified Row","Age of the child", "Height of the child in inches", "Sex of the child ", "Whether the child is a non-smoker or current smoker", "FEV of the child in litres")
)
```


```{r echo=FALSE}
library(knitr)
kable(Variable, format = "pandoc",padding = 2)
```

#####**Background information of the dataset:**

The data contains the determinations of FEB on 654 children ages 6 – 22 who are seen in childhood respiratory disease study in 1980 in East Boston, Massachusetts. The data are part of a larger study to follow the change in pulmonary function over time in children

Note: No citation required for this source (http://www.statsci.org/data/general/fev.html)


###Why is it interesting:
This dataset has chosen by us because of personal interests, whether we can predict the child’s FEV with the help of the available predictor, rather going for a Pulmonary Function Test, which will identify any pulmonary disease of a child. And secondly, to do statistical analysis on what are the predictors responsible to increase / decrease the pulmonary function of the child and try to find answer on these lines.

###Why are we creating a model of this Data:
In order to **predict the child's Forced Exporatory Volume (FEV)** based on the Child's Age, Height, Sex and whether the child is a smoker or not. This will help for kick-start the treatment of the child based on the FEV reading, rather going throgh the Pulmonary Function test.


###Goal of the Model:
The goal of the model is to find the best model after going through the several methods, which predict the child's FEV with minimal error. The best model would have the lowest Root Mean Square Error (RMSE) against Leave One Out cross validation (LOOCV).


# Methods
We will be doing several data analysis and methods in this section, where each section will be describing what's the part of the tasks.

###Load FEV data, Observations:

```{r}
childfev = read.csv("http://www.statsci.org/data/general/fev.txt",
                    sep = "\t",
                    quote = "\"",
                    comment.char = "",
                    stringsAsFactors = FALSE)
childfev$Sex = as.factor(childfev$Sex)
childfev$Smoker = as.factor(childfev$Smoker)
str(childfev)
dim(childfev)
head(childfev$FEV,10)
```

From the dataset, it observered data, Age, Heigh is a numerical variable, where as Sex / Smoker field is a categorical variable. The FEV is the numerical **response** variable.

#####**Load FEV data**
```{r fig.height=7, fig.width=7}
pairs(childfev[c('Age','FEV','Height','Sex','Smoker')], col = "darkgrey")
```

From the pairs plot, it sees there is a clear signs of linear releationship between FEV and Height. However there is no clear sign of linear relationship between FEV and Age variable. The 2 categorical variable `Sex` and `Smoker` seems to have 2 distinct data. Let's explore this

**Let's check the Correlation Matrix to explore what's the co-relation among the variables**
```{r}
cor(childfev[c('Age','Height','FEV')])
```
It seems that what the pair plot shows seems correct, from the corelation matrix it also suggests that `Age` and `Height` are higly corelation with `FEV` response, as well as among it self,  We need to explore the variance inflation factor (VIF) while creating our model in further.


#####**Categorical Data of Sex and Smoker**
```{r}
table(childfev$Sex)
table(childfev$Smoker)
```

###Model 1 - Multiple Linear Regression (MLR) FEV data:
Let's start with the Multiple Linear Regression (MLR) against all the predictor (Except the ID), to predict the FEV as the response

```{r}
mlr_model = lm(FEV ~ Age + Height + Sex + Smoker, data = childfev)
```

The Multiple Linear Regression contains all the predictor in the model, which also includes the dummy variable for the categorical predictor (Sex and Smoker)

###Model 2 - Polynomial Transformation of Numeric Predictor
Let's explore the polynomial transformation of the predictor to see whether we can able to find the best model which lower the RMSE LOOCV

```{r}
poly2_model = lm(FEV ~ Sex + Smoker + Age + Height + I(Age^2) + I(Height^2) , data = childfev)
poly3_model = lm(FEV ~ Sex + Smoker + Age + Height + I(Age^2) + I(Height^2) + I(Age^3) + I(Height^3) , data = childfev)
poly4_model = lm(FEV ~ Sex + Smoker + Age + Height + I(Age^2) + I(Height^2) + I(Age^3) + I(Height^3) + I(Age^4) + I(Height^4), data = childfev)
poly5_model = lm(FEV ~ Sex + Smoker + Age + Height + I(Age^2) + I(Height^2) + I(Age^3) + I(Height^3) + I(Age^4) + I(Height^4) + I(Age^5) + I(Height^5), data = childfev)
poly6_model = lm(FEV ~ Sex + Smoker + Age + Height + I(Age^2) + I(Height^2) + I(Age^3) + I(Height^3) + I(Age^4) + I(Height^4) + I(Age^5) + I(Height^5) + I(Age^6) + I(Height^6), data = childfev)
```

###Model 3 - Interaction between Predictors:
Following are the exploration needs to be done as part of the Interaction between the predictors
 - Interaction between Numerical Predictor (Age, Height) and Categorical Predictor (Sex, Smoker) - One at a Time
 - Interaction between Numerical Predictors (Age, Height) it self
 - Interaction between all of the them 2 way and 3 way.
 - Carry out Inova F Test and RMSE LOOCV and Average Percentage Error to find out what's the best model


```{r}
model_age_sex = lm(FEV ~ (Age + Sex) ^ 2 , data = childfev)
model_age_smoker = lm(FEV ~ (Age + Smoker) ^ 2 , data = childfev)
model_age_sex_smoker = lm(FEV ~ Age + Sex + Smoker + Age:Sex + Age:Smoker , data = childfev)
model_height_sex = lm(FEV ~ (Height + Sex) ^ 2 , data = childfev)
model_height_smoker = lm(FEV ~ (Height + Smoker) ^ 2 , data = childfev)
model_height_sex_smoker = lm(FEV ~ Height + Sex + Smoker + Height:Sex + Height:Smoker , data = childfev)
model_all_int_except_age_height = lm(FEV ~ Age + Height + Sex + Smoker + Age:Sex + Age:Smoker + Height:Sex + Height:Smoker, data = childfev) 
model_all_int_with_age_height = lm(FEV ~ Age + Height + Sex + Smoker + Age:Sex + Age:Smoker + Height:Sex + Height:Smoker + Age:Height, data = childfev) 
model_all_2way = lm(FEV ~ (Age + Height + Sex + Smoker) ^ 2, data = childfev) 
model_all_3way = lm(FEV ~ (Age + Height + Sex + Smoker) ^ 3, data = childfev)
```


###Model 4 - Creation of Big Model (Polynomial + Interaction), Stepwise via AIC / BIC:
Let's create a big model, with Polynomial of degree 3 and 3 way interaction between categorical-to-categorical, categorical-to-numeric, numeric-to-numeric and see it's score. 

Also create few models with combination from the previous model (which treat as good model)
 - Polynomial degree 2 + Interaction Model 8 
 - Polynomial degree 2 + Interaction Model 9 (2 way interaction)
 - Polynomial degree 2 + Interaction Model 10 (3 way interaction)

#####**Big Model: + 3 other model**

```{r}
big_model = lm(FEV ~ (Age + Height + Sex + Smoker) ^ 3 + I(Age^2) + I(Height^2) + I(Age^3) + I(Height^3), data = childfev) # Big Model - Polynomial degree 3 + 3 Way Interaction
poly2_int_model8 = lm(FEV ~ Age + Height + Sex + Smoker + Age:Sex + Age:Smoker + Height:Sex + Height:Smoker + Age:Height , data = childfev) # Polynomial degree 2 + All Interaction Except Sex:Smoker
poly2_int_model9 = lm(FEV ~ (Age + Height + Sex + Smoker) ^ 2, data = childfev) # Polynomial degree 2 + 2 Way Interaction
poly2_int_model10 = lm(FEV ~ (Age + Height + Sex + Smoker) ^ 3, data = childfev) # Polynomial degree 2 + 3 Way Interaction
```

#####**AIC, BIC of the Big Model:**
Let's do the AIC and BIC to see what' the outcome, after do the ANOVA F Test.

```{r}
n = length(resid(big_model))
big_model_aic = step(big_model, direction = "backward", trace = 0)
big_model_bic = step(big_model, direction = "backward", k = log(n), trace = 0)
```

Let's compare with the good model from the Interaction model and Polynomial Regression Model, to see which one is siginificance

# Results
Let's evaluate the results which is derived from the above 5 different category of models

###Model 1,2 - Multiple Linear Regression (MLR) + Log Transformation + Polynomial  - Results:


```{r include=FALSE}
#train_test_error_poly_model = rep(0,6)
r2_poly_model = rep(0,6)
adjr2_poly_model = rep(0,6)

#Populate train_test_error_model
#train_test_error_poly_model[1] = average_percent_error(childfev_tst_data$FEV, predict(mlr_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_poly_model[2] = average_percent_error(childfev_tst_data$FEV, predict(poly2_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_poly_model[3] = average_percent_error(childfev_tst_data$FEV, predict(poly3_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_poly_model[4] = average_percent_error(childfev_tst_data$FEV, predict(poly4_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_poly_model[5] = average_percent_error(childfev_tst_data$FEV, predict(poly5_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_poly_model[6] = average_percent_error(childfev_tst_data$FEV, predict(poly6_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))

#R2
r2_poly_model[1] = summary(mlr_model)$r.squared
r2_poly_model[2] = summary(poly2_model)$r.squared
r2_poly_model[3] = summary(poly3_model)$r.squared
r2_poly_model[4] = summary(poly4_model)$r.squared
r2_poly_model[5] = summary(poly5_model)$r.squared
r2_poly_model[6] = summary(poly6_model)$r.squared

#Adjusted R2
adjr2_poly_model[1] = summary(mlr_model)$adj.r.squared
adjr2_poly_model[2] = summary(poly2_model)$adj.r.squared
adjr2_poly_model[3] = summary(poly3_model)$adj.r.squared
adjr2_poly_model[4] = summary(poly4_model)$adj.r.squared
adjr2_poly_model[5] = summary(poly5_model)$adj.r.squared
adjr2_poly_model[6] = summary(poly6_model)$adj.r.squared
```

```{r include=FALSE}
#Creating Empty list
rss_poly_model = rep(0,6)
rmse_poly_model = rep(0,6)
rmse_loocv_poly_model = rep(0,6)

#Populate RSS
rss_poly_model[1] = sum((resid(mlr_model))^2)
rss_poly_model[2] = sum((resid(poly2_model))^2)
rss_poly_model[3] = sum((resid(poly3_model))^2)
rss_poly_model[4] = sum((resid(poly4_model))^2)
rss_poly_model[5] = sum((resid(poly5_model))^2)
rss_poly_model[6] = sum((resid(poly6_model))^2)

#Populate RMSE
rmse_poly_model[1] = sqrt(mean(sum((resid(mlr_model))^2)))
rmse_poly_model[2] = sqrt(mean(sum((resid(poly2_model))^2)))
rmse_poly_model[3] = sqrt(mean(sum((resid(poly3_model))^2)))
rmse_poly_model[4] = sqrt(mean(sum((resid(poly4_model))^2)))
rmse_poly_model[5] = sqrt(mean(sum((resid(poly5_model))^2)))
rmse_poly_model[6] = sqrt(mean(sum((resid(poly6_model))^2)))

#Populate RMSE LOOC
rmse_loocv_poly_model[1] = sqrt(mean((resid(mlr_model)/(1-hatvalues(mlr_model)))^2))
rmse_loocv_poly_model[2] = sqrt(mean((resid(poly2_model)/(1-hatvalues(poly2_model)))^2))
rmse_loocv_poly_model[3] = sqrt(mean((resid(poly3_model)/(1-hatvalues(poly3_model)))^2))
rmse_loocv_poly_model[4] = sqrt(mean((resid(poly4_model)/(1-hatvalues(poly4_model)))^2))
rmse_loocv_poly_model[5] = sqrt(mean((resid(poly5_model)/(1-hatvalues(poly4_model)))^2))
rmse_loocv_poly_model[6] = sqrt(mean((resid(poly6_model)/(1-hatvalues(poly6_model)))^2))
```

```{r echo=FALSE}
black = "#2C3E50"
grey = "#ECF0F1"
green = "#009999"
purple = "#990073"
blue = "blue4"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
polynomial_degree = 1:6
plot(polynomial_degree, rss_poly_model, type = "b",
       ylim = c(min(rss_poly_model), max(rss_poly_model)), col = purple, lwd = 2,
       xlab = "Polynomial Degree", ylab = "Residual Sum Square (RSS)", main = "RSS Vs Polynomial Degree")

plot(polynomial_degree, rmse_poly_model, type = "b",
       ylim = c(min(rmse_poly_model), max(rmse_poly_model)), col = green, lwd = 2,
       xlab = "Polynomial Degree", ylab = "Root Mean Square (RMSE)", main = "RMSE Vs Polynomial Degree")

plot(polynomial_degree, rmse_loocv_poly_model, type = "b",
       ylim = c(min(rmse_loocv_poly_model), max(rmse_loocv_poly_model)), col = blue, lwd = 2,
       xlab = "Polynomial Degree", ylab = "Root Mean Square (RMSE) LOOCV", main = "RMSE LOOCV Vs Polynomial Degree")
```

It seems that as the Polynomial degree increases, the `RSS` and `RMSE` decreases, which should be as the model becomes more and more complex, the error will decreased. However the RMSE LOOCV seems **increases** after the Polynomial degree 2. Hence it's not been seen good, if we increase the model beyond degree 2, as the Root Mean Square Error (RMSE) Leave One Out Cross Validation Error increases.

Let's see what happens to the R2 and Adjusted R2 when the polynomail degree increases. Also let's see what will be the Average Percentage Error, when the Polynomail degree increases. 


```{r echo=FALSE}
gold = "gold4"
red = "darkred"
orchid = "darkorchid2"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
polynomial_degree = 1:6
plot(polynomial_degree, r2_poly_model, type = "b",
       ylim = c(min(r2_poly_model), max(r2_poly_model)), col = gold, lwd = 2,
       xlab = "Polynomial Degree", ylab = "R2", main = "R2 Vs Polynomial Degree")

plot(polynomial_degree, adjr2_poly_model, type = "b",
       ylim = c(min(adjr2_poly_model), max(adjr2_poly_model)), col = red, lwd = 2,
       xlab = "Polynomial Degree", ylab = "Adjusted R2", main = "Adjusted R2 Vs Polynomial Degree")

#plot(polynomial_degree, train_test_error_poly_model, type = "b",
#       ylim = c(min(train_test_error_poly_model), max(train_test_error_poly_model)), col = orchid, lwd = 2,
#       xlab = "Polynomial Degree", ylab = "Average Percent Error", main = "Average Percent Error Vs Polynomial Degree")
```

It seems the R2 keeps increasing as the Polynomial degree increases. However adjusted R2 seems mostly fixed on/beyond Polynomial degree 2. Which kind of gives enough evidence to go for the model having Polynomail degree 2. 

The 3rd plot which gives the average percentage of error, which is calculated from the below formula

which depicts that the percentage of error doesn't decrease after Polynomial degree 2, and increased. This also have inclination towards the Polynomial Regression model with Degree 2.

Let's do an Inova F Test to compare these models, to see whether the Polynomial degree has significance or not.

#####**Anova F Test**
```{r echo=FALSE}
anova_poly_p_value = rep(0,4)
anova_poly_p_value[1] = anova(mlr_model,poly2_model)$'Pr(>F)'[2]
anova_poly_p_value[2] = anova(poly2_model,poly3_model)$'Pr(>F)'[2]
anova_poly_p_value[3] = anova(poly2_model,poly4_model)$'Pr(>F)'[2]
anova_poly_p_value[4] = anova(poly2_model,poly5_model)$'Pr(>F)'[2]
anova_poly_p_value[5] = anova(poly2_model,poly6_model)$'Pr(>F)'[2]

red = "firebrick4"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
polynomial_degree = 1:5
plot(polynomial_degree, anova_poly_p_value, type = "b",
       ylim = c(min(anova_poly_p_value), max(anova_poly_p_value)), col = red, lwd = 2,
       xlab = "Model Participate in Anova F Test", ylab = "Anova P Value", main = "Anova P Value Vs Model Comparision")
abline (h = 0.05, lwd = 1, lty = 2, col = "darkgreen")
legend("topleft", legend=c("p value","alpha(0.05)"), col = c("firebrick4","darkgreen"),lty = c(1,2))

```

Each point shows the `p value` comes from the Anova F Test between `Polynomial Regresssion of degree 1` Vs `Polynomial Regresssion of degree 2` and rest all points are between `Polynomial Regresssion of degree 2` and `Polynomial Regresssion of degree 3/4/5/6`. It clearly observed that for alpha value **`0.05`** we **failed to reject all hypothesis** of estimated parameters to be zero for Polynomial of degree more than 2. 

Let's see the comparision of the data in actual between all the models, to concrete the Model with Polynomial regression of degree 2 is the best model

```{r include=FALSE}
df_compare_anova_polynomial = data.frame(
  ID        = c("1","2","3","4","5","6"),
  Interaction_Model = c("MLR","Polynomial Degree 2","Polynomial Degree 3", "Polynomial Degree 4", "Polynomial Degree 5", "Polynomial Degree 6"),
  rss        = c(rss_poly_model[1],rss_poly_model[2],rss_poly_model[3],rss_poly_model[4],rss_poly_model[5],rss_poly_model[6]),
  rmse       = c(rmse_poly_model[1],rmse_poly_model[2],rmse_poly_model[3],rmse_poly_model[4],rmse_poly_model[5],rmse_poly_model[6]),
  rmse_loocv = c(rmse_loocv_poly_model[1],rmse_loocv_poly_model[2],rmse_loocv_poly_model[3],rmse_loocv_poly_model[4],rmse_loocv_poly_model[5],rmse_loocv_poly_model[6]), 
  r2         = c(r2_poly_model[1],r2_poly_model[2],r2_poly_model[3],r2_poly_model[4],r2_poly_model[5],r2_poly_model[6]),
  adj_r2     = c(adjr2_poly_model[1],adjr2_poly_model[2],adjr2_poly_model[3],adjr2_poly_model[4],adjr2_poly_model[5],adjr2_poly_model[6])
)
```

```{r echo=FALSE}
library(knitr)
kable(df_compare_anova_polynomial, format = "pandoc",padding = 2)
```

It seems even though ANOVA F Test suugest to Model 10 is significance (`3 Way`), the RMSE LOOCV is small (not that though) against Model 8. We will keep these 2 modesl (`Model 8` and `Model 10`) are the best model, which we will explore further


It also clearly gives confidence that Polynomial degree 2 would be the best model, from the following methods which we have tested
 - Lowest RMSE LOOCV 
 - Highest R2 and Adjusted R2
 - Lowest Average Percentage Error
 - Anova F Test P value

###Model 3 - Interaction Model - Results:

```{r echo=FALSE}
#For Age Vs FEV
pink = "deeppink"
blue = "dodgerblue"
par(mfrow = c(1, 4), oma = c(0, 0, 5, 0))
typecol = c("deeppink","dodgerblue")
plot(FEV ~ Age, data = childfev, col = typecol, pch = c(1,2), main = "Age Vs Fev")
grid()
int_female = summary(model_age_sex)$coefficient[1,1]
int_male = summary(model_age_sex)$coefficient[1,1] + summary(model_age_sex)$coefficient[3,1]
slope_female = summary(model_age_sex)$coefficient[2,1]
slope_male = summary(model_age_sex)$coefficient[2,1] + summary(model_age_sex)$coefficient[4,1]
abline(int_female,slope_female, lwd = 2, col = pink, lty = 2)
abline(int_male,slope_male, lwd = 2, col = blue, lty = 2)
legend("topleft",legend=c("Female","Male"),col = c("deeppink","dodgerblue"), pch=c(1,2))

gold = "gold2"
green = "darkolivegreen"
typecol = c("gold2","darkolivegreen")
plot(FEV ~ Age, data = childfev, col = typecol, pch = c(1,2), main = "Age Vs Fev")
grid()
int_smoker = summary(model_age_smoker)$coefficient[1,1]
int_nonsmoker = summary(model_age_smoker)$coefficient[1,1] + summary(model_age_smoker)$coefficient[3,1]
slope_smoker = summary(model_age_smoker)$coefficient[2,1]
slope_nonsmoker = summary(model_age_smoker)$coefficient[2,1] + summary(model_age_smoker)$coefficient[4,1]
abline(int_smoker,slope_smoker, lwd = 2, col = gold, lty = 2)
abline(int_nonsmoker,slope_nonsmoker, lwd = 2, col = green, lty = 2)
legend("topleft",legend=c("Smoker","Non-Smoker"),col = c("gold2","darkolivegreen"), pch=c(1,2))

#For Height Vs FEV
pink = "orangered"
blue = "yellowgreen"
typecol = c("orangered","yellowgreen")
plot(FEV ~ Height, data = childfev, col = typecol, pch = c(1,2), main = "Height Vs Fev")
grid()
int_female = summary(model_height_sex)$coefficient[1,1]
int_male = summary(model_height_sex)$coefficient[1,1] + summary(model_height_sex)$coefficient[3,1]
slope_female = summary(model_height_sex)$coefficient[2,1]
slope_male = summary(model_height_sex)$coefficient[2,1] + summary(model_height_sex)$coefficient[4,1]
abline(int_female,slope_female, lwd = 2, col = pink, lty = 2)
abline(int_male,slope_male, lwd = 2, col = blue, lty = 2)
legend("topleft",legend=c("Female","Male"),col = c("orangered","yellowgreen"), pch=c(1,2))

gold = "tan1"
green = "slateblue4"
typecol = c("tan1","slateblue4")
plot(FEV ~ Height, data = childfev, col = typecol, pch = c(1,2), main = "Heighte Vs Fev")
grid()
int_smoker = summary(model_height_smoker)$coefficient[1,1]
int_nonsmoker = summary(model_height_smoker)$coefficient[1,1] + summary(model_height_smoker)$coefficient[3,1]
slope_smoker = summary(model_height_smoker)$coefficient[2,1]
slope_nonsmoker = summary(model_height_smoker)$coefficient[2,1] + summary(model_height_smoker)$coefficient[4,1]
abline(int_smoker,slope_smoker, lwd = 2, col = gold, lty = 2)
abline(int_nonsmoker,slope_nonsmoker, lwd = 2, col = green, lty = 2)
legend("topleft",legend=c("Smoker","Non-Smoker"),col = c("tan1","slateblue4"), pch=c(1,2))
```

It seems that the interaction between the `Age` with categorical variable (Sex and Smoker) has changed the estimates drasticallly, than the interaction between `Height` with the Categorical variable (Sex and Smoker).

Let's conduct the Anova F Test to verify, which interaction is significance and which is not

#####**Anova F Test**
```{r echo=FALSE}
anova_int_p_value = rep(0,9)
anova_int_p_value[1] = anova(model_age_sex,model_age_sex_smoker)$'Pr(>F)'[2]
anova_int_p_value[2] = anova(model_age_smoker,model_age_sex_smoker)$'Pr(>F)'[2]
anova_int_p_value[3] = anova(model_height_sex,model_height_sex_smoker)$'Pr(>F)'[2]
anova_int_p_value[4] = anova(model_height_smoker,model_height_sex_smoker)$'Pr(>F)'[2]
anova_int_p_value[5] = anova(model_age_sex_smoker,model_all_int_except_age_height)$'Pr(>F)'[2]
anova_int_p_value[6] = anova(model_height_sex,model_all_int_except_age_height)$'Pr(>F)'[2]
anova_int_p_value[7] = anova(model_height_sex_smoker,model_all_int_except_age_height)$'Pr(>F)'[2]
anova_int_p_value[8] = anova(model_all_int_except_age_height,model_all_int_with_age_height)$'Pr(>F)'[2]
anova_int_p_value[9] = anova(model_all_int_with_age_height,model_all_2way)$'Pr(>F)'[2] #Relation between Sex and Smoker is non-Significant
anova_int_p_value[10] = anova(model_all_int_with_age_height,model_all_3way)$'Pr(>F)'[2] #Certainly this is one of the best model
```


```{r include=FALSE}
df_compare_anova_interaction = data.frame(
  ID = c("1","2","3","4","5","6","7","8","9","10"),
  null_Model = c("Age+Sex+Age:Sex","Age+Smoker+Age:Smoker","Height+Sex+Height:Sex","Height+Smoker+Height:Smoker",
                 "Age+Sex+Smoker+Age:Sex+Age:Smoker","Height+Sex+Height:Sex","Height+Sex+Smoker+Height:Sex+Height:Smoker",
                 "Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker","Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker+Age:Height",
                 "Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker+Age:Height"),
  full_Model = c("Age+Sex+Smoker+Age:Sex+Age:Smoker","Age+Sex+Smoker+Age:Sex+Age:Smoker","Height+Sex+Smoker+Height:Sex+Height:Smoker",
                 "Height+Sex+Smoker+Height:Sex+Height:Smoker","Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker",
                 "Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker","Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker",
                 "Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker+Age:Height","2 way","3 way"),
  p_value = c(anova_int_p_value[1],anova_int_p_value[2],anova_int_p_value[3],anova_int_p_value[4],anova_int_p_value[5],anova_int_p_value[6],anova_int_p_value[7],
              anova_int_p_value[8],anova_int_p_value[9],anova_int_p_value[10]
              ),
  descision = c("Age+Sex+Smoker+Age:Sex+Age:Smoker","Age+Sex+Smoker+Age:Sex+Age:Smoker","Height+Sex+Height:Sex",
                "Height+Sex+Smoker+Height:Sex+Height:Smoker","Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker",
                "Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker","Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker",
                "Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker+Age:Height","Age+Height+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker+Age:Height",
                "3way")
)
```

```{r echo=FALSE}
library(knitr)
kable(df_compare_anova_interaction, format = "pandoc",padding = 2)
```

It seems the 3 way interaction seems significance among all the interaction between the numeric and categorical variable.

Let's see how these model perform on the RSS, RMSE, RMSE LOOCV and 

```{r include=FALSE}
#train_test_error_int_model = rep(0,10)
r2_int_model = rep(0,10)
adjr2_int_model = rep(0,10)

#Populate train_test_error_model
#train_test_error_int_model[1] = average_percent_error(childfev_tst_data$FEV, predict(model_age_sex, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_int_model[2] = average_percent_error(childfev_tst_data$FEV, predict(model_age_smoker, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_int_model[3] = average_percent_error(childfev_tst_data$FEV, predict(model_age_sex_smoker, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_int_model[4] = average_percent_error(childfev_tst_data$FEV, predict(model_height_sex, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_int_model[5] = average_percent_error(childfev_tst_data$FEV, predict(model_height_smoker, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_int_model[6] = average_percent_error(childfev_tst_data$FEV, predict(model_height_sex_smoker, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_int_model[7] = average_percent_error(childfev_tst_data$FEV, predict(model_all_int_except_age_height, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_int_model[8] = average_percent_error(childfev_tst_data$FEV, predict(model_all_int_with_age_height, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_int_model[9] = average_percent_error(childfev_tst_data$FEV, predict(model_all_2way, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_int_model[10] = average_percent_error(childfev_tst_data$FEV, predict(model_all_3way, childfev_tst_data[c("Age","Height","Sex","Smoker")]))

#R2
r2_int_model[1] = summary(model_age_sex)$r.squared
r2_int_model[2] = summary(model_age_smoker)$r.squared
r2_int_model[3] = summary(model_age_sex_smoker)$r.squared
r2_int_model[4] = summary(model_height_sex)$r.squared
r2_int_model[5] = summary(model_height_smoker)$r.squared
r2_int_model[6] = summary(model_height_sex_smoker)$r.squared
r2_int_model[7] = summary(model_all_int_except_age_height)$r.squared
r2_int_model[8] = summary(model_all_int_with_age_height)$r.squared
r2_int_model[9] = summary(model_all_2way)$r.squared
r2_int_model[10] = summary(model_all_3way)$r.squared

#Adjusted R2
adjr2_int_model[1] = summary(model_age_sex)$adj.r.squared
adjr2_int_model[2] = summary(model_age_smoker)$adj.r.squared
adjr2_int_model[3] = summary(model_age_sex_smoker)$adj.r.squared
adjr2_int_model[4] = summary(model_height_sex)$adj.r.squared
adjr2_int_model[5] = summary(model_height_smoker)$adj.r.squared
adjr2_int_model[6] = summary(model_height_sex_smoker)$adj.r.squared
adjr2_int_model[7] = summary(model_all_int_except_age_height)$adj.r.squared
adjr2_int_model[8] = summary(model_all_int_with_age_height)$adj.r.squared
adjr2_int_model[9] = summary(model_all_2way)$adj.r.squared
adjr2_int_model[10] = summary(model_all_3way)$adj.r.squared
```

```{r include=FALSE}
#Creating Empty list
rss_int_model = rep(0,10)
rmse_int_model = rep(0,10)
rmse_loocv_int_model = rep(0,10)

#Populate RSS
rss_int_model[1] = sum((resid(model_age_sex))^2)
rss_int_model[2] = sum((resid(model_age_smoker))^2)
rss_int_model[3] = sum((resid(model_age_sex_smoker))^2)
rss_int_model[4] = sum((resid(model_height_sex))^2)
rss_int_model[5] = sum((resid(model_height_smoker))^2)
rss_int_model[6] = sum((resid(model_height_sex_smoker))^2)
rss_int_model[7] = sum((resid(model_all_int_except_age_height))^2)
rss_int_model[8] = sum((resid(model_all_int_with_age_height))^2)
rss_int_model[9] = sum((resid(model_all_2way))^2)
rss_int_model[10] = sum((resid(model_all_3way))^2)

#Populate RMSE
rmse_int_model[1] = sqrt(mean(sum((resid(model_age_sex))^2)))
rmse_int_model[2] = sqrt(mean(sum((resid(model_age_smoker))^2)))
rmse_int_model[3] = sqrt(mean(sum((resid(model_age_sex_smoker))^2)))
rmse_int_model[4] = sqrt(mean(sum((resid(model_height_sex))^2)))
rmse_int_model[5] = sqrt(mean(sum((resid(model_height_smoker))^2)))
rmse_int_model[6] = sqrt(mean(sum((resid(model_height_sex_smoker))^2)))
rmse_int_model[7] = sqrt(mean(sum((resid(model_all_int_except_age_height))^2)))
rmse_int_model[8] = sqrt(mean(sum((resid(model_all_int_with_age_height))^2)))
rmse_int_model[9] = sqrt(mean(sum((resid(model_all_2way))^2)))
rmse_int_model[10] = sqrt(mean(sum((resid(model_all_2way))^2)))

#Populate RMSE LOOC
rmse_loocv_int_model[1] = sqrt(mean((resid(model_age_sex)/(1-hatvalues(model_age_sex)))^2))
rmse_loocv_int_model[2] = sqrt(mean((resid(model_age_smoker)/(1-hatvalues(model_age_smoker)))^2))
rmse_loocv_int_model[3] = sqrt(mean((resid(model_age_sex_smoker)/(1-hatvalues(model_age_sex_smoker)))^2))
rmse_loocv_int_model[4] = sqrt(mean((resid(model_height_sex)/(1-hatvalues(model_height_sex)))^2))
rmse_loocv_int_model[5] = sqrt(mean((resid(model_height_smoker)/(1-hatvalues(model_height_smoker)))^2))
rmse_loocv_int_model[6] = sqrt(mean((resid(model_height_sex_smoker)/(1-hatvalues(model_height_sex_smoker)))^2))
rmse_loocv_int_model[7] = sqrt(mean((resid(model_all_int_except_age_height)/(1-hatvalues(model_all_int_except_age_height)))^2))
rmse_loocv_int_model[8] = sqrt(mean((resid(model_all_int_with_age_height)/(1-hatvalues(model_all_int_with_age_height)))^2))
rmse_loocv_int_model[9] = sqrt(mean((resid(model_all_2way)/(1-hatvalues(model_all_2way)))^2))
rmse_loocv_int_model[10] = sqrt(mean((resid(model_all_2way)/(1-hatvalues(model_all_2way)))^2))
```

```{r echo=FALSE}
black = "#2C3E50"
grey = "#ECF0F1"
green = "#009999"
purple = "#990073"
blue = "blue4"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
Interaction_Model = 1:10
plot(Interaction_Model, rss_int_model, type = "b",
       ylim = c(min(rss_int_model), max(rss_int_model)), col = purple, lwd = 2,
       xlab = "Interaction Model", ylab = "Residual Sum Square (RSS)", main = "RSS Vs Interaction Model")

plot(Interaction_Model, rmse_int_model, type = "b",
       ylim = c(min(rmse_int_model), max(rmse_int_model)), col = green, lwd = 2,
       xlab = "Interaction Model", ylab = "Root Mean Square (RMSE)", main = "RMSE Vs Interaction Model")

plot(Interaction_Model, rmse_loocv_int_model, type = "b",
       ylim = c(min(rmse_loocv_int_model), max(rmse_loocv_int_model)), col = blue, lwd = 2,
       xlab = "Interaction Model", ylab = "Root Mean Square (RMSE) LOOCV", main = "RMSE LOOCV Vs Interaction Model")
```

It seems that as the Interaction increased, the `RSS` and `RMSE` decreases, which should be as the model becomes more and more complex, the error will decreased. Also the RMSE LOOCV also **decreases** with increase in Interaction, however the RMSE LOOCV increased slighly after the Model 9 

Let's see what happens to the R2 and Adjusted R2 when the polynomail degree increases. Also let's see what will be the Average Percentage Error, when the Polynomail degree increases. 


```{r echo=FALSE}
gold = "gold4"
red = "darkred"
orchid = "darkorchid2"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
Interaction_Model = 1:10
plot(Interaction_Model, r2_int_model, type = "b",
       ylim = c(min(r2_int_model), max(r2_int_model)), col = gold, lwd = 2,
       xlab = "Interaction Model", ylab = "R2", main = "R2 Vs Interaction Model")

plot(Interaction_Model, adjr2_int_model, type = "b",
       ylim = c(min(adjr2_int_model), max(adjr2_int_model)), col = red, lwd = 2,
       xlab = "Interaction Model", ylab = "Adjusted R2", main = "Adjusted R2 Vs Interaction Model")

#plot(Interaction_Model, train_test_error_int_model, type = "b",
#       ylim = c(min(train_test_error_int_model), max(train_test_error_int_model)), col = orchid, lwd = 2,
#       xlab = "Interaction Model", ylab = "Average Percent Error", main = "Average Percent Error Vs Interaction Model")
```

It seems the R2 and adjusted R2 keeps increasing as the Polynomial degree increases. Also the error rate is also decreasing as the interaction increases. However after the Model 9 the Error rate increases slightly as the interaction increases

Let's see the comparision of the data in actual between all the models, to see what's the best finalize model

```{r include=FALSE}
df_compare_anova_interaction = data.frame(
  ID = c("1","2","3","4","5","6","7","8","9","10"),
  Interaction_Model = c("Age+Sex+Age:Sex","Age+Smoker+Age:Smoker","Age+Sex+Smoker+Age:Sex+Age:Smoker","Height+Sex+Height:Sex","Height+Smoker+Height:Smoker",
                        "Height+Sex+Smoker+Height:Sex+Height:Smoker","Age+Height+Sex+Smoker+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker",
                        "Age+Height+Sex+Smoker+Age:Sex+Age:Smoker+Height:Sex+Height:Smoker+Age:Height","2 Way", "3 Way"),
  rss = c(rss_int_model[1],rss_int_model[2],rss_int_model[3],rss_int_model[4],rss_int_model[5],rss_int_model[6],rss_int_model[7],rss_int_model[8],rss_int_model[9],rss_int_model[10]),
  rmse = c(rmse_int_model[1],rmse_int_model[2],rmse_int_model[3],rmse_int_model[4],rmse_int_model[5],rmse_int_model[6],rmse_int_model[7],rmse_int_model[8],rmse_int_model[9],rmse_int_model[10]),
  rmse_loocv = c(rmse_loocv_int_model[1],rmse_loocv_int_model[2],rmse_loocv_int_model[3],rmse_loocv_int_model[4],rmse_loocv_int_model[5],rmse_loocv_int_model[6],rmse_loocv_int_model[7],rmse_loocv_int_model[8],rmse_loocv_int_model[9],rmse_loocv_int_model[10]), 
  r2 = c(r2_int_model[1],r2_int_model[2],r2_int_model[3],r2_int_model[4],r2_int_model[5],r2_int_model[6],r2_int_model[7],r2_int_model[8],r2_int_model[9],r2_int_model[10]),
  adj_r2 = c(adjr2_int_model[1],adjr2_int_model[2],adjr2_int_model[3],adjr2_int_model[4],adjr2_int_model[5],adjr2_int_model[6],adjr2_int_model[7],adjr2_int_model[8],adjr2_int_model[9],adjr2_int_model[10])
)
```

```{r echo=FALSE}
library(knitr)
kable(df_compare_anova_interaction, format = "pandoc",padding = 2)
```

It kind of confirmation that Polynomial regression with degree 2 is lowest RMSE LOOCV. We have decided to see it's the best model.

###Model 4 - Big Model, AIC, BIC - Results:

```{r echo=FALSE}
anova_final_p_value = rep(0,7)
anova_final_p_value[1] = anova(poly2_model,big_model)$'Pr(>F)'[2] #Polynomial Model With Degree 2
anova_final_p_value[2] = anova(model_all_int_with_age_height,big_model)$'Pr(>F)'[2] #Interacton Model 8 (All Interaction Except Sex:Smoker)
anova_final_p_value[3] = anova(model_all_2way,big_model)$'Pr(>F)'[2] #Interacton Model 9 (2 way Interaction Model)
anova_final_p_value[4] = anova(model_all_3way,big_model)$'Pr(>F)'[2] #Interacton Model 10 (3 way Interaction Model)

anova_final_p_value[5] = anova(poly2_int_model8,big_model)$'Pr(>F)'[2] # Polynomial degree 2 + All Interaction Except Sex:Smoker
anova_final_p_value[6] = anova(poly2_int_model9,big_model)$'Pr(>F)'[2] # Polynomial degree 2 + 2 Way Interaction
anova_final_p_value[7] = anova(poly2_int_model10,big_model)$'Pr(>F)'[2] # Polynomial degree 2 + 3 Way Interaction
```


```{r include=FALSE}
poly2_int_model8_aic = step(poly2_int_model8, direction = "backward", trace = 0)
poly2_int_model8_bic = step(poly2_int_model8, direction = "backward", k = log(n), trace = 0)

poly2_int_model9_aic = step(poly2_int_model9, direction = "backward", trace = 0)
poly2_int_model9_bic = step(poly2_int_model9, direction = "backward", k = log(n), trace = 0)

poly2_int_model10_aic = step(poly2_int_model10, direction = "backward", trace = 0)
poly2_int_model10_bic = step(poly2_int_model10, direction = "backward", k = log(n), trace = 0)
```

**ANOVA F Test of the AIC/BIC**
```{r include=FALSE}
anova_final_p_value[8] = anova(big_model_aic,big_model)$'Pr(>F)'[2] # Big Model AIC
anova_final_p_value[9] = anova(big_model_bic,big_model)$'Pr(>F)'[2] # Big Model BIC

anova_final_p_value[10] = anova(poly2_int_model8_aic,big_model)$'Pr(>F)'[2]
anova_final_p_value[11] = anova(poly2_int_model8_bic,big_model)$'Pr(>F)'[2]
anova_final_p_value[12] = anova(poly2_int_model9_aic,big_model)$'Pr(>F)'[2]
anova_final_p_value[13] = anova(poly2_int_model9_bic,big_model)$'Pr(>F)'[2]
anova_final_p_value[14] = anova(poly2_int_model10_aic,big_model)$'Pr(>F)'[2]
anova_final_p_value[15] = anova(poly2_int_model10_bic,big_model)$'Pr(>F)'[2]
```


```{r include=FALSE}
df_compare_anova_final = data.frame(
  ID = c("1","2","3","4","5","6","7","8","9","10","11","12","13","14","15"),
  null_Model = c("Polynomial Degree 2","All Interaction Except Sex:Smoker","2 way","3 way",
                 "Polynomial Degree 2 + All Interaction Except Sex:Smoker","Polynomial Degree 2 + 2 way",
                 "Polynomial Degree 2 + 3 way","Big Model - AIC", "Big Model - BIC",
                 "AIC - Polynomial Degree 2 + All Interaction Except Sex:Smoker","BIC - Polynomial Degree 2 + All Interaction Except Sex:Smoker",
                 "AIC - Polynomial Degree 2 + 2 way","BIC- Polynomial Degree 2 + 2 way",
                 "AIC - Polynomial Degree 2 + 3 way","BIC - Polynomial Degree 2 + 3 way"),
  full_Model = c("Big Model","Big Model","Big Model","Big Model","Big Model",
                 "Big Model","Big Model","Big Model","Big Model","Big Model","Big Model",
                 "Big Model","Big Model","Big Model","Big Model"),
  p_value = c(anova_final_p_value[1],anova_final_p_value[2],anova_final_p_value[3],anova_final_p_value[4],
              anova_final_p_value[5],anova_final_p_value[6],anova_final_p_value[7],anova_final_p_value[8],
              anova_final_p_value[9],anova_final_p_value[10],anova_final_p_value[11],anova_final_p_value[12],
              anova_final_p_value[13],anova_final_p_value[14],anova_final_p_value[15]),
  descision = c("Big Model","Big Model","Big Model","3 way","Big Model","Big Model","Polynomial Degree 2 + 3 way","Big Model - AIC","Big Model - BIC","Big Model","Big Model","Big Model","Big Model","AIC - Polynomial Degree 2 + 3 way","BIC - Polynomial Degree 2 + 3 way")
)
```

```{r echo=FALSE}
library(knitr)
kable(df_compare_anova_final, format = "pandoc",padding = 2)
```

From the above Table, its been observed that the AIC / BIC model of the Big model / Polynomial Degree 2 + 3 way communication is being significance.

Let's do the RSS, RMSE, RMSE LOOCV, R2 and Adjusted R2 and Average Error Rate to compare these 15 models


```{r include=FALSE}
#train_test_error_final_model = rep(0,15)
r2_final_model = rep(0,15)
adjr2_final_model = rep(0,15)

#Populate train_test_error_final_model
#train_test_error_final_model[1] = average_percent_error(childfev_tst_data$FEV, predict(poly2_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[2] = average_percent_error(childfev_tst_data$FEV, predict(model_all_int_with_age_height, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[3] = average_percent_error(childfev_tst_data$FEV, predict(model_all_2way, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[4] = average_percent_error(childfev_tst_data$FEV, predict(model_all_3way, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[5] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model8, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[6] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model8_aic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[7] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model8_bic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[8] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model9, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[9] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model9_aic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[10] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model9_bic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[11] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model10, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[12] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model10_aic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[13] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model10_bic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[14] = average_percent_error(childfev_tst_data$FEV, predict(big_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[15] = average_percent_error(childfev_tst_data$FEV, predict(big_model_aic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
#train_test_error_final_model[16] = average_percent_error(childfev_tst_data$FEV, predict(big_model_bic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))


#R2
r2_final_model[1] = summary(poly2_model)$r.squared
r2_final_model[2] = summary(model_all_int_with_age_height)$r.squared
r2_final_model[3] = summary(model_all_2way)$r.squared
r2_final_model[4] = summary(model_all_3way)$r.squared
r2_final_model[5] = summary(poly2_int_model8)$r.squared
r2_final_model[6] = summary(poly2_int_model8_aic)$r.squared
r2_final_model[7] = summary(poly2_int_model8_bic)$r.squared
r2_final_model[8] = summary(poly2_int_model9)$r.squared
r2_final_model[9] = summary(poly2_int_model9_aic)$r.squared
r2_final_model[10] = summary(poly2_int_model9_bic)$r.squared
r2_final_model[11] = summary(poly2_int_model10)$r.squared
r2_final_model[12] = summary(poly2_int_model10_aic)$r.squared
r2_final_model[13] = summary(poly2_int_model10_bic)$r.squared
r2_final_model[14] = summary(big_model)$r.squared
r2_final_model[15] = summary(big_model_aic)$r.squared
r2_final_model[16] = summary(big_model_bic)$r.squared

#Adjusted R2
adjr2_final_model[1] = summary(poly2_model)$adj.r.squared
adjr2_final_model[2] = summary(model_all_int_with_age_height)$adj.r.squared
adjr2_final_model[3] = summary(model_all_2way)$adj.r.squared
adjr2_final_model[4] = summary(model_all_3way)$adj.r.squared
adjr2_final_model[5] = summary(poly2_int_model8)$adj.r.squared
adjr2_final_model[6] = summary(poly2_int_model8_aic)$adj.r.squared
adjr2_final_model[7] = summary(poly2_int_model8_bic)$adj.r.squared
adjr2_final_model[8] = summary(poly2_int_model9)$adj.r.squared
adjr2_final_model[9] = summary(poly2_int_model9_aic)$adj.r.squared
adjr2_final_model[10] = summary(poly2_int_model9_bic)$adj.r.squared
adjr2_final_model[11] = summary(poly2_int_model10)$adj.r.squared
adjr2_final_model[12] = summary(poly2_int_model10_aic)$adj.r.squared
adjr2_final_model[13] = summary(poly2_int_model10_bic)$adj.r.squared
adjr2_final_model[14] = summary(big_model)$adj.r.squared
adjr2_final_model[15] = summary(big_model_aic)$adj.r.squared
adjr2_final_model[16] = summary(big_model_bic)$adj.r.squared
```

```{r include=FALSE}
#Creating Empty list
rss_final_model = rep(0,15)
rmse_final_model = rep(0,15)
rmse_loocv_final_model = rep(0,15)

#Populate RSS
rss_final_model[1] = sum((resid(poly2_model))^2)
rss_final_model[2] = sum((resid(model_all_int_with_age_height))^2)
rss_final_model[3] = sum((resid(model_all_2way))^2)
rss_final_model[4] = sum((resid(model_all_3way))^2)
rss_final_model[5] = sum((resid(poly2_int_model8))^2)
rss_final_model[6] = sum((resid(poly2_int_model8_aic))^2)
rss_final_model[7] = sum((resid(poly2_int_model8_bic))^2)
rss_final_model[8] = sum((resid(poly2_int_model9))^2)
rss_final_model[9] = sum((resid(poly2_int_model9_aic))^2)
rss_final_model[10] = sum((resid(poly2_int_model9_bic))^2)
rss_final_model[11] = sum((resid(poly2_int_model10))^2)
rss_final_model[12] = sum((resid(poly2_int_model10_aic))^2)
rss_final_model[13] = sum((resid(poly2_int_model10_bic))^2)
rss_final_model[14] = sum((resid(big_model))^2)
rss_final_model[15] = sum((resid(big_model_aic))^2)
rss_final_model[16] = sum((resid(big_model_bic))^2)

#Populate RMSE
rmse_final_model[1] = sqrt(mean(sum((resid(poly2_model))^2)))
rmse_final_model[2] = sqrt(mean(sum((resid(model_all_int_with_age_height))^2)))
rmse_final_model[3] = sqrt(mean(sum((resid(model_all_2way))^2)))
rmse_final_model[4] = sqrt(mean(sum((resid(model_all_3way))^2)))
rmse_final_model[5] = sqrt(mean(sum((resid(poly2_int_model8))^2)))
rmse_final_model[6] = sqrt(mean(sum((resid(poly2_int_model8_aic))^2)))
rmse_final_model[7] = sqrt(mean(sum((resid(poly2_int_model8_bic))^2)))
rmse_final_model[8] = sqrt(mean(sum((resid(poly2_int_model9))^2)))
rmse_final_model[9] = sqrt(mean(sum((resid(poly2_int_model9_aic))^2)))
rmse_final_model[10] = sqrt(mean(sum((resid(poly2_int_model9_bic))^2)))
rmse_final_model[11] = sqrt(mean(sum((resid(poly2_int_model10))^2)))
rmse_final_model[12] = sqrt(mean(sum((resid(poly2_int_model10_aic))^2)))
rmse_final_model[13] = sqrt(mean(sum((resid(poly2_int_model10_bic))^2)))
rmse_final_model[14] = sqrt(mean(sum((resid(big_model))^2)))
rmse_final_model[15] = sqrt(mean(sum((resid(big_model_aic))^2)))
rmse_final_model[16] = sqrt(mean(sum((resid(big_model_bic))^2)))


#Populate RMSE LOOC
rmse_loocv_final_model[1] = sqrt(mean((resid(poly2_model)/(1-hatvalues(poly2_model)))^2))
rmse_loocv_final_model[2] = sqrt(mean((resid(model_all_int_with_age_height)/(1-hatvalues(model_all_int_with_age_height)))^2))
rmse_loocv_final_model[3] = sqrt(mean((resid(model_all_2way)/(1-hatvalues(model_all_2way)))^2))
rmse_loocv_final_model[4] = sqrt(mean((resid(model_all_3way)/(1-hatvalues(model_all_3way)))^2))
rmse_loocv_final_model[5] = sqrt(mean((resid(poly2_int_model8)/(1-hatvalues(poly2_int_model8)))^2))
rmse_loocv_final_model[6] = sqrt(mean((resid(poly2_int_model8_aic)/(1-hatvalues(poly2_int_model8_aic)))^2))
rmse_loocv_final_model[7] = sqrt(mean((resid(poly2_int_model8_bic)/(1-hatvalues(poly2_int_model8_bic)))^2))
rmse_loocv_final_model[8] = sqrt(mean((resid(poly2_int_model9)/(1-hatvalues(poly2_int_model9)))^2))
rmse_loocv_final_model[9] = sqrt(mean((resid(poly2_int_model9_aic)/(1-hatvalues(poly2_int_model9_aic)))^2))
rmse_loocv_final_model[10] = sqrt(mean((resid(poly2_int_model9_bic)/(1-hatvalues(poly2_int_model9_bic)))^2))
rmse_loocv_final_model[11] = sqrt(mean((resid(poly2_int_model10)/(1-hatvalues(poly2_int_model10)))^2))
rmse_loocv_final_model[12] = sqrt(mean((resid(poly2_int_model10_aic)/(1-hatvalues(poly2_int_model10_aic)))^2))
rmse_loocv_final_model[13] = sqrt(mean((resid(poly2_int_model10_bic)/(1-hatvalues(poly2_int_model10_bic)))^2))
rmse_loocv_final_model[14] = sqrt(mean((resid(big_model)/(1-hatvalues(big_model)))^2))
rmse_loocv_final_model[15] = sqrt(mean((resid(big_model_aic)/(1-hatvalues(big_model_aic)))^2))
rmse_loocv_final_model[16] = sqrt(mean((resid(big_model_bic)/(1-hatvalues(big_model_bic)))^2))
```

```{r echo=FALSE}
black = "#2C3E50"
grey = "#ECF0F1"
green = "#009999"
purple = "#990073"
blue = "blue4"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
Final_Model = 1:16
plot(Final_Model, rss_final_model, type = "b",
       ylim = c(min(rss_final_model), max(rss_final_model)), col = purple, lwd = 2,
       xlab = "Final Model", ylab = "Residual Sum Square (RSS)", main = "RSS Vs Final Models")

plot(Final_Model, rmse_final_model, type = "b",
       ylim = c(min(rmse_final_model), max(rmse_final_model)), col = green, lwd = 2,
       xlab = "Final Model", ylab = "Root Mean Square (RMSE)", main = "RMSE Vs Final Models")

plot(Final_Model, rmse_loocv_final_model, type = "b",
       ylim = c(min(rmse_loocv_final_model), max(rmse_loocv_final_model)), col = blue, lwd = 2,
       xlab = "Final Model", ylab = "Root Mean Square (RMSE) LOOCV", main = "RMSE LOOCV Vs Final Models")
```

It seems that as the Interaction increased, the `RSS` and `RMSE` decreases, which should be as the model becomes more and more complex, the error will decreased. Also the RMSE LOOCV also **decreases** with increase in Interaction, however the RMSE LOOCV increased slighly after the Model 9 

Let's see what happens to the R2 and Adjusted R2 when the polynomail degree increases. Also let's see what will be the Average Percentage Error, when the Polynomail degree increases. 


```{r echo=FALSE}
gold = "gold4"
red = "darkred"
orchid = "darkorchid2"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
Interaction_Model = 1:16
plot(Interaction_Model, r2_final_model, type = "b",
       ylim = c(min(r2_final_model), max(r2_final_model)), col = gold, lwd = 2,
       xlab = "Final Model", ylab = "R2", main = "R2 Vs Interaction Model")

plot(Interaction_Model, adjr2_final_model, type = "b",
       ylim = c(min(adjr2_final_model), max(adjr2_final_model)), col = red, lwd = 2,
       xlab = "Final Model", ylab = "Adjusted R2", main = "Adjusted R2 Vs Final Models")

#plot(Interaction_Model, train_test_error_final_model, type = "b",
#       ylim = c(min(train_test_error_final_model), max(train_test_error_final_model)), col = orchid, lwd = 2,
#       xlab = "Final Model", ylab = "Average Percent Error", main = "Average Percent Error Vs Final Models")
```

It seems the R2 and adjusted R2 keeps increasing as the Polynomial degree increases. Also the error rate is also decreasing as the interaction increases. However after the Model 9 the Error rate increases slightly as the interaction increases


Let's see the comparision of the data in actual between all the models, to see what's the best finalize model

```{r include=FALSE}
df_compare_anova_final = data.frame(
  ID = c("1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16"),
  Interaction_Model = c("Polynomial Degree 2","All Interaction Except Sex:Smoker","2 way","3 way",
                         "Polynomial Degree 2 + All Interaction Except Sex:Smoker","AIC - Polynomial Degree 2 + All Interaction Except Sex:Smoker", 
                         "BIC - Polynomial Degree 2 + All Interaction Except Sex:Smoker",
                         "Polynomial Degree 2 + 2 way", "AIC - Polynomial Degree 2 + 2 way", "BIC- Polynomial Degree 2 + 2 way",
                         "Polynomial Degree 2 + 3 way", "AIC - Polynomial Degree 2 + 3 way","BIC - Polynomial Degree 2 + 3 way",
                         "Big Model", "AIC - Big Model", "BIC - Big Model"
                        ),
                rss = c(rss_final_model[1],rss_final_model[2],rss_final_model[3],rss_final_model[4],rss_final_model[5],rss_final_model[6],
                        rss_final_model[7],rss_final_model[8],rss_final_model[9],rss_final_model[10], rss_final_model[11], rss_final_model[12],
                        rss_final_model[13], rss_final_model[14], rss_final_model[15], rss_final_model[16]),
               rmse = c(rmse_final_model[1],rmse_final_model[2],rmse_final_model[3],rmse_final_model[4],rmse_final_model[5],rmse_final_model[6],
                       rmse_final_model[7],rmse_final_model[8],rmse_final_model[9],rmse_final_model[10], rmse_final_model[11],rmse_final_model[12],
                       rmse_final_model[13],rmse_final_model[14],rmse_final_model[15],rmse_final_model[16]),
         rmse_loocv = c(rmse_loocv_final_model[1],rmse_loocv_final_model[2],rmse_loocv_final_model[3],rmse_loocv_final_model[4],rmse_loocv_final_model[5],
                       rmse_loocv_final_model[6],rmse_loocv_final_model[7],rmse_loocv_final_model[8],rmse_loocv_final_model[9], rmse_loocv_final_model[10],
                       rmse_loocv_final_model[11],rmse_loocv_final_model[12], rmse_loocv_final_model[13], rmse_loocv_final_model[14], 
                       rmse_loocv_final_model[15], rmse_loocv_final_model[16]),
            adj_r2 = c(adjr2_final_model[1],adjr2_final_model[2],adjr2_final_model[3],adjr2_final_model[4],adjr2_final_model[5],adjr2_final_model[6],
                       adjr2_final_model[7],adjr2_final_model[8],adjr2_final_model[9],adjr2_final_model[10], adjr2_final_model[11],adjr2_final_model[12],
                       adjr2_final_model[13],adjr2_final_model[14],adjr2_final_model[15],adjr2_final_model[16])
            #percent_error = c(train_test_error_final_model[1],train_test_error_final_model[2],train_test_error_final_model[3],
            #                  train_test_error_final_model[4],train_test_error_final_model[5],train_test_error_final_model[6],
            #                  train_test_error_final_model[7],train_test_error_final_model[8],train_test_error_final_model[9],
            #                  train_test_error_final_model[10],train_test_error_final_model[11],train_test_error_final_model[12],
            #                  train_test_error_final_model[13],train_test_error_final_model[14],train_test_error_final_model[15],
            #                  train_test_error_final_model[16])
)
```

```{r echo=FALSE}
library(knitr)
kable(df_compare_anova_final, format = "pandoc",padding = 2)
```

The best model from the above 16 models is the **Model 12** with lowest RMSE LOOCV which is **`0.3892`**, though doesn't have the highest RSS or RMSE. Let's explore the Linearity Assumptions of this model

###Diagnostic Plot - Best Model :
Below are the 2 assumptions which needs to be tested as part of the section
 - Constant Variance
 - Normality

Let's plot the residual versus Fitted plot and Q-Q plot of the model
```{r fig.height=6, fig.width=10}
par(mfrow = c(1, 2), oma = c(0, 0, 2, 0))

plot(resid(poly2_int_model10_aic)~fitted(poly2_int_model10_aic),
     pch = 1,
     cex = 1,
     cex.main = 0.8,
     col = "darkgrey",
     xlab = "Fitted Values",
     ylab = "Residuals",
     main = "Fitted Vs Residual - Polynomial Degree 2 + 3 Way Interaction Model")
abline (h = 0, col = "darkorange", lwd = 2, lty = 1)

qqnorm(resid(poly2_int_model10_aic), 
       pch = 1,
       cex = 1,
       cex.main = 0.8,
       col = "darkgrey")
qqline(resid(poly2_int_model10_aic),
       lwd = 1,
       col = "red",
       lty = 2)
```

It seems both the Constant Variance and Normality is in **Suspect**. From the residual plot, it seems that the for lower fitted values the variance is small, as the the fitted values increases, the variance also increasing. Also for the Q-Q plot, it seems have a fat tail.

Let's check the BP Test and Shapiro Wiki Test to validate this

```{r}
bptest(poly2_int_model10_aic)
shapiro.test(resid(poly2_int_model10_aic))
```

It seems that both the P value is small, which confirms the Constant Variance and Normality is **Suspect**.


###Outlier Diagnostic - All Models:
Let's check for any influence points in the model

###Large Leverage
```{r}
head(hatvalues(poly2_int_model10_aic)[hatvalues(poly2_int_model10_aic) > 2 * mean(hatvalues(poly2_int_model10_aic))],10)
```

There are around **`r length(hatvalues(poly2_int_model10_aic)[hatvalues(poly2_int_model10_aic) > 2 * mean(hatvalues(poly2_int_model10_aic))])`** observations which have the high leverage

Let's check the high standard residuals

###Large Standard Residuals
```{r}
head(rstandard(poly2_int_model10_aic)[abs(rstandard(poly2_int_model10_aic)) > 2],10)
```

There are around **`r length(rstandard(poly2_int_model10_aic)[abs(rstandard(poly2_int_model10_aic)) > 2])`** observations which have the high Standardize Residuals

Even though the model has high leverage and standard residuals, let's check whether these are influentials or not.

This can be verified by the cook's distance

```{r}
n = length(resid(poly2_int_model10_aic))
length(cooks.distance(poly2_int_model10_aic)[cooks.distance(poly2_int_model10_aic) > (4/n)])
```

It has been observed that there are around `length(cooks.distance(poly2_int_model10_aic)[cooks.distance(poly2_int_model10_aic) > (4/n)])` influential observations in the model

###Re-Fit the Model, by removing these influentials
Now, let's re-fir the model, after removing the influential data to see if the model has improved or not
```{r}
model_cd = cooks.distance(poly2_int_model10_aic)
poly2_int_model10 = lm(FEV ~ (Age + Height + Sex + Smoker) ^ 3, data = childfev, subset = model_cd <= (4/n)) # Polynomial degree 2 + 3 Way Interaction
poly2_int_model10_aic = step(poly2_int_model10, direction = "backward", trace = 0)
```

The model re-fit is now completed. Now let's draw the diagnostic plot once again

```{r fig.height=6, fig.width=10}
par(mfrow = c(1, 2), oma = c(0, 0, 2, 0))

plot(resid(poly2_int_model10_aic)~fitted(poly2_int_model10_aic),
     pch = 1,
     cex = 1,
     cex.main = 0.8,
     col = "darkgrey",
     xlab = "Fitted Values",
     ylab = "Residuals",
     main = "Fitted Vs Residual - Polynomial Degree 2 + 3 Way Interaction Model")
abline (h = 0, col = "darkorange", lwd = 2, lty = 1)

qqnorm(resid(poly2_int_model10_aic), 
       pch = 1,
       cex = 1,
       cex.main = 0.8,
       col = "darkgrey")
qqline(resid(poly2_int_model10_aic),
       lwd = 1,
       col = "red",
       lty = 2)
```

The plot seems much better than the earlier one. The **constant Variance still seems suspect**, as the constant variance is low to high as the fitted values increased from low to how. However the Q-Q plot seems good, hence the **normality is not in suspect**.

Let's do the BP Test and Shapiro Wiki test to confirm

```{r}
bptest(poly2_int_model10_aic)
shapiro.test(resid(poly2_int_model10_aic))
```

As from the plot, the P value of the BP Test is too low, which confirms the **Variance Is Suspect**, where as the P value from the Shapiro Wiki Test is high which is greater than for any alpha value (0.5, 0.1), which confirms the **Normality is not suspect**

# Discussion

#####Dicussion on Why we have Choosen the Model (12)
At the final we have around 16 models which seems to be evalauted. Out of the 16 models, we have selected our best model as the **Model 12** based on the soley fact, it has the lowest **Leave One Out Cross Validation (LOOCV)**. This model comes after the AIC performed on the model Polynomial Regression of Degree - 2 and 3 Way Interaction between the Predictrs

Below is the re-drawn of the RSS, RMSE, RMSE LOOCV, where locate the point number (12) for the model
```{r echo=FALSE}
black = "#2C3E50"
grey = "#ECF0F1"
green = "#009999"
purple = "#990073"
blue = "blue4"

par(mfrow = c(1, 3), oma = c(0, 0, 5, 0))
Final_Model = 1:16
plot(Final_Model, rss_final_model, type = "b",
       ylim = c(min(rss_final_model), max(rss_final_model)), col = purple, lwd = 2,
       xlab = "Final Model", ylab = "Residual Sum Square (RSS)", main = "RSS Vs Final Models")
points(12,rss_final_model[12], col = "red", pch = 1, cex =3 )

plot(Final_Model, rmse_final_model, type = "b",
       ylim = c(min(rmse_final_model), max(rmse_final_model)), col = green, lwd = 2,
       xlab = "Final Model", ylab = "Root Mean Square (RMSE)", main = "RMSE Vs Final Models")
points(12,rmse_final_model[12], col = "red", pch = 1, cex =3 )

plot(Final_Model, rmse_loocv_final_model, type = "b",
       ylim = c(min(rmse_loocv_final_model), max(rmse_loocv_final_model)), col = blue, lwd = 2,
       xlab = "Final Model", ylab = "Root Mean Square (RMSE) LOOCV", main = "RMSE LOOCV Vs Final Models")
points(12,rmse_loocv_final_model[12], col = "red", pch = 1, cex =3 )
```

The RMSE LOOCV is the lowest, the RSS and RMSE is not the lowest one. As we know that RSS and RMSE always decrease as the model complexity increases, hence it will be always low if we go furthe complex model beyond (12). However RMSE LOOCV is great way to validate the model performance, it's a good model which will predict the FEV.


Also below is the replot of the R2 and Adjusted R2, where the circle is marked on the Model (12)
```{r echo=FALSE}
gold = "gold4"
red = "darkred"
orchid = "darkorchid2"

par(mfrow = c(1, 3), oma = c(0, 0, 3, 0))
Interaction_Model = 1:16
plot(Interaction_Model, r2_final_model, type = "b",
       ylim = c(min(r2_final_model), max(r2_final_model)), col = gold, lwd = 2,
       xlab = "Final Model", ylab = "R2", main = "R2 Vs Interaction Model")
points(12,r2_final_model[12], col = "red", pch = 1, cex =3 )


plot(Interaction_Model, adjr2_final_model, type = "b",
       ylim = c(min(adjr2_final_model), max(adjr2_final_model)), col = red, lwd = 2,
       xlab = "Final Model", ylab = "Adjusted R2", main = "Adjusted R2 Vs Final Models")
points(12,adjr2_final_model[12], col = "red", pch = 1, cex =3 )


#plot(Interaction_Model, train_test_error_final_model, type = "b",
#       ylim = c(min(train_test_error_final_model), max(train_test_error_final_model)), col = orchid, lwd = 2,
#       xlab = "Final Model", ylab = "Average Percent Error", main = "Average Percent Error Vs Final Models")
#points(12,train_test_error_final_model[12], col = "red", pch = 1, cex =3 )
```

#####Percent of Error

Let's dicuss what's the percentage of Error Produced by the Model 12. But before that let's create a function which will calculates the percent of error from the below formula

- Calculate the average percent error:
\[
\frac{1}{n}\sum_i\frac{|\text{predicted}_i - \text{actual}_i|}{\text{predicted}_i} \times 100
\]

```{r include=FALSE}
#Split the data into 80% (Train Set), 20% (Test Set)
set.seed(420)
childfev_trn_idx  = sample(nrow(childfev), size = trunc(0.80 * nrow(childfev)))
childfev_trn_data = childfev[childfev_trn_idx, ]
childfev_tst_data = childfev[-childfev_trn_idx, ]

#Function to calculate average percent error
average_percent_error = function(actual, predicted) {
  100 * mean((abs(actual - predicted)) / actual)
}
```


```{r include=FALSE}
train_test_error_final_model = rep(0,15)

#Populate train_test_error_final_model
train_test_error_final_model[1] = average_percent_error(childfev_tst_data$FEV, predict(poly2_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[2] = average_percent_error(childfev_tst_data$FEV, predict(model_all_int_with_age_height, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[3] = average_percent_error(childfev_tst_data$FEV, predict(model_all_2way, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[4] = average_percent_error(childfev_tst_data$FEV, predict(model_all_3way, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[5] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model8, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[6] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model8_aic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[7] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model8_bic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[8] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model9, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[9] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model9_aic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[10] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model9_bic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[11] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model10, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[12] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model10_aic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[13] = average_percent_error(childfev_tst_data$FEV, predict(poly2_int_model10_bic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[14] = average_percent_error(childfev_tst_data$FEV, predict(big_model, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[15] = average_percent_error(childfev_tst_data$FEV, predict(big_model_aic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
train_test_error_final_model[16] = average_percent_error(childfev_tst_data$FEV, predict(big_model_bic, childfev_tst_data[c("Age","Height","Sex","Smoker")]))
```


```{r echo=FALSE}
plot(Interaction_Model, train_test_error_final_model, type = "b",
       ylim = c(min(train_test_error_final_model), max(train_test_error_final_model)), col = orchid, lwd = 2,
       xlab = "Final Model", ylab = "Average Percent Error", main = "Average Percent Error Vs Final 16 Models")
points(12,train_test_error_final_model[12], col = "red", pch = 1, cex =3 )
```

We can see that the Percent of Error for the Model **`Model 12`** is around **`train_test_error_final_model[12]`** which is not bad, though we have done a random sampling with seed. It could be possible for many many sampling, the percentage of error could reduced. However, since the Model 12 is based on the lowest RMSE LOOCV, we will **finalize the model 12 as the final model**


