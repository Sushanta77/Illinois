str(ptitanic)$pclass
table(str(ptitanic)$pclass)
table(ptitanic$pclass)
mtcars
str(mtcars)
mtcars$cyl = as.factor(mtcars$cyl)
str(mtcars)
table(mtcars$cyl)
model = lm(mpg~hp+cyl,data = mtcars)
model
model = glm(survived ~ pclass + sex + age + sex:age, data = ptitanic_trn, family = binomial)
summary(model)
full_model = glm(survived ~ pclass + sex + age + sex:age, data = ptitanic_trn, family = binomial)
summary(full_model)
null_model = glm(survived ~ sex + age + sex:age, data = ptitanic_trn, family = binomial)
summary(null_model)
full_model = glm(survived ~ pclass + sex + age + sex:age, data = ptitanic_trn, family = binomial)
null_model = glm(survived ~ sex + age + sex:age, data = ptitanic_trn, family = binomial)
anova(null_model, full_model, test = "LRT")
anova(null_model, full_model, test = "LRT")['Pr(>Chi)']
anova(null_model, full_model, test = "LRT")[,'Pr(>Chi)']
anova(null_model, full_model, test = "LRT")[,'Pr(>Chi)'][2]
anova(null_model, full_model, test = "LRT")[,'Pr(>Chi)'][2] > 0.01
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
model  = glm(type ~ glu + ped + I(glu ^ 2) + I(ped ^ 2) + glu:ped, data =  Pima_tr, family = binomial)
predict(model, data = Pima_te)
predict(model, data = Pima_te, type = "response")
predict(model, data = Pima_te, type = "response")
predict(model, data = Pima_te, type = "response")
predict(model, data = Pima_te)
predict(model, data = Pima_te)
predict(model, data = Pima_te)
ifelse(predict(model2, Pima_te, type = "response") > 0.8 , "Yes", "No")
ifelse(predict(model2, Pima_te, type = "response") > 0.8 , TRUE, FALSE)
sum(ifelse(predict(model2, Pima_te, type = "response") > 0.8 , TRUE, FALSE))
str(Pima_te)
predict(model, data = Pima_te, type = "response")
predict(model, data = Pima_te, type = "response")
str(Pima_te)
Pima_te["glu"]
Pima_te[c("glu","ped")]
predict(model, data = Pima_te, type = "response")
predict(model, data = Pima_te[c("glu","ped")], type = "response")
all.equal(predict(model, data = Pima_te, type = "response"),predict(model, data = Pima_te[c("glu","ped")], type = "response"))
predict(model, data = Pima_te, type = "response")
mean (predict(model, data = Pima_te, type = "response") > 0.80)
mean (predict(model, data = Pima_te, type = "response") >= 0.80)
mean (predict(model, data = Pima_te, type = "response") > 0.80)
model  = glm(type ~ glu + ped + I(glu ^ 2) + I(ped ^ 2) + glu:ped, data =  Pima_tr, family = binomial)
mean (predict(model, data = Pima_te, type = "response") > 0.80)
predict(model, data = Pima_te, type = "response")
predict(model, data = Pima_te, type = "response") > 0.80
mean(predict(model, data = Pima_te, type = "response") > 0.80)
model  = glm(type ~ glu + ped + I(glu ^ 2) + I(ped ^ 2) + glu:ped, data =  Pima_tr, family = binomial)
anova(model_x1,model_full,test="LRT")
sens_99
spec_99
sens_99 == spec_99
sum(sens_99 == spec_99)
all.equal(sens_99,spec_99)
sens_99
spec_99
library(MASS)
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
model  = glm(type ~ glu + ped + I(glu ^ 2) + I(ped ^ 2) + glu:ped, data =  Pima_tr, family = binomial)
predict_response = predict(model, data = Pima_te, type = "response")
predict_response > 0.80
predict_response[predict_response > 0.80]
mean(predict_response[predict_response > 0.80])
predict_response[predict_response > 0.80]
length(predict_response[predict_response > 0.80])
length(predict_response)
13/200
(13/200)*100
beta_0 = -3
beta_1 = 1
beta_2 = 2
beta_3 = 3
x1 = -1
x2 = 0.5
x3 = 0.25
eta = beta_0 + beta_1 * x1 + beta_2 * x2 + beta_3 * x3
p = 1/(1+exp(-eta))
1 - p
model = glm(am ~ mpg + hp + qsec, data = mtcars, family = binomial)
summary(model)$coefficient[4,1]
summary(model)$coefficient[2,1]
model = glm(am ~ mpg + hp + qsec, data = mtcars, family = binomial)
beta_0 = summary(model)$coefficient[1,1]
beta_1 = summary(model)$coefficient[2,1]
beta_2 = summary(model)$coefficient[3,1]
beta_3 = summary(model)$coefficient[4,1]
newdata = data.frame(mpg = 19,hp = 150, qsec = 19)
beta_0 + beta_1 * 19 + beta_2 * 150 + beta_3 * 19
newdata = data.frame(mpg = 22,hp = 123, qsec = 18)
eta = predict(model, newdata = newdata, type = "response")
eta
null_model = glm(am ~ 1, data = mtcars, family = binomial)
full_model = glm(am ~ mpg + hp + qsec, data = mtcars, family = binomial)
anova(null_model, full_model, test = "LRT")['Deviance'][,1][2]
null_model = glm(am ~ mpg + qsec, data = mtcars, family = binomial)
full_model = glm(am ~ mpg + hp + qsec, data = mtcars, family = binomial)
anova(null_model, full_model, test = "LRT")[2,'Pr(>Chi)']
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
model  = glm(type ~ glu + ped + I(glu ^ 2) + I(ped ^ 2) + glu:ped, data =  Pima_tr, family = binomial)
summary(model)
summary(model)$coefficient[5,1]
predict_response = predict(model, data = Pima_te, type = "response")
mean(predict_response > 0.8)
predict_response = predict(model, data = Pima_te, type = "response")
mean(predict_response > 0.8)*100
library(MASS)
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
model  = glm(type ~ glu + ped + I(glu ^ 2) + I(ped ^ 2) + glu:ped, data =  Pima_tr, family = binomial)
predict_response = predict(model, data = Pima_te, type = "response")
predict_response[predict_response > 0.80]
mean (predict_response[predict_response > 0.80] > 0.80)
library(rpart)
library(rpart.plot)
data("ptitanic")
ptitanic = na.omit(ptitanic)
set.seed(42)
trn_idx = sample(nrow(ptitanic), 300)
ptitanic_trn = ptitanic[trn_idx, ]
ptitanic_tst = ptitanic[-trn_idx, ]
model = glm(survived ~ pclass + sex + age + sex:age, data = ptitanic_trn, family = binomial)
summary(model)
full_model = glm(survived ~ pclass + sex + age + sex:age, data = ptitanic_trn, family = binomial)
null_model = glm(survived ~ pclass + sex + age, data = ptitanic_trn, family = binomial)
anova(null_model, full_model, test = "LRT")
summary(full_model)
anova(null_model, full_model, test = "LRT")
anova(null_model, full_model, test = "LRT")[,'Pr(>Chi) ']
anova(null_model, full_model, test = "LRT")[,"Pr(>Chi)"]
anova(null_model, full_model, test = "LRT")[,"Pr(>Chi)"][2]
summary(full_model)$coefficient
summary(full_model)$coefficient[6,4]
anova(null_model, full_model, test = "LRT")[,"Pr(>Chi)"][2]
summary(full_model)$coefficient[6,4]
summary(null_model)
summary(full_model)
anova(null_model, full_model, test = "LRT")
anova(null_model, full_model, test = "LRT")[,"Pr(>Chi)"]
Pima.te
library(MASS)
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
model  = glm(type ~ glu + ped + I(glu ^ 2) + I(ped ^ 2) + glu:ped, data =  Pima_tr, family = binomial)
predict_response = predict(model, data = Pima_te, type = "response")
predict_response
str(Pima_te)
dim(Pima.te)
predict_response = predict(model, data = Pima_te, type = "response")
predict_response
max(predict_response()
max(predict_response)
min(predict_response)
mean(predict_response > 0.80)
predict_response[predict_response > 0.80]
length(predict_response[predict_response > 0.80]()
length(predict_response[predict_response > 0.80])
length(predict_response)
dim(Pima.te)
dim(predict_response)
predict_response
dim(Pima_te)
predict(model, data = Pima_te, type = "response")
length(predict(model, data = Pima_te, type = "response"))
predict(model, data = Pima_te)
model  = glm(type ~ glu + ped + I(glu ^ 2) + I(ped ^ 2) + glu:ped, data =  Pima_tr, family = binomial)
dim(Pima_tr)
model
head(Pima_te,10)
predict(model, data = Pima_te)
?predict
model2  = glm(type ~ ., data =  Pima_tr, family = binomial)
ifelse(predict(model2,Pima_te) > 0 , "Yes", "No")
predict(model2,Pima_te)
model
model2
predict(model,Pima_te)
predict(model,Pima_te, type = "response")
predict(model,data = Pima_te, type = "response")
predict(model,Pima_te, type = "response")
library(MASS)
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
model  = glm(type ~ glu + ped + I(glu ^ 2) + I(ped ^ 2) + glu:ped, data =  Pima_tr, family = binomial)
predict_response = predict(model,Pima_te, type = "response")
mean(predict_response > 0.8)
mean(predict_response > 0.8)*100
library(MASS)
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
model  = glm(type ~ glu + ped + I(glu ^ 2) + I(ped ^ 2) + glu:ped, data =  Pima_tr, family = binomial)
predict_response = predict(model, data = Pima_te, type = "response")
mean(predict_response > 0.8)
---------------------------------------------------------------------------------------------------------
###Question - 1
beta_0 = -3
beta_1 = 1
beta_2 = 2
beta_3 = 3
x1 = -1
x2 = 0.5
x3 = 0.25
eta = beta_0 + beta_1 * x1 + beta_2 * x2 + beta_3 * x3
p = 1/(1+exp(-eta))
1 - p
1 - p
2.376e-11
beta_0 = -3
beta_1 = 1
beta_2 = 2
beta_3 = 3
x1 = -1
x2 = 0.5
x3 = 0.25
eta = beta_0 + beta_1 * x1 + beta_2 * x2 + beta_3 * x3
p = 1/(1+exp(-eta))
1 - p
###Question - 2
model = glm(am ~ mpg + hp + qsec, data = mtcars, family = binomial)
summary(model)$coefficient[4,1]
summary(model)$coefficient[2,1]
model = glm(am ~ mpg + hp + qsec, data = mtcars, family = binomial)
beta_0 = summary(model)$coefficient[1,1]
beta_1 = summary(model)$coefficient[2,1]
beta_2 = summary(model)$coefficient[3,1]
beta_3 = summary(model)$coefficient[4,1]
newdata = data.frame(mpg = 19,hp = 150, qsec = 19)
beta_0 + beta_1 * 19 + beta_2 * 150 + beta_3 * 19
newdata = data.frame(mpg = 22,hp = 123, qsec = 18)
eta = predict(model, newdata = newdata, type = "response")
eta
eta = beta_0 + beta_1 * 22 + beta_2 * 123 + beta_3 * 18
p = 1/(1+exp(-eta))
p
null_model = glm(am ~ 1, data = mtcars, family = binomial)
full_model = glm(am ~ mpg + hp + qsec, data = mtcars, family = binomial)
anova(null_model, full_model, test = "LRT")['Deviance'][,1][2]
null_model = glm(am ~ mpg + qsec, data = mtcars, family = binomial)
full_model = glm(am ~ mpg + hp + qsec, data = mtcars, family = binomial)
anova(null_model, full_model, test = "LRT")[2,'Pr(>Chi)']
library(MASS)
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
model  = glm(type ~ glu + ped + I(glu ^ 2) + I(ped ^ 2) + glu:ped, data =  Pima_tr, family = binomial)
predict_response = predict(model, Pima_te, type = "response")
mean(predict_response > 0.8)
?predict
?glm
model  = glm(type ~ glu + ped + I(glu ^ 2) + I(ped ^ 2) + glu:ped, data =  Pima_tr, family = binomial)
summary(model)
?predict
model_age_sex_int = glm(survived ~ age:sex, data = ptitanic_trn, family = binomial)
ptitanic = na.omit(ptitanic)
set.seed(42)
trn_idx = sample(nrow(ptitanic), 300)
ptitanic_trn = ptitanic[trn_idx, ]
ptitanic_tst = ptitanic[-trn_idx, ]
library(rpart)
library(rpart.plot)
data("ptitanic")
ptitanic = na.omit(ptitanic)
set.seed(42)
trn_idx = sample(nrow(ptitanic), 300)
ptitanic_trn = ptitanic[trn_idx, ]
ptitanic_tst = ptitanic[-trn_idx, ]
summary(model)$deviance
model_age_sex_int = glm(survived ~ age:sex, data = ptitanic_trn, family = binomial)
summary(model_age_sex_int)
summary(model_age_sex_int)
full_model = glm(survived ~ pclass + sex + age + sex:age, data = ptitanic_trn, family = binomial)
anova(model_age_sex_int, model, test = "LRT")
full_model = glm(survived ~ pclass + sex + age + sex:age, data = ptitanic_trn, family = binomial)
null_model = glm(survived ~ sex + age + sex:age, data = ptitanic_trn, family = binomial)
anova(null_model, full_model, test = "LRT")
options(scipen = 1, digits = 4, width = 80, fig.align = "center")
anova(null_model, full_model, test = "LRT")
full_model = glm(survived ~ pclass + sex + age + sex:age, data = ptitanic_trn, family = binomial)
null_model = glm(survived ~ sex + age + sex:age, data = ptitanic_trn, family = binomial)
anova(null_model, full_model, test = "LRT")
summary(full_model)
null_model = glm(survived ~ pclass + sex + age , data = ptitanic_trn, family = binomial)
anova(null_model, full_model, test = "LRT")
full_model = glm(survived ~ pclass + sex + age + sex:age, data = ptitanic_trn, family = binomial)
summary(full_model)
null_model = glm(survived ~ pclass + sex + sex:age, data = ptitanic_trn, family = binomial)
anova(null_model, full_model, test = "LRT")
?rbinom
str(mtcars)
full_model = lm(mpg ~ hp + disp, data = mtcars)
null_model = lm(mpg ~ hp, data = mtcars)
anova(full_model, null_model)
summary(full_model)
str(mtcars)
mtcars$am = as.factor(mtcars$am)
str(mtcars)
full_model = lm(mpg~hp + am, data = mtcars)
summary(full_model)
null_model = lm(mpg~hp, data = mtcars)
anova(full_model, null_model)
full_model = lm(mpg~hp + am + hp : am, data = mtcars)
summary(full_model)
null_model = lm(mpg~hp + am , data = mtcars)
summary(full_model)
anova(full_model, null_model)
summary(full_model)
summary(null_model)
anova(full_model, null_model)
summary(full_model)$coefficient[4,4]
anova(full_model, null_model)[,"Pr(>F)"]
anova(full_model, null_model)[,"Pr(>F)"][2]
library(rpart)
library(rpart.plot)
data("ptitanic")
ptitanic = na.omit(ptitanic)
set.seed(42)
trn_idx = sample(nrow(ptitanic), 300)
ptitanic_trn = ptitanic[trn_idx, ]
ptitanic_tst = ptitanic[-trn_idx, ]
model = glm(survived ~ pclass + sex + age + sex:age, data = ptitanic_trn, family = binomial)
summary(model)
full_model = glm(survived ~ pclass + sex + age + sex:age, data = ptitanic_trn, family = binomial)
null_model = glm(survived ~ pclass + sex + age , data = ptitanic_trn, family = binomial)
summary(full_model)
summary(null_model)
full_model = glm(survived ~ sex + age + sex:age, data = ptitanic_trn, family = binomial)
null_model = glm(survived ~ sex + age , data = ptitanic_trn, family = binomial)
cls
summary(full_model)
summary(null_model)
anova(full_model, null_model , test = "LRT")
library(MASS)
get_sens = function(conf_mat){
conf_mat[2, 2] / sum(conf_mat[, 2])
}
make_conf_mat = function(predicted, actual){
table(predicted = predicted, actual = actual)
}
# Train, Test Data
Pima_tr = MASS::Pima.tr
Pima_te = MASS::Pima.te
model2  = glm(type ~ ., data =  Pima_tr, family = binomial)
pred = ifelse(predict(model, Pima.te)>0, 'Yes', 'No')
pred = ifelse(predict(model2, Pima.te)>0, 'Yes', 'No')
pred
conf_mat = make_conf_mat(pred, Pima.te$type)
get_sens = function(conf_mat) { conf_mat[2, 2] / sum(conf_mat[, 2]) }
get_sens(conf_mat)
pred = ifelse(predict(model, Pima.te[Pima.te$type == 'Yes',])>0, 'Yes', 'No')
pred = ifelse(predict(model2, Pima.te[Pima.te$type == 'Yes',])>0, 'Yes', 'No')
sum(pred == 'Yes')/sum(Pima.te$type == 'Yes')
y
eta
options(scipen = 1, digits = 4, width = 80, fig.align = "center")
beta_0 = 0.4
beta_1 = -0.35
beta_2_z_val = rep(0,2500)
liklihood_test = rep(0,2500)
for(i in (1:2500)){
eta = beta_0 + beta_1 * x1 #simulate from this model
p = ( 1/(1+exp(-eta)) )
y = rbinom(n = sample_size, size = 1, p)
model_full = glm(y ~ x1 + x2 + x3, family = binomial)
beta_2_z_val[i] = summary(model_full)$coefficient[3,3]
model_x1 = glm(y ~ x1, family = binomial)
liklihood_test[i] = anova(model_x1,model_full,test="LRT")[2,4]
}
setwd("~/Documents/GitHub/Illinois/STAT 420 -  Statistical Modeling in R/HW10/w10-hw")
wisc_train = read.csv("wisc-train.csv")
wisc_test = read.csv("wisc-test.csv")
model1 = glm(class ~ radius + smoothness + texture, data = wisc_train, family = binomial)
model1
sens_99 = seq(1,length(cutoffs))
spec_99 = seq(1,length(cutoffs))
for(i in (1:length(cutoffs))){
test_predict = ifelse(predict(model_add, wisc_test, type = "response") > cutoffs[i] , "M", "B")
conf_mat_predict = make_conf_mat(predicted = test_predict, actual = wisc_test$class)
sens_99[i] = get_sens(conf_mat_predict)
spec_99[i] = get_spec(conf_mat_predict)
}
model_add = glm(class ~ ., data = wisc_train, family = binomial)
sens_99 = seq(1,length(cutoffs))
spec_99 = seq(1,length(cutoffs))
for(i in (1:length(cutoffs))){
test_predict = ifelse(predict(model_add, wisc_test, type = "response") > cutoffs[i] , "M", "B")
conf_mat_predict = make_conf_mat(predicted = test_predict, actual = wisc_test$class)
sens_99[i] = get_sens(conf_mat_predict)
spec_99[i] = get_spec(conf_mat_predict)
}
#Confustion matrix creation
make_conf_mat = function(predicted, actual){
table(predicted = predicted, actual = actual)
}
#Sensitivity Function
get_sens = function(conf_mat){
conf_mat[2, 2] / sum(conf_mat[, 2])
}
#Specificity Function
get_spec = function(conf_mat){
conf_mat[1, 1] / sum(conf_mat[, 1])
}
cutoffs = seq(0.01, 0.99, by = 0.01)
sens_99 = seq(1,length(cutoffs))
spec_99 = seq(1,length(cutoffs))
for(i in (1:length(cutoffs))){
test_predict = ifelse(predict(model_add, wisc_test, type = "response") > cutoffs[i] , "M", "B")
conf_mat_predict = make_conf_mat(predicted = test_predict, actual = wisc_test$class)
sens_99[i] = get_sens(conf_mat_predict)
spec_99[i] = get_spec(conf_mat_predict)
}
plot(sens_99~cutoffs,type = "l",col = "darkorange", lwd = 2, lty = 1, ylim = c(0.5,1), xlab = "Threshold - Cutoffs", ylab = "Sensitivity / Specificity")
lines(spec_99~cutoffs,type = "l",col = "dodgerblue", lwd = 2, lty = 1)
legend("topright", legend = c("Sensitivity", "Specificity"), col=c("darkorange","dodgerblue"),lty = c(1,1))
plot(cutoffs, sens_99, type = "l", ylim = c(0.5, 1), col = "dodgerblue",
xlab = "Cutoff", ylab = "Metric", main = "Sensitivity and Specificity vs Cutoff")
grid()
lines(cutoffs, spec_99, type = "l", col = "darkorange", lty = 2)
legend("bottomright", col = c("dodgerblue", "darkorange"), lty = c(1, 2),
legend = c("Sensitivity", "Specificity"))
plot(sens_99~cutoffs,type = "l",col = "darkorange", lwd = 1, lty = 1, ylim = c(0.5,1), xlab = "Threshold - Cutoffs", ylab = "Sensitivity / Specificity")
lines(spec_99~cutoffs,type = "l",col = "dodgerblue", lwd = 1, lty = 2)
legend("topright", legend = c("Sensitivity", "Specificity"), col=c("darkorange","dodgerblue"),lty = c(1,1))
plot(sens_99~cutoffs,type = "l",col = "darkorange", lwd = 1, lty = 1, ylim = c(0.5,1), xlab = "Threshold - Cutoffs", ylab = "Sensitivity / Specificity")
lines(spec_99~cutoffs,type = "l",col = "dodgerblue", lwd = 1, lty = 2)
legend("bottomright", legend = c("Sensitivity", "Specificity"), col=c("darkorange","dodgerblue"),lty = c(1,1))
# obtain predicted probabilities in the test set
wisc_probs = predict(additive, wisc_test, type = "response")
# make classifications for different probability cutoffs
make_class = function(probs, cutoff = 0.5) {
ifelse(probs > cutoff, "M", "B")
}
# calculate specificity
calc_spec = function(predicted, actual) {
tab = table(predicted, actual)
tab[1, 1] / sum(tab[, 1])
}
# calculate sensitivity
calc_sens = function(predicted, actual) {
tab = table(predicted, actual)
tab[2, 2] / sum(tab[, 2])
}
# setup
cutoffs = seq(0.01, 0.99, by = 0.01)
sens = rep(0, length(cutoffs))
spec = rep(0, length(cutoffs))
# calculations
for (i in seq_along(cutoffs)) {
classifications = make_class(probs = wisc_probs, cutoff = cutoffs[i])
truth = wisc_test$class
sens[i] = calc_sens(classifications, truth)
spec[i] = calc_spec(classifications, truth)
}
# obtain predicted probabilities in the test set
wisc_probs = predict(additive, wisc_test, type = "response"
wisc_probs = predict(additive, wisc_test, type = "response")
additive = glm(class ~ ., data = wisc_train, family = "binomial")
cutoffs = seq(0.01, 0.99, by = 0.01)
# obtain predicted probabilities in the test set
wisc_probs = predict(additive, wisc_test, type = "response")
# make classifications for different probability cutoffs
make_class = function(probs, cutoff = 0.5) {
ifelse(probs > cutoff, "M", "B")
}
# calculate specificity
calc_spec = function(predicted, actual) {
tab = table(predicted, actual)
tab[1, 1] / sum(tab[, 1])
}
# calculate sensitivity
calc_sens = function(predicted, actual) {
tab = table(predicted, actual)
tab[2, 2] / sum(tab[, 2])
}
# setup
cutoffs = seq(0.01, 0.99, by = 0.01)
sens = rep(0, length(cutoffs))
spec = rep(0, length(cutoffs))
# calculations
for (i in seq_along(cutoffs)) {
classifications = make_class(probs = wisc_probs, cutoff = cutoffs[i])
truth = wisc_test$class
sens[i] = calc_sens(classifications, truth)
spec[i] = calc_spec(classifications, truth)
}
# plotting
plot(cutoffs, sens, type = "l", ylim = c(0.5, 1), col = "dodgerblue",
xlab = "Cutoff", ylab = "Metric", main = "Sensitivity and Specificity vs Cutoff")
grid()
lines(cutoffs, spec, type = "l", col = "darkorange", lty = 2)
legend("bottomright", col = c("dodgerblue", "darkorange"), lty = c(1, 2),
legend = c("Sensitivity", "Specificity"))
