---
title: "panda5-sim-proj"
author: "Sushanta Panda"
date: "6/21/2019"
output: 
  html_document: 
    toc: yes
editor_options: 
  chunk_output_type: console
---
## Simulation Study 1: Significance of Regression

Below is the simulation for the **Significance Model**
```{r}
birthday = 19770411
set.seed(birthday)
n = 25
sigma = c(1,5,10)
no_loop = 2500
mlr_sim = function(n_in,sd=1,signifincance_ind=1){
  exer_data = read.csv("study_1.csv")
  
  epsilon = rnorm(n_in,mean = 0,sd = sd)
  if (signifincance_ind){
    beta_0 = 3
    beta_1 = 1
    beta_2 = 1
    beta_3 = 1 
    exer_data[,1] = beta_0 + beta_1 * exer_data[,2] + beta_2 * exer_data[,3] + beta_3 * exer_data[,4] + epsilon
  }
  else {
    beta_0 = 3
    beta_1 = 0
    beta_2 = 0
    beta_3 = 0 
    exer_data[,1] = beta_0 + beta_1 * exer_data[,2] + beta_2 * exer_data[,3] + beta_3 * exer_data[,4] + epsilon
  }
  exer_data
}
```

###Below is the simulation for 2500 simulations (Significance Model)
```{r}
birthday = 19770411
set.seed(birthday)
#---------------------------------------------------------------------------------------------------------------
# Below code is to simulate the Significance Model 
#---------------------------------------------------------------------------------------------------------------
model_significance = cbind(sigma_1_F=rep(0,no_loop),sigma_1_P=rep(0,no_loop),sigma_1_R_SQUARED=rep(0,no_loop),
                           sigma_5_F=rep(0,no_loop),sigma_5_P=rep(0,no_loop),sigma_5_R_SQUARED=rep(0,no_loop),
                           sigma_10_F=rep(0,no_loop),sigma_10_P=rep(0,no_loop),sigma_10_R_SQUARED=rep(0,no_loop))
extra_counter = 0

for(s in 1:length(sigma)){
  #print(paste("Sigma:",sigma[s]," extra_counter",extra_counter))
  for (i in 1:no_loop){
     mlr_data = mlr_sim(n,sigma[s],signifincance_ind = 1)
     null_model = lm(y~1,data = mlr_data)
     full_model = lm(y~x1+x2+x3,data = mlr_data)
     model_significance[i,s+extra_counter] = anova(null_model,full_model)$F[2]
     model_significance[i,s+extra_counter+1] = anova(null_model,full_model)$'Pr(>F)'[2]
     model_significance[i,s+extra_counter+2] = summary(full_model)$r.squared
  }
  extra_counter = extra_counter + 2
}

#---------------------------------------------------------------------------------------------------------------
# Below code is to simulate the Non Significance Model 
#---------------------------------------------------------------------------------------------------------------
model_nonsignificance = cbind(sigma_1_F=rep(0,no_loop),sigma_1_P=rep(0,no_loop),sigma_1_R_SQUARED=rep(0,no_loop),
                           sigma_5_F=rep(0,no_loop),sigma_5_P=rep(0,no_loop),sigma_5_R_SQUARED=rep(0,no_loop),
                           sigma_10_F=rep(0,no_loop),sigma_10_P=rep(0,no_loop),sigma_10_R_SQUARED=rep(0,no_loop))
extra_counter = 0
for(s in 1:length(sigma)){
  print(paste("Sigma:",sigma[s]," extra_counter",extra_counter))
  for (i in 1:no_loop){
     mlr_data = mlr_sim(n,sigma[s],signifincance_ind = 0)
     null_model = lm(y~1,data = mlr_data)
     full_model = lm(y~x1+x2+x3,data = mlr_data)
     model_nonsignificance[i,s+extra_counter] = anova(null_model,full_model)$F[2]
     model_nonsignificance[i,s+extra_counter+1] = anova(null_model,full_model)$'Pr(>F)'[2]
     model_nonsignificance[i,s+extra_counter+2] = summary(full_model)$r.squared
  }
  extra_counter = extra_counter + 2
}

```

###Below is the Empirical distibution for 2500 simulations (Sigma = 1)
```{r}
par(mfrow=c(2, 2))

hist(model_significance[,1],
     main = "Empirical Distribution of F [Significance]",
     xlab = "Simulated values of F",
     col = "darkolivegreen",
     border = "white"
     )

hist(model_nonsignificance[,1],
     main = "Empirical Distribution of F [Non Significance]",
     xlab = "Simulated values of F",
     col = "plum4",
     border = "white",
     probability = TRUE
     )

hist(model_significance[,2],
     main = "Empirical Distribution of P [Significance]",
     xlab = "Simulated values of P",
     col = "sienna2",
     border = "white"
     )

hist(model_nonsignificance[,2],
     main = "Empirical Distribution of P [Non Significance]",
     xlab = "Simulated values of P",
     col = "slateblue1",
     border = "white"
     )

hist(model_significance[,3],
     main = "Empirical Distribution of R Squared [Significance]",
     xlab = "Simulated values of R Squared",
     col = "yellow",
     border = "white"
     )

hist(model_nonsignificance[,3],
     main = "Empirical Distribution of R Squared [Non Significance]",
     xlab = "Simulated values of R Squared",
     col = "tan",
     border = "white"
     )

```

###Below is the Empirical distibution for 2500 simulations (Sigma = 5)
```{r}
par(mfrow=c(2, 2))

hist(model_significance[,4],
     main = "Empirical Distribution of F [Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of F",
     col = "darkolivegreen",
     border = "white"
     )

hist(model_nonsignificance[,4],
     main = "Empirical Distribution of F [Non Significance]",
     cex.main = 1,
     xlab = "Simulated values of F",
     col = "plum4",
     border = "white"
     )

hist(model_significance[,5],
     main = "Empirical Distribution of P [Significance]",
     cex.main = 1,
     xlab = "Simulated values of P",
     col = "sienna2",
     border = "white"
     )

hist(model_nonsignificance[,5],
     main = "Empirical Distribution of P [Non Significance]",
     cex.main = 1,
     xlab = "Simulated values of P",
     col = "slateblue1",
     border = "white"
     )

hist(model_significance[,6],
     main = "Empirical Distribution of R Squared [Significance]",
     cex.main = 1,
     xlab = "Simulated values of R Squared",
     col = "yellow",
     border = "white"
     )

hist(model_nonsignificance[,6],
     main = "Empirical Distribution of R Squared [Non Significance]",
     xlab = "Simulated values of R Squared",
     col = "tan",
     border = "white"
     )
```

###Below is the Empirical distibution for 2500 simulations (Sigma = 10)
```{r}
par(mfrow=c(2, 2))

hist(model_significance[,7],
     main = "Empirical Distribution of F (Sigma = 10) [Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of F",
     col = "darkolivegreen",
     border = "white"
     )


hist(model_nonsignificance[,7],
     main = "Empirical Distribution of F (Sigma = 10) [Non Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of F",
     col = "darkolivegreen",
     border = "white"
     )

hist(model_significance[,8],
     main = "Empirical Distribution of P (Sigma = 10) [Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of P",
     col = "darkgreen",
     border = "white"
     )

hist(model_nonsignificance[,8],
     main = "Empirical Distribution of P (Sigma = 10) [Non Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of P",
     col = "darkgreen",
     border = "white"
     )

hist(model_significance[,9],
     main = "Empirical Distribution of R Squared (Sigma = 10) [Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of R Squared",
     col = "darkcyan",
     border = "white"
     )

hist(model_nonsignificance[,9],
     main = "Empirical Distribution of R Squared (Sigma = 10) [Non Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of R Squared",
     col = "darkcyan",
     border = "white"
     )

```

##True Distribution 
The true distribution will be only available for the **Non Significance Model**

###True Distribution of F Statistics
```{r}
curve(df(x, df1=3, df2=21),
      xlab = "Probability",
      ylab = "Frequency",
      lwd=3,
      col = "darkgreen")
```
The True distribution of the F Tests shows as a right skewed distribution, where in the initial values is inflated

###True Distribution of P value
```{r}
par(mfrow=c(2, 2))
curve(pnorm(rnorm(x,mean = 3, sd = 1),mean=3,sd=1),
      main = "True Distribution of P Value, Sigma = 1",
      cex.main = 1,
      xlab = "Probability",
      ylab = "Frequency",
      lwd = 3,
      col = "orange")

curve(pnorm(rnorm(x,mean = 3, sd = 5),mean = 3,sd = 5),
      main = "True Distribution of P Value, Sigma = 5",
      cex.main = 1,
      xlab = "Probability",
      ylab = "Frequency",
      lwd = 3,
      col = "orange")

curve(pnorm(rnorm(x,mean = 3, sd = 5),mean = 3,sd = 10),
      main = "True Distribution of P Value, Sigma = 10",
      cex.main = 1,
      xlab = "Probability",
      ylab = "Frequency",
      lwd = 3,
      col = "orange")
```
The True distribution of the P seems to have an uniform distribution for 

###True Distribution of R Squared Value
```{r}
curve(dbeta(x, (4-1)/2, (25-4)/2),
      xlab = "Probability",
      ylab = "Frequency",
      lwd = 3,
      col = "palevioletred4")
```
The True distribution of R Squared is a beta distribution, right skewed distribution, where the shape 1 and shape 2 parameter is of value (k-1)/2 and (n-k)/2, where k = number of esimator in the True model(which is 4,i.e $\beta_{0} \beta_{1} \beta_{2} \beta_{3}) and n = number of elements in the data (which is 25)

##How do the empirical distributions from the simulations compare to the true distributions?
### Empirical distributions of F Test related to the True Distibution of F Test
```{r}

par(mfrow=c(2, 2))

hist(model_nonsignificance[,1],
     main = "Empirical Distribution of F (Sigma = 1) [Non Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of F",
     col = "darkolivegreen1",
     border = "white",
     probability = TRUE
     )
curve(df(x, df1=3, df2=21),
      lwd=3,
      col = "darkgreen",
      add = TRUE)

hist(model_nonsignificance[,4],
     main = "Empirical Distribution of F (Sigma = 5) [Non Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of F",
     col = "darkolivegreen1",
     border = "white",
     probability = TRUE
     )
curve(df(x, df1=3, df2=21),
      lwd=3,
      col = "darkgreen",
      add = TRUE)

hist(model_nonsignificance[,7],
     main = "Empirical Distribution of F (Sigma = 10) [Non Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of F",
     col = "darkolivegreen1",
     border = "white",
     probability = TRUE
     )
curve(df(x, df1=3, df2=21),
      lwd=3,
      col = "darkgreen",
      add = TRUE)
```

It seems the True distribution of the F test statistics is **matching** with the empirical distribution of the of the F Test for all the three (3) sigma values (1,5 and 10). The dark green color shows the true distribution of the F test statistics, where as the histogram in light green color is the empirical distribution of the F test statistics obtained from the simulated values.

  
### Empirical distributions of P value related to the True Distibution of P (Non Siginificance)
```{r}
par(mfrow=c(2, 2))

hist(model_nonsignificance[,2],
     main = "Empirical Distribution of P (Sigma = 1) [Non Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of P",
     col = "deepskyblue1",
     border = "white",
     probability = TRUE
     )
curve(pnorm(rnorm(x,mean = 3, sd = 1),mean=3,sd=1),
      main = "True Distribution of P Value - Sigma = 1",
      cex.main = 1,
      xlab = "Probability",
      ylab = "Frequency",
      lwd = 3,
      col = "darkblue",
      add = TRUE)

hist(model_nonsignificance[,5],
     main = "Empirical Distribution of P (Sigma = 5) [Non Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of P",
     col = "deepskyblue1",
     border = "white",
     probability = TRUE
     )
curve(pnorm(rnorm(x,mean = 3, sd = 1),mean=3,sd=1),
      main = "True Distribution of P Value - Sigma = 1",   
      cex.main = 1,
      xlab = "Probability",
      ylab = "Frequency",
      lwd = 3,
      col = "darkblue",
      add = TRUE)

hist(model_nonsignificance[,8],
     main = "Empirical Distribution of P (Sigma = 10) [Non Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of P",
     col = "deepskyblue1",
     border = "white",
     probability = TRUE
     )
curve(pnorm(rnorm(x,mean = 3, sd = 1),mean=3,sd=1),
      main = "True Distribution of P Value - Sigma = 1",
      cex.main = 1,
      xlab = "Probability",
      ylab = "Frequency",
      lwd = 3,
      col = "darkblue",
      add = TRUE)

```
From the above plots the empirical distrubution of the P values for the three (3) sigma values (1,5 and 10) are **matching** with the true distribution of the P values, which is uniform distribution.

### Empirical distributions of R squared related to the True Distibution of R Squared (Non Siginificance Model)
```{r}
par(mfrow=c(2, 2))

hist(model_nonsignificance[,3],
     main = "Empirical Distribution of R Squared (Sigma = 1) [Non Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of R Squared",
     col = "palevioletred1",
     border = "white",
     probability = TRUE
     )
curve(dbeta(x, (4-1)/2, (25-4)/2),
      lwd = 3,
      col = "palevioletred4",
      add = TRUE)

hist(model_nonsignificance[,6],
     main = "Empirical Distribution of R Squared (Sigma = 5) [Non Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of R Squared",
     col = "palevioletred1",
     border = "white",
     probability = TRUE
     )
curve(dbeta(x, (4-1)/2, (25-4)/2),
      lwd = 3,
      col = "palevioletred4",
      add = TRUE)

hist(model_nonsignificance[,9],
     main = "Empirical Distribution of R Squared (Sigma = 10) [Non Significance Model]",
     cex.main = 1,
     xlab = "Simulated values of R Squared",
     col = "palevioletred1",
     border = "white",
     probability = TRUE
     )
curve(dbeta(x, (4-1)/2, (25-4)/2),
      lwd = 3,
      col = "palevioletred4",
      add = TRUE)
```
The empirical distribution is **matching** with the True distribution of the R Squared which is the **right skewed**, which follows **beta distribution**

##How are R2 and sigma are related
```{r}
plot(model_significance[,3],col="dodgerblue",ylim=c(0,1),lty=1,xlab="R Squared Simulation Index",ylab="R Squared Value",main = "R Squared ~ Sigma")
points(model_significance[,6],col="green",lty=2)
points(model_significance[,9],col="red",lty=3)
legend("topright",legend=c("sigma=1","sigma=5","sigma=10"),col=c("dodgerblue","green","red"),lty=c(1,2,3))
```

**Description of how R2 and sigma
From the above plot, it seems **R square and sigma are related**. **Higher the value of the sigma, lower the value of the R squared**. It seems prominent in case of sigma =1 (blue circles) for which the R squared value is bit higher as compared to the Sigma = 5 (green circles) and Sigma = 10 (red circles). Red circles (Sigma = 10) have in the bottom with lowest R Squared value, where as green circles (Sigma = 5) have higher R squared values. Though there are few green circles (Sigma = 5) have lower R Squared same as of red circles (Sigma = 10) 


## Simulation Study 2: Significance of Regression
```{r}
birthday = 19770411
set.seed(birthday)

beta_0 = 0
beta_1 = 5
beta_2 = -4
beta_3 = 1.6
beta_4 = -1.1
beta_5 = 0.7
beta_6 = 0.3
n = 500
no_loop = 1000
sigma = c(1,2,4)
sig_data = read.csv("study_2.csv")


mlr_sim = function(data,sd=1){
  epsilon = rnorm(n,mean = 0,sd = sd)
  data[,1] = beta_0 + beta_1 * data[,2] + beta_2 * data[,3] + beta_3 * data[,4] + beta_4 * data[,5] + beta_5 * data[,6] + beta_6 * data[,7] + epsilon
  data
}

train_rmse_model1_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
train_rmse_model2_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
train_rmse_model3_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
train_rmse_model4_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
train_rmse_model5_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
train_rmse_model6_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
train_rmse_model7_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
train_rmse_model8_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
train_rmse_model9_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))

test_rmse_model1_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
test_rmse_model2_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
test_rmse_model3_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
test_rmse_model4_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
test_rmse_model5_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
test_rmse_model6_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
test_rmse_model7_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
test_rmse_model8_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
test_rmse_model9_mat = cbind(sigma_1=rep(0,no_loop),sigma_2=rep(0,no_loop),sigma_4=rep(0,no_loop))
train_rmse_mat = cbind(sigma_1=rep(0,9),sigma_2=rep(0,9),sigma_4=rep(0,9))
test_rmse_mat = cbind(sigma_1=rep(0,9),sigma_2=rep(0,9),sigma_4=rep(0,9))

model1_counter_all_sigma = 0 
model2_counter_all_sigma = 0 
model3_counter_all_sigma = 0 
model4_counter_all_sigma = 0 
model5_counter_all_sigma = 0 
model6_counter_all_sigma = 0 
model7_counter_all_sigma = 0 
model8_counter_all_sigma = 0 
model9_counter_all_sigma = 0 
  
for(s in 1:length(sigma)){
  for(i in 1:no_loop){
    #epsilon = rnorm(n,mean = 0, sd = sigma[s])
    mlr_data=mlr_sim(sig_data,sd=sigma[s])
    
    trn_idx = sample(1:nrow(mlr_data), 250)
    n_test = nrow(mlr_data) - length(trn_idx)
    
    model1 = lm(y~x1,data=mlr_data[trn_idx,])
    model2 = lm(y~x1+x2,data=mlr_data[trn_idx,])
    model3 = lm(y~x1+x2+x3,data=mlr_data[trn_idx,])
    model4 = lm(y~x1+x2+x3+x4,data=mlr_data[trn_idx,])
    model5 = lm(y~x1+x2+x3+x4+x5,data=mlr_data[trn_idx,])
    model6 = lm(y~x1+x2+x3+x4+x5+x6,data=mlr_data[trn_idx,])
    model7 = lm(y~x1+x2+x3+x4+x5+x6+x7,data=mlr_data[trn_idx,])
    model8 = lm(y~x1+x2+x3+x4+x5+x6+x7+x8,data=mlr_data[trn_idx,])
    model9 = lm(y~x1+x2+x3+x4+x5+x6+x7+x8+x9,data=mlr_data[trn_idx,])
    

    
    newdata_model1 = subset(mlr_data[-trn_idx,],select=c("x1"))
    newdata_model2 = subset(mlr_data[-trn_idx,],select=c("x1","x2"))
    newdata_model3 = subset(mlr_data[-trn_idx,],select=c("x1","x2","x3"))
    newdata_model4 = subset(mlr_data[-trn_idx,],select=c("x1","x2","x3","x4"))
    newdata_model5 = subset(mlr_data[-trn_idx,],select=c("x1","x2","x3","x4","x5"))
    newdata_model6 = subset(mlr_data[-trn_idx,],select=c("x1","x2","x3","x4","x5","x6"))
    newdata_model7 = subset(mlr_data[-trn_idx,],select=c("x1","x2","x3","x4","x5","x6","x7"))
    newdata_model8 = subset(mlr_data[-trn_idx,],select=c("x1","x2","x3","x4","x5","x6","x7","x8"))
    newdata_model9 = subset(mlr_data[-trn_idx,],select=c("x1","x2","x3","x4","x5","x6","x7","x8","x9"))    
    
    train_rmse_model1 = sqrt(sum((mlr_data[trn_idx,]$y - predict(model1))^2) / length(trn_idx))
    train_rmse_model2 = sqrt(sum((mlr_data[trn_idx,]$y - predict(model2))^2) / length(trn_idx))
    train_rmse_model3 = sqrt(sum((mlr_data[trn_idx,]$y - predict(model3))^2) / length(trn_idx))
    train_rmse_model4 = sqrt(sum((mlr_data[trn_idx,]$y - predict(model4))^2) / length(trn_idx))
    train_rmse_model5 = sqrt(sum((mlr_data[trn_idx,]$y - predict(model5))^2) / length(trn_idx))
    train_rmse_model6 = sqrt(sum((mlr_data[trn_idx,]$y - predict(model6))^2) / length(trn_idx))
    train_rmse_model7 = sqrt(sum((mlr_data[trn_idx,]$y - predict(model7))^2) / length(trn_idx))
    train_rmse_model8 = sqrt(sum((mlr_data[trn_idx,]$y - predict(model8))^2) / length(trn_idx))
    train_rmse_model9 = sqrt(sum((mlr_data[trn_idx,]$y - predict(model9))^2) / length(trn_idx))
    train_rmse_model1_mat[i,s] = train_rmse_model1
    train_rmse_model2_mat[i,s] = train_rmse_model2
    train_rmse_model3_mat[i,s] = train_rmse_model3
    train_rmse_model4_mat[i,s] = train_rmse_model4
    train_rmse_model5_mat[i,s] = train_rmse_model5
    train_rmse_model6_mat[i,s] = train_rmse_model6
    train_rmse_model7_mat[i,s] = train_rmse_model7
    train_rmse_model8_mat[i,s] = train_rmse_model8
    train_rmse_model9_mat[i,s] = train_rmse_model9    
    
    test_rmse_model1 = sqrt(sum((mlr_data[-trn_idx,]$y - predict(model1,newdata=newdata_model1))^2) / n_test)
    test_rmse_model2 = sqrt(sum((mlr_data[-trn_idx,]$y - predict(model2,newdata=newdata_model2))^2) / n_test)
    test_rmse_model3 = sqrt(sum((mlr_data[-trn_idx,]$y - predict(model3,newdata=newdata_model3))^2) / n_test)
    test_rmse_model4 = sqrt(sum((mlr_data[-trn_idx,]$y - predict(model4,newdata=newdata_model4))^2) / n_test)
    test_rmse_model5 = sqrt(sum((mlr_data[-trn_idx,]$y - predict(model5,newdata=newdata_model5))^2) / n_test)
    test_rmse_model6 = sqrt(sum((mlr_data[-trn_idx,]$y - predict(model6,newdata=newdata_model6))^2) / n_test)
    test_rmse_model7 = sqrt(sum((mlr_data[-trn_idx,]$y - predict(model7,newdata=newdata_model7))^2) / n_test)
    test_rmse_model8 = sqrt(sum((mlr_data[-trn_idx,]$y - predict(model8,newdata=newdata_model8))^2) / n_test)
    test_rmse_model9 = sqrt(sum((mlr_data[-trn_idx,]$y - predict(model9,newdata=newdata_model9))^2) / n_test)
    test_rmse_model1_mat[i,s] = test_rmse_model1
    test_rmse_model2_mat[i,s] = test_rmse_model2
    test_rmse_model3_mat[i,s] = test_rmse_model3
    test_rmse_model4_mat[i,s] = test_rmse_model4
    test_rmse_model5_mat[i,s] = test_rmse_model5
    test_rmse_model6_mat[i,s] = test_rmse_model6
    test_rmse_model7_mat[i,s] = test_rmse_model7
    test_rmse_model8_mat[i,s] = test_rmse_model8
    test_rmse_model9_mat[i,s] = test_rmse_model9

    model1_counter_all_sigma = model1_counter_all_sigma + 1
    model2_counter_all_sigma = model2_counter_all_sigma + 1
    model3_counter_all_sigma = model3_counter_all_sigma + 1 
    model4_counter_all_sigma = model4_counter_all_sigma + 1 
    model5_counter_all_sigma = model5_counter_all_sigma + 1
    model6_counter_all_sigma = model6_counter_all_sigma + 1 
    model7_counter_all_sigma = model7_counter_all_sigma + 1
    model8_counter_all_sigma = model8_counter_all_sigma + 1
    model9_counter_all_sigma = model9_counter_all_sigma + 1
  }
}

print (paste("Number of times the model : 1 trained for alpha:",sigma[s]," is: ",model1_counter_all_sigma))
print (paste("Number of times the model : 2 trained for alpha:",sigma[s]," is: ",model2_counter_all_sigma))
print (paste("Number of times the model : 3 trained for alpha:",sigma[s]," is: ",model3_counter_all_sigma))
print (paste("Number of times the model : 4 trained for alpha:",sigma[s]," is: ",model4_counter_all_sigma))
print (paste("Number of times the model : 5 trained for alpha:",sigma[s]," is: ",model5_counter_all_sigma))
print (paste("Number of times the model : 6 trained for alpha:",sigma[s]," is: ",model6_counter_all_sigma))  
print (paste("Number of times the model : 7 trained for alpha:",sigma[s]," is: ",model7_counter_all_sigma))  
print (paste("Number of times the model : 8 trained for alpha:",sigma[s]," is: ",model8_counter_all_sigma))  
print (paste("Number of times the model : 9 trained for alpha:",sigma[s]," is: ",model9_counter_all_sigma))  
  
for(s in 1:length(sigma)){
  train_rmse_mat[1,s] = mean(train_rmse_model1_mat[,s])
  train_rmse_mat[2,s] = mean(train_rmse_model2_mat[,s])
  train_rmse_mat[3,s] = mean(train_rmse_model3_mat[,s])
  train_rmse_mat[4,s] = mean(train_rmse_model4_mat[,s])
  train_rmse_mat[5,s] = mean(train_rmse_model5_mat[,s])
  train_rmse_mat[6,s] = mean(train_rmse_model6_mat[,s])
  train_rmse_mat[7,s] = mean(train_rmse_model7_mat[,s])
  train_rmse_mat[8,s] = mean(train_rmse_model8_mat[,s])
  train_rmse_mat[9,s] = mean(train_rmse_model9_mat[,s])  
  
  test_rmse_mat[1,s] = mean(test_rmse_model1_mat[,s])
  test_rmse_mat[2,s] = mean(test_rmse_model2_mat[,s])
  test_rmse_mat[3,s] = mean(test_rmse_model3_mat[,s])
  test_rmse_mat[4,s] = mean(test_rmse_model4_mat[,s])
  test_rmse_mat[5,s] = mean(test_rmse_model5_mat[,s])
  test_rmse_mat[6,s] = mean(test_rmse_model6_mat[,s])
  test_rmse_mat[7,s] = mean(test_rmse_model7_mat[,s])
  test_rmse_mat[8,s] = mean(test_rmse_model8_mat[,s])
  test_rmse_mat[9,s] = mean(test_rmse_model9_mat[,s])
}
```

```{r}
plot(seq(1,9), train_rmse_mat[,1], type="o", col="blue", pch="o", lty=1,main="Sigma = 1",xlab = "MODEL SIZE",ylab = "RMSE")
points(seq(1,9), test_rmse_mat[,1], col="red", pch=8)
lines(seq(1,9), test_rmse_mat[,1], col="red",lty=2)
legend("topright",legend=c("train rmse","test rmse"), col=c("blue","red"),pch=c("o","*"),lty=c(1,2), ncol=1)

plot(seq(1,9), train_rmse_mat[,2], type="o", col="blue", pch="o", lty=1,main="Sigma = 2",xlab = "MODEL SIZE",ylab = "RMSE")
points(seq(1,9), test_rmse_mat[,2], col="red", pch=8)
lines(seq(1,9), test_rmse_mat[,2], col="red",lty=2)
legend("topright",legend=c("train rmse","test rmse"), col=c("blue","red"),pch=c("o","*"),lty=c(1,2), ncol=1)

plot(seq(1,9), train_rmse_mat[,3], type="o", col="blue", pch="o", lty=1,main="Sigma = 4",xlab = "MODEL SIZE",ylab = "RMSE")
points(seq(1,9), test_rmse_mat[,3], col="red", pch=8)
lines(seq(1,9), test_rmse_mat[,3], col="red",lty=2)
legend("topright",legend=c("train rmse","test rmse"), col=c("blue","red"),pch=c("o","*"),lty=c(1,2), ncol=1)
```



```{r}
plot(test_rmse_model1_mat[,1],col="dodgerblue",ylim=(c(0.8,3)),pch=1,lty=1,xlab = "Index", ylab = "RMSE")
points(test_rmse_model2_mat[,1], col="orangered",ylim=(c(0.8,3)),pch=1,lty=2)
points(test_rmse_model3_mat[,1], col="blue4",ylim=(c(0.8,3)),pch=1,lty=3)
points(test_rmse_model4_mat[,1], col="limegreen",ylim=(c(0.8,3)),pch=1,lty=3)
points(test_rmse_model5_mat[,1], col="orange",ylim=(c(0.8,3)),pch=1,lty=4)
points(test_rmse_model6_mat[,1], col="darkorchid",ylim=(c(0.8,3)),pch=6,lty=5)
points(test_rmse_model7_mat[,1], col="violetred",ylim=(c(0.8,3)),pch=1,lty=6)
points(test_rmse_model8_mat[,1], col="tan3",ylim=(c(0.8,3)),pch=1,lty=7)
points(test_rmse_model9_mat[,1], col="deeppink",ylim=(c(0.8,3)),pch=1,lty=8)
legend("topright",legend=c("Model1","Model2","Model3","Model4","Model5","Model6","Model7","Model8","Model9"),col=c("dodgerblue","orangered","blue4","limegreen","orange","darkorchid","violetred","tan3","deeppink"),lty=c(1,2,3,4,5,6,7,8,9))
```

** The above model plots the RMSE of all model created from the simulation for the Sigma = 1 **
The correct model should be the one which should have the **lowest RMSE**. From the above plots (which plots against all the 1000 RMSE of simulation) it shows that the Model 1 and Model 2 have higher RMSE and distinctly far from the other model (Model 3/4/5/6/7/8/9), hence its obious to ignore the Model 1 and Model 2. Let's explore the other models as below 



```{r}
plot(test_rmse_model3_mat[,1], col="dodgerblue",ylim=(c(0.9,1.3)),pch=1,lty=3,xlab="Indx",ylab="RMSE")
points(test_rmse_model4_mat[,1], col="limegreen",ylim=(c(0.9,1.3)),pch=1,lty=3)
points(test_rmse_model5_mat[,1], col="orange",ylim=(c(0.9,1.3)),pch=1,lty=4)
points(test_rmse_model6_mat[,1], col="darkorchid",ylim=(c(0.9,1.3)),pch=8,lty=5)
points(test_rmse_model7_mat[,1], col="violetred",ylim=(c(0.9,1.3)),pch=1,lty=6)
points(test_rmse_model8_mat[,1], col="tan3",ylim=(c(0.9,1.3)),pch=1,lty=7)
points(test_rmse_model9_mat[,1], col="deeppink",ylim=(c(0.9,1.3)),pch=1,lty=8)
legend("topright",legend=c("Model3","Model4","Model5","Model6","Model7","Model8","Model9"),col=c("blue4","limegreen","orange","darkorchid","violetred","tan3","deeppink"),pch=c(1,1,1,8,1,1),lty=c(3,4,5,6,7,8,9))
```

** The above model plots the RMSE of models (3/4/5/6/7/8/9) created from the simulation for the Sigma = 1 **

From the above plot, its clear that the **Model 6 not always** (marked in ** * **) selected as the **correct model**. There are many instances, where the ** Model 6 ** RMSE is higher than that of other models, also there are instances where the **Model 6** RMSE is the lowest among other models. Also other models also have in range with the **model 6**. Let's take a loot at the average plot of RMSE of all the models and plot


```{r}
plot(seq(1,9), test_rmse_mat[,1], type="o", col="chartreuse4", pch=8, lty=1,main="Sigma = 1",xlab = "MODEL SIZE",ylab = "RMSE")
points(6, min(test_rmse_mat[,1]), col="chartreuse4",pch=16,cex=3) #This is to highlight the point where the RMSE is minimum for sigma = 1
```

The above plot shows the average RMSE for **1000 simulation** over **9 models** for the **sigma = 1**, the **model 6** has the lowest RMSE which is around ``r min(test_rmse_mat[,1])``

```{r}
plot(seq(1,9), test_rmse_mat[,2], type="o", col="blue4", pch="*", lty=1,main="Sigma = 2",xlab = "MODEL SIZE",ylab = "RMSE")
points(6, min(test_rmse_mat[,2]), col="blue4",pch=16,cex=3) #This is to highlight the point where the RMSE is minimum for sigma = 2
```
The above plot shows the average RMSE for **1000 simulation** over **9 models** for the **sigma = 2**, the **model 6** has the lowest RMSE which is around ``r min(test_rmse_mat[,2])``


```{r}
plot(seq(1,9), test_rmse_mat[,3], type="o", col="red", pch="*", lty=1,main="Sigma = 4",xlab = "MODEL SIZE",ylab = "RMSE")
points(6, min(test_rmse_mat[,3]), col="red",pch=16,cex=3) #This is to highlight the point where the RMSE is minimum for sigma = 4
```
The above plot shows the average RMSE for **1000 simulation** over **9 models** for the **sigma = 4**, the **model 6** has the lowest RMSE which is around ``r min(test_rmse_mat[,3])``


```{r}
plot(seq(1,9), test_rmse_mat[,3], col="red",lty=1,ylim=c(0.5,5),xlab="MODEL SIZE",ylab="RMSE")
lines(seq(1,9), test_rmse_mat[,3], col="red",lty=1)
points(6, min(test_rmse_mat[,3]), col="red",pch=16,cex=3) #This is to highlight the point where the RMSE is minimum for sigma = 4
points(seq(1,9), test_rmse_mat[,2], col="blue4",lty=2)
lines(seq(1,9), test_rmse_mat[,2], col="blue4",lty=2)
points(6, min(test_rmse_mat[,2]), col="blue4",pch=16,cex=3) #This is to highlight the point where the RMSE is minimum for sigma = 2
points(seq(1,9), test_rmse_mat[,1], col="chartreuse4",lty=3)
lines(seq(1,9), test_rmse_mat[,1], col="chartreuse4",lty=3)
points(6, min(test_rmse_mat[,1]), col="chartreuse4",pch=16,cex=3) #This is to highlight the point where the RMSE is minimum for sigma = 1
legend("topright",legend=c("sigma = 4","sigma = 2","simga = 1"),col=c("red","blue4","chartreuse4"),lty=c(1,2,3))
```

The above plots shows the comparision of the average RMSE of all the 9 models for respective 3 sigma values (1, 2 and 4). The big filled circle points the lowest of the RMSE. From the comparision of the plot, it shows that **lowest RMSE** is from the **sigma =1**, also noted that **higher the value of sigma, higher will be the Test RMSE**. Hence to lower the RMSE for the test, we need to choose the lower value of noise (i.e. sigma) 


## Simulation Study 3, Power

###Introduction
In this simulation project we will investigate the **power** of the signifincance of the regression test for the simple linear regression (**SLR**) model

$H_0 : \beta_{0} = 0 Vs H_1: \beta_{1} \neq 0$

where, Power is the probability of rejecting the null hypothesis when the null is not true, that is, the alternative is true and $\beta_{1}$ is non-zero.

We will do the simulation of the Simple linear regression of the model \[ Y_i = \beta_0 + \beta_1 x_{i1} + \epsilon_i.\]. 

For the simplicity we will make $\beta_0$ = 0, thus $\beta_1$ is essentially controlling the amount of signal. We will be considering the following for the different signals , noises and sample sizes

 - β1 ∈ (−2,−1.9,−1.8,…,−0.1,0,0.1,0.2,0.3,…1.9,2) , **which is 41 values**
 - σ ∈ (1,2,4), **three distinct values of sigma**
 - n ∈(10,20,30), **three distinct values of n (sample size)**
 
We will hold the value if the $\alpha$ as **0.05**, while validing the hypothesis. For the generation of the sample data, will be using the seq(0, 5, length = n) for different values of the sample size (i.e., n)

For each possible combination of $\beta_{1}$ and $\alpha$, we will simulate 1000 times to perform the significance of linear regression (**SLR**) and following formula will be using to measure the Power

$\hat{Power}$ = $\hat{P}$[Reject $H_0$, $H_1$ True] = $\dfrac{\#Test Rejected}{\#Simulations}$

**Goal:**

As part of this exercise, the following are the Goals to achieve
 - Simulate the SLR models for 1000 times for a given value of σ, n , β1 and stored the Power you get
 - Plot the Power Curve against the signal strength (β1) for different value of n, plot this kind of plot for each value of σ
 - Discuss with relevant plots, what are the impact of σ, n , β1 on the Power, as following 
   - What's the impact of σ on Power
   - What's the impact of n on Power
   - What's the impact of β1 on Power
 - As we have simulated for the 1000 iterations, would it be suffice ? or more simulations have more important informations to revealed?

 In order to achieve these goals, we have various methods (especially R codes and R markdown) on how we achieve these goals
 
###Methods (Simulation Study 3)
Below is the code which will runs the 1000 simulations against β1, σ and n. After each simulations,
 - The power value is being agregated and stored in the matrix model_sim
 - The 1st column of the row of the matix is the β1 value
 - 2nd, 3rd and 4th column of matrix = model_sim, stores the power values for sigma = 1, for the sample size 10, 20 and 30 respectively
 - 5th, 6th and 7th column of matrix = model_sim, stores the power values for sigma = 2, for the sample size of 10, 20 and 30 respectively
 - 8th, 9th and 10th column of matrix = model_sim, stores the power values for sigma = 5, for the sample size of 10, 20 and 30 respectively
 
Once the matrix model_sim is populated and completed, we will be using to plot different plots to address different discussion

#### Code for Simulations
```{r}
birthday = 19770411
set.seed(birthday)

alpha = 0.05
beta_1 = seq(from=-2,to=2,by=0.1)
sigma = c(1,2,4)
n = c(10,20,30)
no_loop = 1000

#simple linear regression(SLR) Function to create sample data
slr_sim = function(n_in,sd=1,beta_1_in=-2){
  x_values = seq(0, 5, length = n_in)
  epsilon = rnorm(n_in,mean = 0,sd = sd)
  y = beta_1_in * x_values + epsilon
  data.frame(predictor = x_values,response=y)
}

#Matrix to store the Power of the simulated models
model_sim = cbind(beta_1_sim_val=rep(0,length(beta_1)),n_10_sigma_1=rep(0,length(beta_1)),n_20_sigma_1=rep(0,length(beta_1)),n_30_sigma_1=rep(0,length(beta_1)),n_10_sigma_2=rep(0,length(beta_1)),n_20_sigma_2=rep(0,length(beta_1)),n_30_sigma_2=rep(0,length(beta_1)),n_10_sigma_4=rep(0,length(beta_1)),n_20_sigma_4=rep(0,length(beta_1)),n_30_sigma_1=rep(0,length(beta_1)))

model_sim[,1] = seq(from=-2,to=2,by=0.1)
extra_counter = 0

#Loop to iterate over Sigma, number of samples, beta_1 values and 1000 simulations to extract and store the Power values
for(s in 1:length(sigma)){ #sigma = c(1,2,4)
  for (n_s in 1:length(n)){ #n = c(10,20,30)
    for (b in 1:length(beta_1)){ # beta_1 = seq(from=-2,to=2,by=0.1)
      tot_sum_signifincace_sim = 0
      for(i in 1:no_loop){
        slr_data = slr_sim(n_in = n[n_s], sd = sigma[s], beta_1_in = beta_1[b] )
        model = lm(response~predictor, data = slr_data)
        model_p_val = summary(model)$coefficient[2,4]
        tot_sum_signifincace_sim = tot_sum_signifincace_sim + ifelse(model_p_val<alpha,1,0)
      }
      power_sim_beta = tot_sum_signifincace_sim / no_loop
      model_sim[b,s+n_s+extra_counter] = power_sim_beta    
      print (paste("Sigma:",sigma[s]," n:",n[n_s]," beta_1:",beta_1[b]," Signifiance_Sum:",tot_sum_signifincace_sim, " Power:",power_sim_beta))
    }
  }
  extra_counter = extra_counter + 2
}
```

###Results
As we have discussed in the Introduction on the aspect of **Goal**, we have to producded plots to support these Goals

 - Plot the Power Curve against the signal strength (β1) for different value of n, plot this kind of plot for each value of σ


```{r}
#Below code plot the effect of Signal (β1) against the Power for noise of sigma = 1 against all sample size (10,20 and 30)
plot(model_sim[,1],model_sim[,2], type="o", col="dodgerblue", pch=1, lty=1,main="Sigma = 1",xlab = "beta_1",ylab = "Power")
points(model_sim[,1], model_sim[,3], col="red", pch=8,lty=2)
lines(model_sim[,1], model_sim[,3], col="red",lty=2)
points(model_sim[,1], model_sim[,4], col="darkorchid", pch=16,lty=3)
lines(model_sim[,1], model_sim[,4], col="darkorchid",lty=3)
legend("topright",legend=c("n = 10","n = 20"," n = 30"),col=c("dodgerblue","red","darkorchid"),pch=c(1,8,16),lty=c(1,2,3))
```

The above plot depicts the following for the noise of sigma = 1
 - The power is constant i.e. 1 (# rejected hypothesis = # simulation) for beta_1 between -2 and -1 for all sample size (10,20 and 30)
 - As beta_1 increases after -1 and before 0, power decreases rapidly towards 0, means number of rejected hypothesis becomes smaller (failed to reject hypothesis becomes larger) 
 - Again as beta_1 increases after 0, the power increases, i.e. number of rejected hypothesis is larger.
 - Dropping of power nearly or after -1 depends on the sample size, more the sample size (30 > 20 > 10) power becomes constant to 1 (i.e. # reject hypothesis is higher) 


#Below code plot the effect of Signal (β1) against the Power for noise of sigma = 2 against all sample size (10,20 and 30)
```{r}
plot(model_sim[,1],model_sim[,5], type="o", col="dodgerblue", pch=1, lty=1,main="Sigma = 2",xlab = "beta_1",ylab = "Power")
points(model_sim[,1], model_sim[,6], col="red", pch=8,lty=2)
lines(model_sim[,1], model_sim[,6], col="red",lty=2)
points(model_sim[,1], model_sim[,7], col="darkorchid", pch=16,lty=3)
lines(model_sim[,1], model_sim[,7], col="darkorchid",lty=3)
legend("topright",legend=c("n = 10","n = 20"," n = 30"),col=c("dodgerblue","red","darkorchid"),pch=c(1,8,16),lty=c(1,2,3))
```

The above plot depicts the following for the noise of sigma = 2
 - The power is constant i.e. 1 (# rejected hypothesis = # simulation) for beta_1 between till -1.5 for sample size 20 and 30. However lower the sample size with higher noise, the power decreases rapidly (i.e., # of hypothesis rejectes is less)
 - Once beta_1 increase after 0, power increases very rapidly for higher sample size, however slow for small sample size
 - As noise level increases (Sigma =2), the rate at which the power increases/ decreases also lower. So if we compare the power rate increases / decreases between sigma = 1 versus sigma = 2, it founds that power rate increase/decreases is much faster rate in sigma = 1 than in sigma = 2
 - The distance between the power increase/decrease for different sample size (n=10/20 and 30) is wider for higher noise level (sigma = 2) than that of sigma =1, means rejected of hypothesis is higher for higher simga and even higher for lower sample size


#Below code plot the effect of Signal (β1) against the Power for noise of sigma = 4 against all sample size (10,20 and 30)
```{r}
plot(model_sim[,1],model_sim[,8], type="o", col="dodgerblue", pch=1, lty=1,main="Sigma = 4",xlab = "beta_1",ylab = "Power",ylim=c(0,1))
points(model_sim[,1], model_sim[,9], col="red", pch=8,lty=2)
lines(model_sim[,1], model_sim[,9], col="red",lty=2)
points(model_sim[,1], model_sim[,10], col="darkorchid", pch=16,lty=3)
lines(model_sim[,1], model_sim[,10], col="darkorchid",lty=3)
legend("topright",legend=c("n = 10","n = 20"," n = 30"),col=c("dodgerblue","red","darkorchid"),pch=c(1,8,16),lty=c(1,2,3))
```

The above plot depicts the following for the noise of sigma = 4
 - The power seems lower at the initial stage of beta_1 itself, for the lower sample size (10) and decrease very fast until 0. However though it decreases very fast for higher sample size(n=20, 30), however relatively slow as compared to lower sample size (n=10)
 - The above point still valid for the case of increase of beta_1 beyond point 0, where power increases rapidly for higher sample size (30 and then 30) as compared to lower sample size
 - The distance between the power increase/decrease for different sample size (n=10/20 and 30) is wider for higher noise level (sigma = 4) than that of sigma =1 & 2, means rejected of hypothesis is higher for higher simga and even higher for lower sample size


###Discussion
Now as part of the **goal**, let's discuss the what's the impact of β1, n and σ with respect to power. We will be plotting different plots to conclude the summary of the impact

**Effect of sigma(1,2,4) on the Power **
```{r}
plot(model_sim[,1],model_sim[,2], type="o", col="dodgerblue", pch=1, lty=1,main="Effect of sigma (1,2,4) on the Power",xlab = "beta_1",ylab = "Power")
points(model_sim[,1], model_sim[,3], col="dodgerblue", pch=1,lty=1)
lines(model_sim[,1], model_sim[,3], col="dodgerblue",lty=1)
points(model_sim[,1], model_sim[,4], col="dodgerblue", pch=1,lty=1)
lines(model_sim[,1], model_sim[,4], col="dodgerblue",lty=1)

points(model_sim[,1],model_sim[,5], type="o", col="green", pch=1, lty=2)
lines(model_sim[,1],model_sim[,5], type="o", col="green", pch=1, lty=2)
points(model_sim[,1], model_sim[,6], col="green", pch=1,lty=2)
lines(model_sim[,1], model_sim[,6], col="green",lty=2)
points(model_sim[,1], model_sim[,7], col="green", pch=1,lty=2)
lines(model_sim[,1], model_sim[,7], col="green",lty=2)

points(model_sim[,1],model_sim[,8], type="o", col="red", pch=1, lty=3)
lines(model_sim[,1],model_sim[,8], type="o", col="red", pch=1, lty=3)
points(model_sim[,1], model_sim[,9], col="red", pch=1,lty=3)
lines(model_sim[,1], model_sim[,9], col="red",lty=3)
points(model_sim[,1], model_sim[,10], col="red", pch=1,lty=3)
lines(model_sim[,1], model_sim[,10], col="red",lty=3)
legend("topright",legend=c("sigma=1,n=10,20,30","sigma=2,n=10,20,30","sigma=3,n=10,20,30"),col=c("dodgerblue","green","darkorchid","red"),pch=c(1,1,1),lty=c(1,2,3))
```

**Below are the observations on the effect of σ on power**
 - Higher the sigma (σ),lower is the power. 
 - It clearly visible that all the blue line (sigma=1) have higher power than that of green line (sigma = 2) & red line (sigma = 4) for any particular value of β1 and sample size. That means higher the value of the sigma (σ) = number of rejected hypothesis will be lower and lower the value of sigma (σ) = number of rejected hypothesis becomes higher.


**Effect of n(10,20,30) on the Power **
```{r}
par(mfrow=c(2, 2))

plot(model_sim[,1],model_sim[,2], type="o", col="deeppink", pch=1, lty=1,main="Sigma=1",xlab = "beta_1",ylab = "Power")
points(model_sim[,1], model_sim[,3], col="darkolivegreen4", pch=1,lty=2)
lines(model_sim[,1], model_sim[,3], col="darkolivegreen4",lty=2)
points(model_sim[,1], model_sim[,4], col="blueviolet", pch=1,lty=3)
lines(model_sim[,1], model_sim[,4], col="blueviolet",lty=3)
legend("topright",legend=c("n=10","n=20","n=30"),col=c("deeppink","darkolivegreen4","blueviolet"),pch=c(1,1,1),lty=c(1,2,3))

plot(model_sim[,1],model_sim[,5], type="o", col="deeppink", pch=1, lty=1,main="Sigma=2",xlab = "beta_1",ylab = "Power")
#points(model_sim[,1],model_sim[,5], type="o", col="deeppink", pch=1, lty=1)
lines(model_sim[,1],model_sim[,5], type="o", col="deeppink", pch=1, lty=1)
points(model_sim[,1], model_sim[,6], col="darkolivegreen4", pch=1,lty=2)
lines(model_sim[,1], model_sim[,6], col="darkolivegreen4",lty=2)
points(model_sim[,1], model_sim[,7], col="blueviolet", pch=1,lty=3)
lines(model_sim[,1], model_sim[,7], col="blueviolet",lty=3)
legend("topright",legend=c("n=10","n=20","n=30"),col=c("deeppink","darkolivegreen4","blueviolet"),pch=c(1,1,1),lty=c(1,2,3))

plot(model_sim[,1],model_sim[,8], type="o", col="deeppink", pch=1, lty=1,main="Sigma=4",xlab = "beta_1",ylab = "Power",ylim=c(0,1))
#points(model_sim[,1],model_sim[,8], type="o", col="deeppink", pch=1, lty=1)
lines(model_sim[,1],model_sim[,8], type="o", col="deeppink", pch=1, lty=1)
points(model_sim[,1], model_sim[,9], col="darkolivegreen4", pch=1,lty=2)
lines(model_sim[,1], model_sim[,9], col="darkolivegreen4",lty=2)
points(model_sim[,1], model_sim[,10], col="blueviolet", pch=1,lty=3)
lines(model_sim[,1], model_sim[,10], col="blueviolet",lty=3)
legend("topright",legend=c("n=10","n=20","n=30"),col=c("deeppink","darkolivegreen4","blueviolet"),pch=c(1,1,1),lty=c(1,2,3))
```

Below are the observations on the effect of sample size (n = 10,20 and 30) on the beta_1
 - From the abobe 3 plots, for different value of sigma (σ), Higher the sample size (n=30),higher is the power. It clearly visible that for all the 3 plots (against 3 different sigma (σ)), the blueviolet (n = 30) lines have higher than that of the rest 2 lines (green,n = 20 and deep pink, n= 10). That is higher the sample size, reject the hypothesis becomes higher

**Effect of n(10,20,30) on the Power **

```{r}
plot(model_sim[,1],model_sim[,2], type="o", col="dodgerblue", pch=1, lty=1,main="Sigma = 1,2,4 & n = 10,20,30",xlab = "beta_1",ylab = "Power")
points(model_sim[,1], model_sim[,3], col="red", pch=2,lty=2)
lines(model_sim[,1], model_sim[,3], col="red",lty=2)
points(model_sim[,1], model_sim[,4], col="tan1", pch=3,lty=3)
lines(model_sim[,1], model_sim[,4], col="tan1",lty=3)

points(model_sim[,1],model_sim[,5], type="o", col="yellow", pch=4, lty=4)
lines(model_sim[,1],model_sim[,5], type="o", col="yellow", pch=4, lty=4)

points(model_sim[,1], model_sim[,6], col="deeppink", pch=5,lty=5)
lines(model_sim[,1], model_sim[,6], col="deeppink",lty=5)
points(model_sim[,1], model_sim[,7], col="darkolivegreen4", pch=6,lty=6)
lines(model_sim[,1], model_sim[,7], col="darkolivegreen4",lty=6)

points(model_sim[,1],model_sim[,8], type="o", col="darkgreen", pch=7, lty=7)
lines(model_sim[,1],model_sim[,8], type="o", col="darkgreen", pch=7, lty=7)

points(model_sim[,1], model_sim[,9], col="darkblue", pch=8,lty=8)
lines(model_sim[,1], model_sim[,9], col="darkblue",lty=8)
points(model_sim[,1], model_sim[,10], col="blueviolet", pch=9,lty=9)
lines(model_sim[,1], model_sim[,10], col="blueviolet",lty=9)

legend("topright",legend=c("sigma=1,n=10","sigma=1,n=20","sigma=1,n=30","sigma=2,n=10","sigma=2,n=20","sigma=2,n=30","sigma=3,n=10","sigma=3,n=20","sigma=3,n=30"),col=c("dodgerblue","red","darkorchid","yellow","deeppink","darkolivegreen4","darkgreen","darkblue","blueviolet"),pch=c(1,2,3,4,5,6,7,8,9),lty=c(1,2,3,4,5,6,7,8,9))
```

If we combine all the plots for all the sample size beta(β1), sample size(n) and sigma(σ), from the above figure, **below are the observations on the effect of β1 on power ***
 - Power decreased as β1 increased from -2 till 0 for any given sigma(σ) and sample size(n), means as β1 increases, reject hypothesis decreases
 - Power increased as β1 increased from 0 till 2  for any given sigma(σ) and sample size(n), means as β1 increases, reject hypothesis increases

 